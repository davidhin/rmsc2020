key,Message,topic,val,words
53789589_so,keras python python-3.x tensorflow keras tensorflow importing error in sublime text and spyder but working in command line in command-line everything seems fine but when i am importing tensorflow in sublime text or spyder it gives the following error -      traceback most recent call last:    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py line 28 in       _pywrap_tensorflow_internal = swig_import_helper    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description    file /usr/lib/python3.6/imp.py line 243 in load_module      return load_dynamicname filename file    file /usr/lib/python3.6/imp.py line 343 in load_dynamic      return _loadspec  importerror libcublas.so.9.0 cannot open shared object file no such file or directory      during handling of the above exception another exception occurred      traceback most recent call last:    file /home/himanshu/desktop/iii.py line 1 in       import tensorflow as tf    file /usr/local/lib/python3.6/dist-packages/tensorflow/ init .py line 24 in       from tensorflow.python import pywrap_tensorflow  # pylint disable=unused-import    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/ init .py line 49 in       from tensorflow.python import pywrap_tensorflow    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py line 74 in       raise importerrormsg  importerror traceback most recent call last:    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py line 28 in       _pywrap_tensorflow_internal = swig_import_helper    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description    file /usr/lib/python3.6/imp.py line 243 in load_module      return load_dynamicname filename file    file /usr/lib/python3.6/imp.py line 343 in load_dynamic      return _loadspec  importerror libcublas.so.9.0 cannot open shared object file no such file or directory   when i am importing keras   following is the error     using tensorflow backend.  traceback most recent call last:    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py line 28 in       _pywrap_tensorflow_internal = swig_import_helper    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description    file /usr/lib/python3.6/imp.py line 243 in load_module      return load_dynamicname filename file    file /usr/lib/python3.6/imp.py line 343 in load_dynamic      return _loadspec  importerror libcublas.so.9.0 cannot open shared object file no such file or directory      during handling of the above exception another exception occurred      traceback most recent call last:    file /home/himanshu/desktop/iii.py line 1 in       import keras    file /usr/local/lib/python3.6/dist-packages/keras/ init .py line 3 in       from  import utils    file /usr/local/lib/python3.6/dist-packages/keras/utils/ init .py line 6 in       from  import conv_utils    file /usr/local/lib/python3.6/dist-packages/keras/utils/conv_utils.py line 9 in       from . import backend as k    file /usr/local/lib/python3.6/dist-packages/keras/backend/ init .py line 89 in       from .tensorflow_backend import *    file /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py line 5 in       import tensorflow as tf    file /usr/local/lib/python3.6/dist-packages/tensorflow/ init .py line 24 in       from tensorflow.python import pywrap_tensorflow  # pylint disable=unused-import    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/ init .py line 49 in       from tensorflow.python import pywrap_tensorflow    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py line 74 in       raise importerrormsg  importerror traceback most recent call last:    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py line 28 in       _pywrap_tensorflow_internal = swig_import_helper    file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description    file /usr/lib/python3.6/imp.py line 243 in load_module      return load_dynamicname filename file    file /usr/lib/python3.6/imp.py line 343 in load_dynamic      return _loadspec  importerror libcublas.so.9.0 cannot open shared object file no such file or directory      failed to load the native tensorflow runtime    note - i am using pip for my python packages and not conda ,6,0.991587372772214,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
45777648_so,python tensorflow problems installing tensor flow windows 10 i m trying to get tensorflow to work on my windows 10 machine i have cude 8 and cudnn 5.1 installed and added to the  .installed python 3.5.4 then proceeded to install tensorflow by executing   the computer is running a geforce 1060  here is what i get when i try to import tensorflow     import tensorflow as tf  traceback most recent call last:   file c:\users\morit\appdata\local\programs\python\python35\lib\site->packages\tensorflow\python\pywrap_tensorflow_internal.py line 18 in >swig_import_helper     return importlib.import_modulemname   file >c:\users\morit\appdata\local\programs\python\python35\lib\importlib__init__.p>y line 126 in import_module     return _bootstrap._gcd_importname[level:] package level   file  line 985 in _gcd_import   file  line 968 in _find_and_load   file  line 957 in _find_and_load_unlocked   file  line 666 in _load_unlocked   file  line 577 in module_from_spec   file  line 938 in create_module   file  line 222 in _call_with_frames_removed  importerror dll load failed the specified module could not be found   during handling of the above exception another exception occurred below     traceback most recent call last:   file c:\users\morit\appdata\local\programs\python\python35\lib\site->packages\tensorflow\python\pywrap_tensorflow.py line 41 in      from tensorflow.python.pywrap_tensorflow_internal import *   file c:\users\morit\appdata\local\programs\python\python35\lib\site->packages\tensorflow\python\pywrap_tensorflow_internal.py line 21 in      _pywrap_tensorflow_internal = swig_import_helper   file c:\users\morit\appdata\local\programs\python\python35\lib\site->packages\tensorflow\python\pywrap_tensorflow_internal.py line 20 in >swig_import_helper     return importlib.import_module _pywrap_tensorflow_internal    file >c:\users\morit\appdata\local\programs\python\python35\lib\importlib__init__.p>y line 126 in import_module     return _bootstrap._gcd_importname[level:] package level  importerror no module named  _pywrap_tensorflow_internal    during handling of the above exception another exception occurred     traceback most recent call last:   file  line 1 in    file c:\users\morit\appdata\local\programs\python\python35\lib\site->packages\tensorflow__init__.py line 24 in      from tensorflow.python import *   file c:\users\morit\appdata\local\programs\python\python35\lib\site->packages\tensorflow\python__init__.py line 49 in      from tensorflow.python import pywrap_tensorflow   file c:\users\morit\appdata\local\programs\python\python35\lib\site->packages\tensorflow\python\pywrap_tensorflow.py line 52 in      raise importerrormsg  importerror traceback most recent call last:   file c:\users\morit\appdata\local\programs\python\python35\lib\site->packages\tensorflow\python\pywrap_tensorflow_internal.py line 18 in >swig_import_helper     return importlib.import_modulemname   file >c:\users\morit\appdata\local\programs\python\python35\lib\importlib__init__.p>y line 126 in import_module     return _bootstrap._gcd_importname[level:] package level   file  line 985 in _gcd_import   file  line 968 in _find_and_load   file  line 957 in _find_and_load_unlocked   file  line 666 in _load_unlocked   file  line 577 in module_from_spec   file  line 938 in create_module   file  line 222 in _call_with_frames_removed  importerror dll load failed the specified module could not be found   during handling of the above exception another exception occurred     traceback most recent call last:   file c:\users\morit\appdata\local\programs\python\python35\lib\site->packages\tensorflow\python\pywrap_tensorflow.py line 41 in      from tensorflow.python.pywrap_tensorflow_internal import *   file c:\users\morit\appdata\local\programs\python\python35\lib\site->packages\tensorflow\python\pywrap_tensorflow_internal.py line 21 in      _pywrap_tensorflow_internal = swig_import_helper   file c:\users\morit\appdata\local\programs\python\python35\lib\site->packages\tensorflow\python\pywrap_tensorflow_internal.py line 20 in >swig_import_helper     return importlib.import_module _pywrap_tensorflow_internal    file >c:\users\morit\appdata\local\programs\python\python35\lib\importlib__init__.p>y line 126 in import_module     return _bootstrap._gcd_importname[level:] package level  importerror no module named  _pywrap_tensorflow_internal       failed to load the native tensorflow runtime      see > https://www.tensorflow.org/install/install_sources#common_installation_problems       for some common reasons and solutions include the entire stack trace  above this error message when asking for help i ve faced this error during my setup  but my environment is windows 7.uninstalled the python and reinstalled python 3.5 and continued the setup.next followed this link to resolve the dll load failed error  https://www.tensorflow.org/versions/r0.12/get_started/os_setup#pip_installation_on_windows,6,0.9865279707833945,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
46644117_so,tensorflow trensorflow installation issue failed to load the native tensorflow runtime i am trying to install tensorflow in a ubuntu machine running on oracle virtualbox within a windows pc  system details:host os windows7 - 32 bitvm oracle virtuaboxvm os ubuntu -  64 bit   steps followed for tensor flow installation 1 created a session tflow with conda and python 3.52 activated tflow3 installed tensorflow through pip4 tried to import tensorflow with the following command after installation: import tensorflow as tf   system threw the following error      import tensorflow as tf   traceback most recent call last     file /home/sethu/conda3/envs/tflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py line 41 in        from tensorflow.python.pywrap_tensorflow_internal import *     file /home/sethu/conda3/envs/tflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py line 28 in        _pywrap_tensorflow_internal = swig_import_helper     file /home/sethu/conda3/envs/tflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py line 24 in swig_import_helper       _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description     file /home/sethu/conda3/envs/tflow/lib/python3.5/imp.py line 243 in load_module       return load_dynamicname filename file     file /home/sethu/conda3/envs/tflow/lib/python3.5/imp.py line 343 in load_dynamic       return _loadspec   importerror /lib/x86_64-linux-gnu/libc.so.6 version `glibc_2.17  not found required by /home/sethu/conda3/envs/tflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so    during handling of the above exception another exception occurred      traceback most recent call last     file  line 1 in      file /home/sethu/conda3/envs/tflow/lib/python3.5/site-packages/tensorflow/ init .py line 24 in        from tensorflow.python import *     file /home/sethu/conda3/envs/tflow/lib/python3.5/site-packages/tensorflow/python/ init .py line 49 in        from tensorflow.python import pywrap_tensorflow     file /home/sethu/conda3/envs/tflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py line 52 in        raise importerrormsg   importerror traceback most recent call last     file /home/sethu/conda3/envs/tflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py line 41 in        from tensorflow.python.pywrap_tensorflow_internal import *     file /home/sethu/conda3/envs/tflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py line 28 in        _pywrap_tensorflow_internal = swig_import_helper     file /home/sethu/conda3/envs/tflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py line 24 in swig_import_helper       _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description     file /home/sethu/conda3/envs/tflow/lib/python3.5/imp.py line 243 in load_module       return load_dynamicname filename file     file /home/sethu/conda3/envs/tflow/lib/python3.5/imp.py line 343 in load_dynamic       return _loadspec   importerror /lib/x86_64-linux-gnu/libc.so.6 version `glibc_2.17  not found required by /home/sethu/conda3/envs/tflow/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so        failed to load the native tensorflow runtime        see   https://www.tensorflow.org/install/install_sources#common_installation_problems       for some common reasons and solutions  include the entire stack trace  above this error message when asking for help   please help!  thankssethu may you use jupyter notebook?there is all file you required have been already install,6,0.986081884714081,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
53542547_so,tensorflow import tensorflow is failing with importerror dll load failed the specified module could not be found python 3.6.7 v3.6.7:6ec5cf24b7 oct 20 2018 13:35:33 [msc v.1900 64 bit amd64] on win32type help copyright credits or license for more information                 import tensorflow      traceback most recent call last:        file c:\users\abhisek\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in           from tensorflow.python.pywrap_tensorflow_internal import *        file c:\users\abhisek\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in           _pywrap_tensorflow_internal = swig_import_helper        file c:\users\abhisek\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper          _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description        file c:\users\abhisek\appdata\local\programs\python\python36\lib\imp.py line 243 in load_module          return load_dynamicname filename file        file c:\users\abhisek\appdata\local\programs\python\python36\lib\imp.py line 343 in load_dynamic          return _loadspec      importerror dll load failed the specified module could not be found           during handling of the above exception another exception occurred  traceback most recent call last:  file  line 1 in     import tensorflow  file c:\users\abhisek\appdata\local\programs\python\python36\lib\site-packages\tensorflow__init__.py line 24 in     from tensorflow.python import pywrap_tensorflow  # pylint disable=unused-import  file c:\users\abhisek\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python__init__.py line 49 in     from tensorflow.python import pywrap_tensorflow  file c:\users\abhisek\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 74 in     raise importerrormsgimporterror traceback most recent call last:  file c:\users\abhisek\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in     from tensorflow.python.pywrap_tensorflow_internal import *  file c:\users\abhisek\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in     _pywrap_tensorflow_internal = swig_import_helper  file c:\users\abhisek\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper    _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description  file c:\users\abhisek\appdata\local\programs\python\python36\lib\imp.py line 243 in load_module    return load_dynamicname filename file  file c:\users\abhisek\appdata\local\programs\python\python36\lib\imp.py line 343 in load_dynamic    return _loadspecimporterror dll load failed the specified module could not be found  failed to load the native tensorflow runtime  see  https://www.tensorflow.org/install/errors ,6,0.9853208710006094,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
50338301_so,"python tensorflow import tensorflow as tf error help appreciated on following tensorflow installation issue system windows 10 home 64-bit  -clean installed python 3.6.5 as administrator  -ran pip install tensorflow from python s script directory via cmd-line as administrator no errors  trying to execute following code importing module   gives following stack trace      traceback most recent call last   file  c:\users\user\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 14 in swig_import_helper      return importlib.import_modulemname   file c:\users\user\appdata\local\programs\python\python36\lib\importlib__init__.py,  line 126 in import_module      return _bootstrap._gcd_importname[level:] package level   file  line 994 in _gcd_import   file   line 971 in _find_and_load   file   line 955 in _find_and_load_unlocked   file  line 658 in _load_unlocked   file  line 571 in module_from_spec   file  line 922 in  create_module   file  line 219 in  _call_with_frames_removed importerror dll load failed a dynamic link library dll initialization routine failed      during handling of the above exception another exception occurred      traceback most recent call last   file  c:\users\user\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py,  line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *   file c:\users\user\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 17 in       _pywrap_tensorflow_internal = swig_import_helper   file c:\users\user\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 16 in swig_import_helper      return importlib.import_module _pywrap_tensorflow_internal    file  c:\users\user\appdata\local\programs\python\python36\lib\importlib__init__.py,  line 126 in import_module      return _bootstrap._gcd_importname[level:] package level modulenotfounderror no module named  _pywrap_tensorflow_internal       during handling of the above exception another exception occurred      traceback most recent call last   file  line 1 in        import tensorflow as tf   file c:\users\user\appdata\local\programs\python\python36\lib\site-packages\tensorflow__init__.py,  line 24 in       from tensorflow.python import pywrap_tensorflow  # pylint disable=unused-import   file  c:\users\user\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python__init__.py,  line 49 in       from tensorflow.python import pywrap_tensorflow   file c:\users\user\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py,  line 74 in       raise importerrormsg importerror traceback most recent call last   file  c:\users\user\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 14 in swig_import_helper      return importlib.import_modulemname   file c:\users\user\appdata\local\programs\python\python36\lib\importlib__init__.py,  line 126 in import_module      return _bootstrap._gcd_importname[level:] package level   file  line 994 in _gcd_import   file   line 971 in _find_and_load   file   line 955 in _find_and_load_unlocked   file  line 658 in _load_unlocked   file  line 571 in module_from_spec   file  line 922 in  create_module   file  line 219 in  _call_with_frames_removed importerror dll load failed a dynamic link library dll initialization routine failed      during handling of the above exception another exception occurred      traceback most recent call last   file  c:\users\user\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py,  line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *   file c:\users\user\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 17 in       _pywrap_tensorflow_internal = swig_import_helper   file c:\users\user\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 16 in swig_import_helper      return importlib.import_module _pywrap_tensorflow_internal    file  c:\users\user\appdata\local\programs\python\python36\lib\importlib__init__.py,  line 126 in import_module      return _bootstrap._gcd_importname[level:] package level modulenotfounderror no module named  _pywrap_tensorflow_internal       failed to load the native tensorflow runtime      see   https://www.tensorflow.org/install/install_sources#common_installation_problems       for some common reasons and solutions  include the entire stack trace  above this error message when asking for help   help appreciated!  ",6,0.9851443832102339,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
44989628_so,"pip python tensorflow error importing tensorflow python 3.6.1 i get this error whenever i try to import tensorflow  traceback most recent call last:  file c:\users\ali\appdata\local\programs\python\python36-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 18 in swig_import_helper    fp pathname description = imp.find_module _pywrap_tensorflow  [dirname file ]  file c:\users\ali\appdata\local\programs\python\python36-32\lib\imp.py line 296 in find_module    raise importerror_err_msg.formatname name=nameimporterror no module named  _pywrap_tensorflow   during handling of the above exception another exception occurred  traceback most recent call last:  file c:\users\ali\appdata\local\programs\python\python36-32\lib\site-packages\tensorflow\python__init__.py line 54 in     from tensorflow.python import pywrap_tensorflow  file c:\users\ali\appdata\local\programs\python\python36-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 28 in     _pywrap_tensorflow = swig_import_helper  file c:\users\ali\appdata\local\programs\python\python36-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 20 in swig_import_helper    import _pywrap_tensorflowmodulenotfounderror no module named  _pywrap_tensorflow   during handling of the above exception another exception occurred  traceback most recent call last:  file  line 1 in     import tensorflow  file c:\users\ali\appdata\local\programs\python\python36-32\lib\site-packages\tensorflow__init__.py line 24 in     from tensorflow.python import *  file c:\users\ali\appdata\local\programs\python\python36-32\lib\site-packages\tensorflow\python__init__.py line 60 in     raise importerrormsgimporterror traceback most recent call last:  file c:\users\ali\appdata\local\programs\python\python36-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 18 in swig_import_helper    fp pathname description = imp.find_module _pywrap_tensorflow  [dirname file ]  file c:\users\ali\appdata\local\programs\python\python36-32\lib\imp.py line 296 in find_module    raise importerror_err_msg.formatname name=nameimporterror no module named  _pywrap_tensorflow   during handling of the above exception another exception occurred  traceback most recent call last:  file c:\users\ali\appdata\local\programs\python\python36-32\lib\site-packages\tensorflow\python__init__.py line 54 in     from tensorflow.python import pywrap_tensorflow  file c:\users\ali\appdata\local\programs\python\python36-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 28 in     _pywrap_tensorflow = swig_import_helper  file c:\users\ali\appdata\local\programs\python\python36-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 20 in swig_import_helper    import _pywrap_tensorflowmodulenotfounderror no module named  _pywrap_tensorflow   error importing tensorflow  unless you are using bazel,you should not try to import tensorflow from its source directory;please exit the tensorflow source tree and relaunch your python interpreterfrom there ",6,0.9845100459891519,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
55113660_so,anaconda python tensorflow cannot get tensorflow to work dll load failed and dll initialization routine failed i cant seem to import tensorflow even though i have supposedly installed cuda and followed an online tutorial i am using windows please help me  this is my error      import tensorflow  traceback most recent call last:    file c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *    file c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in       _pywrap_tensorflow_internal = swig_import_helper    file c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description    file c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\imp.py line 243 in load_module      return load_dynamicname filename file    file c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\imp.py line 343 in load_dynamic      return _loadspec           importerror dll load failed a dynamic link library dll initialization routine failed          during handling of the above exception another exception occurred         traceback most recent call last:    file  line 1 in     file c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow__init__.py line 24 in       from tensorflow.python import pywrap_tensorflow  # pylint disable=unused-import    file c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python__init__.py line 49 in       from tensorflow.python import pywrap_tensorflow    file c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 74 in       raise importerrormsg  importerror traceback most recent call last:    file c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *    file c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in       _pywrap_tensorflow_internal = swig_import_helper    file c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description    file c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\imp.py line 243 in load_module      return load_dynamicname filename file    file c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\imp.py line 343 in load_dynamic      return _loadspec           importerror dll load failed a dynamic link library dll initialization routine failed.    failed to load the native tensorflow runtime      this is what i get when i run tensorflow_self_check.py:error failed to import the tensorflow module        python version is 3.6    tensorflow is installed at c:\users\user\appdata\local\conda\conda\envs\tensorflow\lib\site-packages\tensorflow    could not load  cudart64_80.dll  the gpu version of tensorflow  requires that this dll be installed in a directory that is named in  your %path% environment variable download and install cuda 8.0 from  this url  https://developer.nvidia.com/cuda-toolkit     could not load  nvcuda.dll  the gpu version of tensorflow requires that  this dll be installed in a directory that is named in your %path%  environment variable typically it is installed in  c:\windows\system32 .  if it is not present ensure that you have a cuda-capable gpu with the  correct driver installed ,6,0.9844333156741174,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
56913551_so,"importerror python tensorflow i have installed tensorflow in python in windows 10 through pip comand but there is an error of dll load failed while importing it i am facing following error while importing tensorflow  c:\windows\system32>import tensorflow as tf import  is not recognized as an internal or external command,operable program or batch file  c:\windows\system32>pythonpython 3.6.2 |anaconda inc.| default sep 19 2017 08:03:39 [msc v.1900 64 bit amd64] on win32type help copyright credits or license for more information                 import tensorflow as tf      traceback most recent call last:        file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in           from tensorflow.python.pywrap_tensorflow_internal import *        file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in           _pywrap_tensorflow_internal = swig_import_helper        file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper          _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description        file c:\programdata\anaconda3\lib\imp.py line 242 in load_module          return load_dynamicname filename file        file c:\programdata\anaconda3\lib\imp.py line 342 in load_dynamic          return _loadspec      importerror dll load failed a dynamic link library dll initialization routine failed           during handling of the above exception another exception occurred  traceback most recent call last:  file  line 1 in   file c:\programdata\anaconda3\lib\site-packages\tensorflow__init__.py line 40 in     from tensorflow.python.tools import module_util as _module_util  file c:\programdata\anaconda3\lib\site-packages\tensorflow\python__init__.py line 49 in     from tensorflow.python import pywrap_tensorflow  file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 74 in     raise importerrormsgimporterror traceback most recent call last:  file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in     from tensorflow.python.pywrap_tensorflow_internal import *  file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in     _pywrap_tensorflow_internal = swig_import_helper  file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper    _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description  file c:\programdata\anaconda3\lib\imp.py line 242 in load_module    return load_dynamicname filename file  file c:\programdata\anaconda3\lib\imp.py line 342 in load_dynamic    return _loadspecimporterror dll load failed a dynamic link library dll initialization routine failed  failed to load the native tensorflow runtime  see  https://www.tensorflow.org/install/errors   for some common reasons and solutions  include the entire stack traceabove this error message when asking for help                 import tensorflow as tf      traceback most recent call last:        file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in           from tensorflow.python.pywrap_tensorflow_internal import *        file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in           _pywrap_tensorflow_internal = swig_import_helper        file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper          _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description        file c:\programdata\anaconda3\lib\imp.py line 242 in load_module          return load_dynamicname filename file        file c:\programdata\anaconda3\lib\imp.py line 342 in load_dynamic          return _loadspec      importerror dll load failed a dynamic link library dll initialization routine failed           during handling of the above exception another exception occurred  traceback most recent call last:  file  line 1 in   file c:\programdata\anaconda3\lib\site-packages\tensorflow__init__.py line 40 in     from tensorflow.python.tools import module_util as _module_util  file c:\programdata\anaconda3\lib\site-packages\tensorflow\python__init__.py line 49 in     from tensorflow.python import pywrap_tensorflow  file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 74 in     raise importerrormsgimporterror traceback most recent call last:  file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in     from tensorflow.python.pywrap_tensorflow_internal import *  file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in     _pywrap_tensorflow_internal = swig_import_helper  file c:\programdata\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper    _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description  file c:\programdata\anaconda3\lib\imp.py line 242 in load_module    return load_dynamicname filename file  file c:\programdata\anaconda3\lib\imp.py line 342 in load_dynamic    return _loadspecimporterror dll load failed a dynamic link library dll initialization routine failed  failed to load the native tensorflow runtime  see  https://www.tensorflow.org/install/errors   for some common reasons and solutions  include the entire stack traceabove this error message when asking for help ",6,0.9843721319791107,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
52919239_so,python python-3.x tensorflow importerror dll load failed a dynamic link library dll initialization routine failed.importing tensorflow error import tensorflow as tf      traceback most recent call last:        file e:\path\envs\py36_tf_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in           from tensorflow.python.pywrap_tensorflow_internal import *        file e:\path\envs\py36_tf_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in           _pywrap_tensorflow_internal = swig_import_helper        file e:\path\envs\py36_tf_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper          _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description        file e:\path\envs\py36_tf_cpu\lib\imp.py line 243 in load_module          return load_dynamicname filename file        file e:\path\envs\py36_tf_cpu\lib\imp.py line 343 in load_dynamic          return _loadspec      importerror dll load failed a dynamic link library dll initialization routine failed           during handling of the above exception another exception occurred  traceback most recent call last:  file  line 1 in   file e:\path\envs\py36_tf_cpu\lib\site-packages\tensorflow__init__.py line 22 in     from tensorflow.python import pywrap_tensorflow  # pylint disable=unused-import  file e:\path\envs\py36_tf_cpu\lib\site-packages\tensorflow\python__init__.py line 49 in     from tensorflow.python import pywrap_tensorflow  file e:\path\envs\py36_tf_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 74 in     raise importerrormsgimporterror traceback most recent call last:  file e:\path\envs\py36_tf_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in     from tensorflow.python.pywrap_tensorflow_internal import *  file e:\path\envs\py36_tf_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in     _pywrap_tensorflow_internal = swig_import_helper  file e:\path\envs\py36_tf_cpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper    _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description  file e:\path\envs\py36_tf_cpu\lib\imp.py line 243 in load_module    return load_dynamicname filename file  file e:\path\envs\py36_tf_cpu\lib\imp.py line 343 in load_dynamic    return _loadspecimporterror dll load failed a dynamic link library dll initialization routine failed  failed to load the native tensorflow runtime  see  https://www.tensorflow.org/install/install_sources#common_installation_problems   for some common reasons and solutions  include the entire stack traceabove this error message when asking for help as of april 2019 i solved the dll load failed problem under windows 10 / python 3.6.x / gpu rtx 20xx by installing  cuda 10.0  not 10.1 or 9.x!!! with  cudnn 7.5.0  i also have visual studio 2015 installed   if you have cuda 10.1 uninstall it install 10.0 and reboot place the files from cudnn in the respective dirs of your cuda installation don t forget to add the location of your cudnn   files the   folder of your cuda installation to your path  tensorflow can be installed using   currently version 1.13.1  you can test if the gpu is registered using,6,0.9841173843488503,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
53921175_so,"python python-3.x tensorflow not able to import tensorflow on anaconda with python 3.6 version on 64bit system with 64bit anaconda when i import tensorflow it gives me this error                          traceback most recent call last:          file c:\users\user\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in             from tensorflow.python.pywrap_tensorflow_internal import *          file c:\users\user\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in             _pywrap_tensorflow_internal = swig_import_helper          file c:\users\user\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper            _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description          file c:\users\user\anaconda3\lib\imp.py line 243 in load_module            return load_dynamicname filename file          file c:\users\user\anaconda3\lib\imp.py line 343 in load_dynamic            return _loadspec        importerror dll load failed a dynamic link library dll initialization routine failed                     during handling of the above exception another exception occurred      traceback most recent call last   file  line 1 in        import tensorflow as tf   file c:\users\user\anaconda3\lib\site-packages\tensorflow__init__.py,  line 24 in       from tensorflow.python import pywrap_tensorflow  # pylint disable=unused-import   file  c:\users\user\anaconda3\lib\site-packages\tensorflow\python__init__.py,  line 49 in       from tensorflow.python import pywrap_tensorflow   file c:\users\user\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py,  line 74 in       raise importerrormsg importerror traceback most recent call last   file  c:\users\user\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py,  line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *   file c:\users\user\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 28 in       _pywrap_tensorflow_internal = swig_import_helper   file c:\users\user\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description   file c:\users\user\anaconda3\lib\imp.py,  line 243 in load_module      return load_dynamicname filename file   file c:\users\user\anaconda3\lib\imp.py line 343 in load_dynamic      return _loadspec importerror dll load failed a dynamic link library dll initialization routine failed      failed to load the native tensorflow runtime      see  https://www.tensorflow.org/install/errors    please help me with this the following might me the problems     you have not installed microsoft c++ redist 2015 update 3 it contains the missing dll you need to download the 2015 update 3 version only    your cpu doesn t support avx instructions which are needed by tensorflow you will need a processer which supports avx",6,0.9836548707009776,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
52767007_so,"python python-3.x tensorflow importing tensorflow not working when upgraded was working fine when i had   but when i upgraded it it stopped working  the version that i installed is   with   and        traceback most recent call last   file  c:\users\anime\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py,  line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *   file c:\users\anime\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 28 in       _pywrap_tensorflow_internal = swig_import_helper   file c:\users\anime\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description   file  c:\users\anime\appdata\local\programs\python\python36\lib\imp.py,  line 243 in load_module      return load_dynamicname filename file   file c:\users\anime\appdata\local\programs\python\python36\lib\imp.py,  line 343 in load_dynamic      return _loadspec importerror dll load failed the specified module could not be found   during handling of the above exception another exception occurred     traceback most recent call last   file  line 1 in     file  c:\users\anime\appdata\local\programs\python\python36\lib\site-packages\tensorflow__init__.py,  line 22 in       from tensorflow.python import pywrap_tensorflow  # pylint disable=unused-import   file  c:\users\anime\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python__init__.py,  line 49 in       from tensorflow.python import pywrap_tensorflow   file c:\users\anime\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py,  line 74 in       raise importerrormsg importerror traceback most recent call last   file  c:\users\anime\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py,  line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *   file c:\users\anime\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 28 in       _pywrap_tensorflow_internal = swig_import_helper   file c:\users\anime\appdata\local\programs\python\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description   file  c:\users\anime\appdata\local\programs\python\python36\lib\imp.py,  line 243 in load_module      return load_dynamicname filename file   file c:\users\anime\appdata\local\programs\python\python36\lib\imp.py,  line 343 in load_dynamic      return _loadspec importerror dll load failed the specified module could not be found ",6,0.9831248394519203,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
49203553_so,build raspberry-pi3 raspbian tensorflow tensorflow on raspbian stretch importerror i built   from source on   i encountered a problem though when starting up tensorflow i get an importerror as shown below     traceback most recent call last:    file /usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *    file /usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py line 28 in       _pywrap_tensorflow_internal = swig_import_helper    file /usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description    file /usr/lib/python3.5/imp.py line 242 in load_module      return load_dynamicname filename file    file /usr/lib/python3.5/imp.py line 342 in load_dynamic      return _loadspec  importerror /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so undefined symbol _zn10tensorflow9concatcpuins_8bfloat16eeevpns_10devicebaseerkst6vectorist10unique_ptrins_6ttypesit_li2eie11constmatrixest14default_deleteis9_eesaisc_eepns8_6matrixe   during handling of the above exception another exception occurred     traceback most recent call last:    file idex.py line 1 in       import gui    file /home/pi/desktop/idex/scripts/gui.py line 10 in       import fun_util    file signlang/fun_util.py line 3 in       import tensorflow as tf    file /usr/local/lib/python3.5/dist-packages/tensorflow/ init .py line 24 in       from tensorflow.python import *  # pylint disable=redefined-builtin    file /usr/local/lib/python3.5/dist-packages/tensorflow/python/ init .py line 49 in       from tensorflow.python import pywrap_tensorflow    file /usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py line 74 in       raise importerrormsg  importerror traceback most recent call last:    file /usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *    file /usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py line 28 in       _pywrap_tensorflow_internal = swig_import_helper    file /usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description    file /usr/lib/python3.5/imp.py line 242 in load_module      return load_dynamicname filename file    file /usr/lib/python3.5/imp.py line 342 in load_dynamic      return _loadspec  importerror /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so undefined symbol _zn10tensorflow9concatcpuins_8bfloat16eeevpns_10devicebaseerkst6vectorist10unique_ptrins_6ttypesit_li2eie11constmatrixest14default_deleteis9_eesaisc_eepns8_6matrixe   failed to load the native tensorflow runtime  see  https://www.tensorflow.org/install/install_sources#common_installation_problems   for some common reasons and solutions  include the entire stack traceabove this error message when asking for help  i ve tried searching for this problem but i couldnt find anything for this particular undefined symbol i was able to install tf with keras using pip3 on raspbian stretch it is much faster then building it.here what i run following  https://installvirtual.com/how-to-install-tensorflow-on-raspberry-pi,6,0.9830207634511214,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
42483644_so,python tensorflow error imporing tensorflow in python 3.4 failed to load the native tensorflow runtime traceback most recent call last:  file /usr/local/lib/python3.4/dist-packages/tensorflow/python/ init .py line 61 in     from tensorflow.python import pywrap_tensorflow  file /usr/local/lib/python3.4/dist-packages/tensorflow/python/pywrap_tensorflow.py line 28 in     _pywrap_tensorflow = swig_import_helper  file /usr/local/lib/python3.4/dist-packages/tensorflow/python/pywrap_tensorflow.py line 24 in swig_import_helper    _mod = imp.load_module _pywrap_tensorflow  fp pathname description  file /usr/lib/python3.4/imp.py line 243 in load_module    return load_dynamicname filename fileimporterror /opt/xilinx/vivado/2015.1/lib/lnx64.o/libstdc++.so.6 version `glibcxx_3.4.19  not found required by /usr/local/lib/python3.4/dist-packages/tensorflow/python/_pywrap_tensorflow.so  during handling of the above exception another exception occurred  traceback most recent call last:  file image_resize.py line 10 in     import tensorflow as tf  file /usr/local/lib/python3.4/dist-packages/tensorflow/ init .py line 24 in     from tensorflow.python import *  file /usr/local/lib/python3.4/dist-packages/tensorflow/python/ init .py line 72 in     raise importerrormsgimporterror traceback most recent call last:  file /usr/local/lib/python3.4/dist-packages/tensorflow/python/ init .py line 61 in     from tensorflow.python import pywrap_tensorflow  file /usr/local/lib/python3.4/dist-packages/tensorflow/python/pywrap_tensorflow.py line 28 in     _pywrap_tensorflow = swig_import_helper  file /usr/local/lib/python3.4/dist-packages/tensorflow/python/pywrap_tensorflow.py line 24 in swig_import_helper    _mod = imp.load_module _pywrap_tensorflow  fp pathname description  file /usr/lib/python3.4/imp.py line 243 in load_module    return load_dynamicname filename fileimporterror /opt/xilinx/vivado/2015.1/lib/lnx64.o/libstdc++.so.6 version `glibcxx_3.4.19  not found required by /usr/local/lib/python3.4/dist-packages/tensorflow/python/_pywrap_tensorflow.so  failed to load the native tensorflow runtime  see  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error   for some common reasons and solutions  include the entire stack traceabove this error message when asking for help  i am using ubuntu 14.4and python version 3.4 it looks like you installed xilinx which includes an older version of libstdc++ if you remove it from your   that should solve the issue  i m using ubuntu 14.4 with python 3.5 i run the following and the python3 shell imported tensorflow perfectly fine,6,0.9829554492370193,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
48506055_so,"tensorflow this exception comes while install tensorflow 1.3.0 i am getting this error while installing tensorflow 1.3.0 in the terminal of mac   traceback most recent call last:  file /library/frameworks/python.framework/versions/2.7/lib/python2.7/site-packages/pip/basecommand.py line 215 in main    status = self.runoptions args  file /library/frameworks/python.framework/versions/2.7/lib/python2.7/site-packages/pip/commands/install.py line 342 in run    prefix=options.prefix_path,  file /library/frameworks/python.framework/versions/2.7/lib/python2.7/site-packages/pip/req/req_set.py line 784 in install    **kwargs  file /library/frameworks/python.framework/versions/2.7/lib/python2.7/site-packages/pip/req/req_install.py line 851 in install    self.move_wheel_filesself.source_dir root=root prefix=prefix  file /library/frameworks/python.framework/versions/2.7/lib/python2.7/site-packages/pip/req/req_install.py line 1064 in move_wheel_files    isolated=self.isolated,  file /library/frameworks/python.framework/versions/2.7/lib/python2.7/site-packages/pip/wheel.py line 345 in move_wheel_files    clobbersource lib_dir true  file /library/frameworks/python.framework/versions/2.7/lib/python2.7/site-packages/pip/wheel.py line 323 in clobber    shutil.copyfilesrcfile destfile  file /library/frameworks/python.framework/versions/2.7/lib/python2.7/shutil.py line 97 in copyfile    with opendst  wb  as fdst:ioerror [errno 13] permission denied  /library/frameworks/python.framework/versions/2.7/lib/python2.7/site-packages/backports/weakref.py ",6,0.9816433726419003,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
55993754_so,"python-3.x tensorflow importerror libcublas.so.10.0 cannot open shared object file no such file or directory i am getting tensorflow import errot i have tensorflow version 1.13 cuda version 10.1 the entire stack trace is as follow        traceback most recent call last   file  /home/danyial/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py,  line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *   file /home/danyial/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py,  line 28 in       _pywrap_tensorflow_internal = swig_import_helper   file /home/danyial/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py,  line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description   file /usr/lib/python3.6/imp.py line 243,  in load_module      return load_dynamicname filename file   file /usr/lib/python3.6/imp.py line 343 in load_dynamic      return _loadspec importerror libcublas.so.10.0 cannot open shared object file no such file or directory      during handling of the above exception another exception occurred      traceback most recent call last   file  line 1 in     file  /home/danyial/.local/lib/python3.6/site-packages/tensorflow/ init .py,  line 24 in       from tensorflow.python import pywrap_tensorflow  # pylint disable=unused-import   file  /home/danyial/.local/lib/python3.6/site-packages/tensorflow/python/ init .py,  line 49 in       from tensorflow.python import pywrap_tensorflow   file /home/danyial/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py,  line 74 in       raise importerrormsg importerror traceback most recent call last   file  /home/danyial/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py,  line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *   file /home/danyial/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py,  line 28 in       _pywrap_tensorflow_internal = swig_import_helper   file /home/danyial/.local/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py,  line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description   file /usr/lib/python3.6/imp.py line 243,  in load_module      return load_dynamicname filename file   file /usr/lib/python3.6/imp.py line 343 in load_dynamic      return _loadspec importerror libcublas.so.10.0 cannot open shared object file no such file or directory      failed to load the native tensorflow runtime ",6,0.9812804042043078,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
44558198_so,"python-3.x tensorflow tensorflow importerror on windows cmd i have installed python 3.5.2 and installed tensorflow throght the command pip3 install tensorflow --upgradeafter the installation finished i try to import the tensorflow but failed the error report is as follow how to fix this problem?                           import tensorflow traceback most recent call last   file c:\python\python352\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,        line 18 in swig_import_helper            return importlib.import_modulemname   file c:\python\python352\lib\importlib__init__.py line 126 in        import_module            return _bootstrap._gcd_importname[level:] package level   file  line 986 in _gcd_import   file         line 969 in _find_and_load   file         line 958 in _find_and_load_unlocked         file  line 666 in _load_unlocked         file  line 577 in module_from_spec         file  line 906 in        create_module   file  line 222 in        _call_with_frames_removed importerror dll load failed 找不到指定的模块。could not find the moudle                     during handling of the above exception another exception occurred      traceback most recent call last   file  c:\python\python352\lib\site-packages\tensorflow\python\pywrap_tensorflow.py,  line 41 in       from tensorflow.python.pywrap_tensorflow_internal import *   file c:\python\python352\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 21 in       _pywrap_tensorflow_internal = swig_import_helper   file c:\python\python352\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 20 in swig_import_helper      return importlib.import_module _pywrap_tensorflow_internal    file c:\python\python352\lib\importlib__init__.py line 126 in  import_module      return _bootstrap._gcd_importname[level:] package level importerror no module named  _pywrap_tensorflow_internal       during handling of the above exception another exception occurred      traceback most recent call last   file  line 1 in     file  c:\python\python352\lib\site-packages\tensorflow__init__.py line  24 in       from tensorflow.python import *   file c:\python\python352\lib\site-packages\tensorflow\python__init__.py,  line 51 in       from tensorflow.python import pywrap_tensorflow   file c:\python\python352\lib\site-packages\tensorflow\python\pywrap_tensorflow.py,  line 52 in       raise importerrormsg importerror traceback most recent call last   file  c:\python\python352\lib\site-packages\tensorflow\python\pywrap_tensorflo  w_internal.py line 18 in swig_import_helper      return importlib.import_modulemname   file c:\python\python352\lib\importlib__init__.py line 126 in  import_module      return _bootstrap._gcd_importname[level:] package level   file  line 986 in _gcd_import   file   line 969 in _find_and_load   file   line 958 in _find_and_load_unlocked   file  line 666 in _load_unlocked   file  line 577 in module_from_spec   file  line 906 in  create_module   file  line 222 in  _call_with_frames_removed importerror dll load failed 找不到指定的模块。could not find the moudle      during handling of the above exception another exception occurred      traceback most recent call last   file  c:\python\python352\lib\site-packages\tensorflow\python\pywrap_tensorflo  w.py line 41 in       from tensorflow.python.pywrap_tensorflow_internal import *   file c:\python\python352\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 21 in       _pywrap_tensorflow_internal = swig_import_helper   file c:\python\python352\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py,  line 20 in swig_import_helper      return importlib.import_module _pywrap_tensorflow_internal    file c:\python\python352\lib\importlib__init__.py line 126 in  import_module      return _bootstrap._gcd_importname[level:] package level importerror no module named  _pywrap_tensorflow_internal       failed to load the native tensorflow runtime ",6,0.9812503491106694,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
139085_kg,i think it is common error of all versions of covid_19_data.csvduplicate records                             row 4749 and 4927 for hebei province 11th march  row 4927 has 0 as data                             row 4966 and 5148 for hebei province 12th march  row 5148 has 0 as data                             row 4766 and 4926 for gansu province 11th march  row 4926 has 0 as data                             row 4984 and 5147 for gansu province 12th march  row 5147 has 0 as datadata errorrow 8105    23-mar-20   french polynesia    france  19874   860 2200 the numbers appear to be for mainland france not french polynesia  cumulative confirmed cases for the following less than those reported on previous dayrow         date                 province   country74          23-jan-20       japan480         31-jan-20   queensland  australia606         02-feb-20   queensland  australia940         07-feb-20       japan2283    24-feb-20   lackland tx from diamond princess    us2284    24-feb-20   omaha ne from diamond princess   us2285    24-feb-20   travis ca from diamond princess  us2815    29-feb-20   from diamond princess   australia3580    06-mar-20   diamond princess cruise ship    others3764    06-mar-20   northern territory  australia3854    07-mar-20   new york county ny us4198    08-mar-20   fairfield county ct    us4447    09-mar-20       saint barthelemy4487    09-mar-20   rockingham county nh   us4622    10-mar-20       russia4935    11-mar-20       occupied palestinian territory5235    13-mar-20       bahrain5914    16-mar-20       japan5973    16-mar-20       lebanon6042    16-mar-20   grand princess  us6055    16-mar-20       azerbaijan6093    16-mar-20   french guiana   france6434    17-mar-20       guernsey6435    17-mar-20       jersey6436    17-mar-20       puerto rico6437    17-mar-20       republic of the congo6459    18-mar-20   washington  us6518    18-mar-20   guizhou mainland china6566    18-mar-20   nevada  us6701    18-mar-20       montenegro6713    18-mar-20   french guiana   france6714    18-mar-20   guadeloupe  france6715    18-mar-20   mayotte france6716    18-mar-20   reunion france6717            18-mar-20       guam6722    18-mar-20       the gambia7007    19-mar-20       greenland7013    19-mar-20       the bahamas7149    20-mar-20   utah    us8111            23-mar-20   grand princess  us8274    24-mar-20       guyana8681    25-mar-20   alberta canada  cumulative reported deaths for the following less than those reported on previous dayrow         date                province country4530    10-mar-20       japan4575    10-mar-20   new south wales australia5941    16-mar-20       iceland6796    19-mar-20       philippines7067    20-mar-20       iceland7383    21-mar-20       india7479    21-mar-20       kazakhstan7750    22-mar-20       slovakia7881    22-mar-20   quebec  canada8719    25-mar-20   hawaii  us  cumulative reported recoveries for the following less than those reported on previous dayrow         date                province country648         03-feb-20   shanxi  mainland china860         06-feb-20   guizhou mainland china1080    09-feb-20   ningxia mainland china1207             11-feb-20  heilongjiang    mainland china1286    12-feb-20   guangxi mainland china1511            15-feb-20   hainan  mainland china1976    21-feb-20   hong kong   hong kong2119            23-feb-20   diamond princess cruise ship    others2216    24-feb-20       italy3995    08-mar-20       south korea4569    10-mar-20       iraq4572    10-mar-20       egypt5273    13-mar-20       andorra5702    15-mar-20       egypt5941    16-mar-20       iceland6176    17-mar-20       austria6459    18-mar-20   washington  us6465    18-mar-20   california  us6488    18-mar-20   new jersey  us6500    18-mar-20   massachusetts   us6514    18-mar-20   illinois    us6541    18-mar-20   wisconsin   us6544    18-mar-20   maryland    us6603    18-mar-20   arizona us6604    18-mar-20   kentucky    us6770    19-mar-20       poland7027    20-mar-20       belgium7458    21-mar-20       sri lanka7685    22-mar-20       iceland7766    22-mar-20       togo7767    22-mar-20       trinidad and tobago7791    22-mar-20   british columbia    canada7875    22-mar-20   ontario canada7925    23-mar-20       azerbaijan8054    23-mar-20       sri lanka8121    23-mar-20   heilongjiang    mainland china8213    24-mar-20       algeria8332    24-mar-20       poland,8,0.9807881001931891,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
53496913_so,"nvidia python tensorflow ubuntu-18.04 import error tensorflow-gpu in ubuntu18.04 i m getting some error while importing tensorflow  my computer s specifications  os:ubuntu 18.04  nvidia rtx 2080 ti*2   nvidia driver-415  cuda：10.0  cudnn：7.3.0tensorflow：1.11.0   error     traceback most recent call last   file  /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py,  line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *   file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py,  line 28 in       _pywrap_tensorflow_internal = swig_import_helper   file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py,  line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description   file /usr/lib/python3.6/imp.py line 243,  in load_module      return load_dynamicname filename file   file /usr/lib/python3.6/imp.py line 343 in load_dynamic      return _loadspec importerror libcublas.so.9.0 cannot open shared object file no such file or directory      during handling of the above exception another exception occurred      traceback most recent call last   file  line 1 in     file  /usr/local/lib/python3.6/dist-packages/tensorflow/ init .py line  22 in       from tensorflow.python import pywrap_tensorflow  # pylint disable=unused-import   file  /usr/local/lib/python3.6/dist-packages/tensorflow/python/ init .py,  line 49 in       from tensorflow.python import pywrap_tensorflow   file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py,  line 74 in       raise importerrormsg importerror traceback most recent call last   file  /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py,  line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *   file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py,  line 28 in       _pywrap_tensorflow_internal = swig_import_helper   file /usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py,  line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description   file /usr/lib/python3.6/imp.py line 243,  in load_module      return load_dynamicname filename file   file /usr/lib/python3.6/imp.py line 343 in load_dynamic      return _loadspec importerror libcublas.so.9.0 cannot open shared object file no such file or directory      failed to load the native tensorflow runtime      see   https://www.tensorflow.org/install/install_sources#common_installation_problems       for some common reasons and solutions  include the entire stack trace  above this error message when asking for help   i already tried to use ubuntu 16.04 ,but gpu didn t support.installation of cuda9.0 &amp cuda9.2 was not supported too  how can i use tensorflow-gpu?  i already app path in ~/.bashrc the   package is built against cuda 9.0 but you have cuda 10.0 installed   you need either to downgrade your version of cuda to 9.0 but if i recall that s not possible with a 2080ti or build tensorflow from the sources there is extensive documentation on how to do so on the  tensorflow webiste   you can also try to install the package   you should note that this version is more experimental though as it has not been tested as extensively",6,0.9806836965154371,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
52992595_so,python python-3.x tensorflow fail to import tensorflow on windows i am using windows10 python 3.6 without anaconda i was trying to install tensorflow for my gtx1060.after installing it i found that i cannot import tensorflow and the error message as followed traceback most recent call last:  file c:\program files\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in     from tensorflow.python.pywrap_tensorflow_internal import *  file c:\program files\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in     _pywrap_tensorflow_internal = swig_import_helper  file c:\program files\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper    _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description  file c:\program files\python36\lib\imp.py line 243 in load_module    return load_dynamicname filename file  file c:\program files\python36\lib\imp.py line 343 in load_dynamic    return _loadspecimporterror dll load failed 找不到指定的模块。  during handling of the above exception another exception occurred  traceback most recent call last:  file  line 1 in   file c:\program files\python36\lib\site-packages\tensorflow__init__.py line 22 in     from tensorflow.python import pywrap_tensorflow  # pylint disable=unused-import  file c:\program files\python36\lib\site-packages\tensorflow\python__init__.py line 49 in     from tensorflow.python import pywrap_tensorflow  file c:\program files\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 74 in     raise importerrormsgimporterror traceback most recent call last:  file c:\program files\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in     from tensorflow.python.pywrap_tensorflow_internal import *  file c:\program files\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in     _pywrap_tensorflow_internal = swig_import_helper  file c:\program files\python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper    _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description  file c:\program files\python36\lib\imp.py line 243 in load_module    return load_dynamicname filename file  file c:\program files\python36\lib\imp.py line 343 in load_dynamic    return _loadspecimporterror dll load failed 找不到指定的模块。  failed to load the native tensorflow runtime  see  https://www.tensorflow.org/install/install_sources#common_installation_problems   for some common reasons and solutions  include the entire stack traceabove this error message when asking for help ,6,0.9806278619504326,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
54089127_so,tensorflow importerror dll load failed the specified module could not be found ... i found this error while installing tensorflow gpu python 3.5.6 |anaconda inc.| default aug 26 2018 16:05:27 [msc v.1900 64 bit amd64] on win32type help copyright credits or license for more information                 import tensorflow      traceback most recent call last:        file c:\users\amit\appdata\local\continuum\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in           from tensorflow.python.pywrap_tensorflow_internal import *        file c:\users\amit\appdata\local\continuum\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in           _pywrap_tensorflow_internal = swig_import_helper        file c:\users\amit\appdata\local\continuum\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper          _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description        file c:\users\amit\appdata\local\continuum\anaconda3\envs\tensorflow\lib\imp.py line 243 in load_module          return load_dynamicname filename file        file c:\users\amit\appdata\local\continuum\anaconda3\envs\tensorflow\lib\imp.py line 343 in load_dynamic          return _loadspec      importerror dll load failed the specified module could not be found           during handling of the above exception another exception occurred  traceback most recent call last:  file  line 1 in   file c:\users\amit\appdata\local\continuum\anaconda3\envs\tensorflow\lib\site-packages\tensorflow__init__.py line 24 in     from tensorflow.python import pywrap_tensorflow  # pylint disable=unused-import  file c:\users\amit\appdata\local\continuum\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python__init__.py line 49 in     from tensorflow.python import pywrap_tensorflow  file c:\users\amit\appdata\local\continuum\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 74 in     raise importerrormsgimporterror traceback most recent call last:  file c:\users\amit\appdata\local\continuum\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in     from tensorflow.python.pywrap_tensorflow_internal import *  file c:\users\amit\appdata\local\continuum\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in     _pywrap_tensorflow_internal = swig_import_helper  file c:\users\amit\appdata\local\continuum\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper    _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description  file c:\users\amit\appdata\local\continuum\anaconda3\envs\tensorflow\lib\imp.py line 243 in load_module    return load_dynamicname filename file  file c:\users\amit\appdata\local\continuum\anaconda3\envs\tensorflow\lib\imp.py line 343 in load_dynamic    return _loadspecimporterror dll load failed the specified module could not be found ,6,0.9804373166156016,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
53077429_so,anaconda python-3.6 tensorflow error when importing tensorflow importerror dll load failed the specified module could not be found system information   win10  python 3.6.2  tensorflow 1.11.0  numpy 1.15.3  conda 4.3.30  cuda 8.0  cudnn 6.0  pip 18.1  i created a new environment with python3.6.2 in anaconda and  installed tensorflow with pip and met with such a problem thanks for help     python 3.6.2 |continuum analytics inc.| default jul 20 2017 12:30:02 [msc v.1900 64 bit amd64] on win32  type help copyright credits or license for more information           import tensorflow as tf         traceback most recent call last:    file c:\users\szf\appdata\roaming\python\python36\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *    file c:\users\szf\appdata\roaming\python\python36\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in       _pywrap_tensorflow_internal = swig_import_helper    file c:\users\szf\appdata\roaming\python\python36\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description    file i:\anaconda\envs\envpytf\lib\imp.py line 242 in load_module      return load_dynamicname filename file    file i:\anaconda\envs\envpytf\lib\imp.py line 342 in load_dynamic      return _loadspec  importerror dll load failed 找不到指定的模块。      during handling of the above exception another exception occurred      traceback most recent call last:    file  line 1 in     file c:\users\szf\appdata\roaming\python\python36\site-packages\tensorflow__init__.py line 22 in       from tensorflow.python import pywrap_tensorflow  # pylint disable=unused-import    file c:\users\szf\appdata\roaming\python\python36\site-packages\tensorflow\python__init__.py line 49 in       from tensorflow.python import pywrap_tensorflow    file c:\users\szf\appdata\roaming\python\python36\site-packages\tensorflow\python\pywrap_tensorflow.py line 74 in       raise importerrormsg  importerror traceback most recent call last:    file c:\users\szf\appdata\roaming\python\python36\site-packages\tensorflow\python\pywrap_tensorflow.py line 58 in       from tensorflow.python.pywrap_tensorflow_internal import *    file c:\users\szf\appdata\roaming\python\python36\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 28 in       _pywrap_tensorflow_internal = swig_import_helper    file c:\users\szf\appdata\roaming\python\python36\site-packages\tensorflow\python\pywrap_tensorflow_internal.py line 24 in swig_import_helper      _mod = imp.load_module _pywrap_tensorflow_internal  fp pathname description    file i:\anaconda\envs\envpytf\lib\imp.py line 242 in load_module      return load_dynamicname filename file    file i:\anaconda\envs\envpytf\lib\imp.py line 342 in load_dynamic      return _loadspec  importerror dll load failed 找不到指定的模块。      failed to load the native tensorflow runtime maybe try installing it with conda tensorflow   tensorflow-gpu,6,0.9797318000027528,"0.076*""tensorflow"" + 0.065*""python"" + 0.025*""file"" + 0.022*""version"" + 0.021*""error"" + 0.020*""py"" + 0.020*""install"" + 0.019*""instal"" + 0.017*""run"" + 0.016*""line"""
128782_kg,top five youtube channels to learn machine learning https://www.youtube.com/watch?v=i0mtzctxxyq   machine learning tutorial videos https://www.youtube.com/playlist?list=pleieaq2vkuulyygj13yhuwmrepqiu8ddy   machine learning basics https://www.youtube.com/watch?v=ukzfi9rgwfu   machine learning by andrew ng https://www.youtube.com/watch?v=pplop4l2egk&amp;list=pllsst5z_dsk-h9vyzkqkynwcitqhlrjln   machine learning full course  https://www.youtube.com/watch?v=gwio3gdzcvq   a friendly introduction to machine learning https://www.youtube.com/watch?v=ipgxlwoizy4   artificial intelligence full course https://www.youtube.com/watch?v=jmuxmlyrhsk   the seven steps of machine learning https://www.youtube.com/watch?v=nkw8ndu7mjw   how to learn machine learning in 2020 https://www.youtube.com/watch?v=hzmeaw3mwd0   mathematics for machine learning - full course https://www.youtube.com/watch?v=t3tpdpmtlso bonus learn machine learning in three months with curriculum https://www.youtube.com/watch?v=cr6vqtro1v0,22,0.9721914812371244,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
74684_kg,"nice plots nitin :   thank you :d   awesome kernel.. very informative!   thank you so much    hi nitin @nitindatta! nice visualizations upvoted your kernel!  i have also recently created  my new titanic kernel  could you please upvote it if you find it interesting? =   i am also trying to reach the discussion expert level and would greatly appreciate if you upvote this comment ;    thank you pavlo i will surely check out your kernel    thank you for sharing very insightful and great visualizations    thank you for the kind words,please check out my other kernels and upvote them if you like them.cheers!!   very good kernel upvoted :   thank you @ nhlr   please check out my other kernels at  https://www.kaggle.com/nitindatta/kernels  and support if you find them of good quality    very good visualization buddy...!!   thanks mate could you check out my other kernels and support them too.it would be of great help   very good! congratulations! i learned  this your job :d   thanks @ lucas  check out my other kernels at   https://www.kaggle.com/nitindatta/kernels  and support with an upvote if you like them   great visualizations !!   thank you    great job!   thank you   sure buddy   cool visualizations thanks for sharing!   you’re welcome mate",16,0.9683684014505938,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
37191818_so,apache-spark bigdata hadoop scala is it possible to execute tasks on the namenode i am using spark with hdfs and yarn so basically spark running on hadoop i use the yarn-client mode to run tasks on the cluster by default the tasks execute on the data nodes of the cluster however i would also like the namenode to execute some tasks as it sits idle all the time so is it possible to also have the namenode execute some of the tasks? if so how to be more specific spark tasks are not running on datanodes when running spark on hadoop the tasks are executed on the nodemanagers which are the execution units in hadoop/yarn cluster runniong on each slave node on hadoop/yarn cluster but in general in hadoop/yarn cluster on each slave node there are the two processes datanode and nodemanager  the equivalent of namenode the master of datanodes with nodemanager is the resourcemanager which is the master of nodemanagers  the namenode/resourcemanager themselves could not execute any task they are just the master processes which manage the slaves datanode and nodemanagers respectivelym unless you have started nodemanager process on the same host running the namenode or resourcemanager  if you mean by namenode the physical node where the namenode process starts yes you could as soon as you start the nodemanager process on that node,15,0.9683511396923928,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
72908_kg,!   nice job    thanks   great   thanks   !   good job   thx   nice kernel @frtgnn    thanks   amazing work ✌️✌️   thanks friend   thanks for sharing 👍    nice and precise    thanks for sharing   aciklayici bir calisma olmus ellerinize saglik! @frtgnn    ilginiz ve zamaniniz icin cok tesekkurler  @fatihbilgin      thanks for sharing...!! @frtgnn    amazing work...!! @frtgnn    thank you very much   great   thanks   thanks   thanks   nice work!   thanks a lot!   amazing kaggle notebook firat i appreciated a lot of the illustrations   thank you so much  @mpwolke     i m gonna visit some of your works i was playing with rock paper or scissors   appreciate it!   great job !   thanks   amazing stuff..thanks for sharing..   thanks a lot  @ajnasaju     awesome kernel congratulations.bütün kernellerinizi inceledim birçok şey öğrendim teşekkür ederim :   ben tesekkur ederim   great job thanks!   thank you very much  @tejashshah     very useful content thank you!   appreciate it  @olavomendes   happy to help   thank you!   thank you! as always really good   👍    thanks for checking my notebook,16,0.9677760604567,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
48006_kg,hi dear experts  i m a techie guy who works in banking applications as systems analyst  i have good knowledge in business intelligence &amp planning to focus my career in data science  please help me to get succeed  thanks for the help   get started with statistics basics along with python and r    learning data science can be intimidating especially when you are just beginning your adventure.which language to use? what techniques to focus on? how much statistics to learn? do i need to learn to code? these are some of the many questions you need to answer as part of your journey as you have mentioned you are a techie guy it won t be very much difficult for you to begin in data science.i would suggest going to the following links and get a firm idea about how to start the data science  tips for starting career in data science  https://www.analyticsvidhya.com/blog/2017/10/tips-people-starting-career-data-science/   data science plan  https://www.analyticsvidhya.com/blog/2017/01/the-most-comprehensive-data-science-learning-plan-for-2017/   good way to start data science and resources  https://www.quora.com/what-are-good-ways-to-get-started-with-data-science-for-a-complete-novice   all the best on your adventure in data science feel free to ask any questions thank you   in addition to what they said you can also consider kaggle learn  https://www.kaggle.com/learn/overview,22,0.9671604296439384,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
27206_kg,"am a final year student of statistics i want to learn data analysis but i dont know where to start from should i start learning all those tools? r,python  spss   sas ??    please i need help  thank you   hey amaka i m also new to data analysis and have been searching around to see what s next i just finished an online data analysis circuit that taught the basics of excel and sql as well as best practices on how to gather prepare analyze and present data i found it pretty useful and there s quite a few platforms that offer these kinds of courses might be a good place to start now i m aiming to learn more about how relational databases work and then move into r and python best of luck!     http://cs109.github.io/2015/  - this might be a good place to start they use python which is pretty easy to pick up but it might be good to do an online course maybe on coursera or codecademy to learn some basics before starting on cs109   thanks . i took your advice and have started learning excel online  what link did you do the analysis circuit pls can i get your email address? so i can follow as you lead do what you do. i know its a burden but i really want to learn    i also started a course  audit on coursera data scientist s tools . thanks again   thanks!!! pls what basics are you talking about? excel and what else   although i just started  an audit course with coursera  data scientist s tools and the week 2 said something about the gits you just mentioned .    hi amaka,you can try  [1] www.udacity.com [2] www.coursera.org[3] www.edx.org  many courses and almost free instructors come big company like google facebook or top universities you can find everything you need to start your journey  nice to meet you!   hie amaka  i also started with data science couple of weeks back i refered to udemy videos on data science and machine learning with python he has explained things hands on this should definetely help",22,0.9665022418423113,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
65379_kg,can someone post md5 hashes for the train_[0-9a-f].tar.gz archives to be sure everything was downloaded properly?   not sure mine md5 is valid   08200b7f4d9f3032b69c5263f4f10782 train_0.tar.gz  184de5278017c27ae4d713f50230fc65 train_1.tar.gz  12e1ba3c791bb055be865858f4e473ff train_2.tar.gz  5ea000fa99d15a5d6d943f08dd1b8577 train_3.tar.gz  3102489fcc78038c2f4ca41a8e3e8983 train_4.tar.gz  e12f0d81b151b18a969bbf7226d162fa train_5.tar.gz  3430610cf4c09969300dd8b377dbda55 train_6.tar.gz  df7e55855ee58b14c55d28127a2c9abe train_7.tar.gz  23177befe2d5228c5609ffa28ca7bff6 train_8.tar.gz  0ba1067a99c1fc51d112c231bc56e05a train_9.tar.gz  71b2d36033164c32d2757d62e791081a train_a.tar.gz  c08d4b0bcd759902c785299002d278e5 train_b.tar.gz  0a45811ad31e3102301efb9868d7a3eb train_c.tar.gz  bdf3989658e8a714c23074998853b5a6 train_d.tar.gz  13c7e0d6342126a64808848357960c5d train_e.tar.gz  b682bc1851c26771c84ac6545f61a1d0 train_f.tar.gz    these are the md5 hashes for the folders to be downloaded  08200b7f4d9f3032b69c5263f4f10782  train_0.tar.gz  184de5278017c27ae4d713f50230fc65  train_1.tar.gz  12e1ba3c791bb055be865858f4e473ff  train_2.tar.gz  5ea000fa99d15a5d6d943f08dd1b8577  train_3.tar.gz  3102489fcc78038c2f4ca41a8e3e8983  train_4.tar.gz  e12f0d81b151b18a969bbf7226d162fa  train_5.tar.gz  3430610cf4c09969300dd8b377dbda55  train_6.tar.gz  df7e55855ee58b14c55d28127a2c9abe  train_7.tar.gz  23177befe2d5228c5609ffa28ca7bff6  train_8.tar.gz  0ba1067a99c1fc51d112c231bc56e05a  train_9.tar.gz  71b2d36033164c32d2757d62e791081a  train_a.tar.gz  c08d4b0bcd759902c785299002d278e5  train_b.tar.gz  0a45811ad31e3102301efb9868d7a3eb  train_c.tar.gz  bdf3989658e8a714c23074998853b5a6  train_d.tar.gz  13c7e0d6342126a64808848357960c5d  train_e.tar.gz  b682bc1851c26771c84ac6545f61a1d0  train_f.tar.gz,4,0.9660933309853079,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
1398_kg,"任务一几乎是每个sns网站都会遇到的问题：）   求大神带下 需要用到什么方面的知识 刚接触   有多少大神参加啊？   请问下这个推荐是只推荐名人吗？不能推荐普通人？我看数据集给的数据好像只有名人啊   items are organized in categories so i think it must be vip users   买看懂它的evaluation，谁帮忙解释一下啊？？？   that is to say an item is a user,but a user may not be an item.what to be recommended is not every user in the system,but those belong to vip user,who has the category information.is that?    请问“ 关注历史 ”是不是按时间排序的？ 文件中貌&#20284;是按id从小到大的顺序   birth gender,,,,&nbsp   [quote=sw072;8913]   请问“ 关注历史 ”是不是按时间排序的？ 文件中貌&#20284;是按id从小到大的顺序  [/quote]  并不保证按特定的顺序   [quote=yanzhi;8984]  [quote=sw072;8913]   请问“ 关注历史 ”是不是按时间排序的？ 文件中貌&#20284;是按id从小到大的顺序  [/quote]  并不保证按特定的顺序  [/quote]  文中用了“follow history”一词，以为是时间序的，那只能算是followship的一个snapshot了，要是有follow的时间就好了。   [quote=sw072;8997]  [quote=yanzhi;8984]  [quote=sw072;8913]   请问“ 关注历史 ”是不是按时间排序的？ 文件中貌&#20284;是按id从小到大的顺序  [/quote]  并不保证按特定的顺序  [/quote]  文中用了“follow history”一词，以为是时间序的，那只能算是followship的一个snapshot了，要是有follow的时间就好了。  [/quote]  是。文档也在逐渐修正这些问题。  由于一些历史原因，follow时间确实无法提供",8,0.963354153501576,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
20689_kg,here i defined three different kinds of names.1 used over 15000 times i call it over-populated name.2 used over 1000 times exclude over 15000 times i call it normal name.3 used less than 500 times i call it unique name  from the figures we noticed that all three kind of names are sensitive to the increasing of population   interesting thing starts to happen around 1940s to 1960s we can see a huge population increasing during this period of time corresponding to this change in population three kinds of name has different reaction first we can see that over-populated name has a 3-time increasing in number while population is just a 2-time increasing however when we look at the normal name it keeps a similar scale of increasing as population the most interesting thing is that during this period of time unique name is a little bit decreased in number based on the background of this period of time my best guessing is that people s life during this time is pretty hard a couple may have several kids but they don t have too much energy to take care of their kids when it reflects on the baby names parents are more usual to pick up a over-populated name for their kids  things got a 180 degree change after 1980s at this time the new born baby stop to increase but keep a relatively stable number at the same time over-populated name has a sharp decreasing while normal name and unique name start to become trend among them the increasing in unique name is pretty huge it almost went up 300% with equal or little decreased number of new born baby to explain that we could also get some idea from the background after 1980s there is a long and peaceful time for people no wars no hunger people s life becoming stable and affluent this kind of life give people more time and energy to focusing on themselves and their own family as a result parents pay much more attention to pick a beautiful and unique name for their baby,10,0.9619189496428503,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
130133_kg,"this is a forum to write expectations on wids workshop   understanding better ways of solving data science problems   i want to learn ml   i want to lean machine learning,deep learning   excited to attend the wids workshop   want to learn ml   learn something new and interesting   i want to learn ml   i want to learn ml   hey i want to learn artificial intelligence   i want to learn ml   i want to learn ml   i want to learn ml   want to learn ml   attended to learn ml🙌    i wish to learn ethical hacking and become an ethical hacker   i want to learn deep learning   expecting better visualization of data science   i want to learn ml   i want to learm ml   i want to learn machine learning i hope this platform would help   i want to learn ml   abc   hey   i want to learn machine learning   want to learn ml and deep learning   i want to learn ml   i wanted to learn machine learning   i would like to learn ml   i want to learn machine learning   to learn ml   i want to learn ml   machine learning    to learn machine learning and data science    i want to learn machine learning   i want to learn ml   machine learning   got the knowledge of data science   heyyyyy   i want to  learn python   i want to learn machine learning   i want to learn python",22,0.9609599130862881,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
22456_kg,unify rule1   ex chinese -&gt china  ex french -&gt france  count rank nation frequency  1   1   haiti   2097  2   2   libya   1993  3   3   israel  1738  4   4   china   1661  5   5   iran    1596  6   6   pakistan    1549  7   7   afghanistan 1293  8   8   palestinian territories 954  9   9   iraq    922  10  10  egypt   735  11  11  russia  719  12  12  france  567  13  13  india   524  14  14  saudi arabia    489  15  14  turkey  489  16  16  honduras    475  17  17  brazil  466  18  18  armenia 341  19  19  north korea 336  20  20  colombia    321  21  21  germany 315  22  22  mexico  307  23  23  sudan   284  24  24  italy   255  25  24  syria   255  26  26  canada  254  27  27  greece  252  28  28  japan   240  29  28  cuba    240  30  30  spain   236  31  31  bangladesh  212  32  32  palau   210  33  33  poland  184  34  34  qatar   181  35  35  somalia 174  36  36  yemen   165  37  37  indonesia   157  38  38  kenya   156  39  38  kyrgyzstan  156  40  40  uganda  151  41  41  sri lanka   136  42  42  venezuela   133  43  43  south korea 129  44  43  argentina   129  45  45  jordan  125  46  46  norway  109  47  47  lebanon 103  48  48  ireland 97  49  49  south africa    96  50  49  australia   96   gegmap -&gt  geomap,8,0.9590525253789807,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
130346_kg,"hi kaggle family  if i want to learn ai what is the best resource which i need to refer?kindly advise me  thanks and reagards,nithin   hi nith_in  there is no single best resource for learning ai   my approach for learning ai is to list down the topics you want to go learn then probably start topic by topic  for example you can  refer1 analytics vidya for starter: https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/     statquest material is also good https://statquest.org/video-index/     you can also refer to online cources and e books:you can try linkedin learning videos or coursera or may be udemy courses as well    the list is exhaustive it depends up to you and your preference   for me i like to follow courses on youtube you have a lot of different options and different tutorials from  stanford online courses  to  icml conference videos  etc there are of course loooots of excellent tutorial and courses by different youtubers you just have to search 😄    dear nith_in,i recommend you to take machine learning course by andrew ng available on coursera 100% free.it helps you have an overview and keys to start dealing with ml techniques  https://www.coursera.org/learn/machine-learning",22,0.9568890594203198,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
59038_kg,"it seems the rule says team mergers are not allowed in this competition but there is at least one merged team in the leaderboard don t anybody read the rules? are merged teams disqualified?   dear hassan,teams are allowed in this competition unfortunately the automatically generated rule page for this competition still had the rule you mentioned i edited the rules page to reflect the correct rules.thank you for your attention and sorry for any inconveniences it may have caused you   wtf  دوستان آدم باید فرق دست راست و چپش رو بدونه بعد مسابقه برگذار کند الان ۲۷ روز از شروع مسابقه میگذره و ظاهرا حتی برگزار کننده های مسابقه هم درست نمی دونن قانون مسابقه دقیقا چیه",17,0.956186200541798,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
49346_kg,"i just joined the competition moments ago the deadline said feb 7th however the website still allowed me to join the competition  would any winning entry unlikely from me be disqualified?   you are allowed to submit only late submission this will not be considered for prizes i guess   hi jeff the deadline feb 7th is for rule acceptance not submission as long as you accepted the rule before feb 7th which seems to be the case for you here otherwise you won t be allowed to join this competition at this time point it doesn t matter when you make your first submission e.g theoretically speaking you could make your 1st submission at the last day of the competition and still win the 1st place prize^_^   kaggle has changed to such a policy to be more friendly to kagglers previously competitors were required to make his/her 1st submission before the merging deadline in order to join the competition   hope this helps  best regards  shize   but he joined after deadline   @naresh jeff mentioned deadline feb 7th which is the deadline for rule acceptance/team merging in this competition not the final deadline when competition ends which would be feb 14th so he should be fine since he has already accepted the competition rules before feb 7th   on the other hand if he made submission after the competition ends feb 14th then the situation would be just as what you said i.e it would be a late submission and not considered for prize  hope this helps   hi shize,one minute i think there is some gap in understanding according to jeff statement the deadline said feb 7th however the website still allowed me to join the competition   it seems rules were accepted after feb 7th if that is correct then jeff will see only late submission button    @naresh my understanding was that jeff accepted the rules before feb 7th but just hadn t made any submissions yet when he said allowed me to join i assume that it meant kaggle still allow him to make regular submission to this competition after feb 7th anyway only jeff himself could clarify which situation he is at   but if he hadn t accepted the rules before feb 7th then indeed he would only be eligible for late submission",17,0.9534948036404973,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
38420_kg,machine learning interview questions and answers   click this link for    machine learning interview questions and answers     thank you interesting   an interesting quora discussion on this   https://www.quora.com/what-are-some-common-machine-learning-interview-questions    overall i think it depends on the interviewer s background and interest the questions can be geared towards computer science statistics or generic product sense   here  http://bit.ly/2zntfxr   found some  interesting machine learning interview questions with answers     http://bit.ly/2irmrfw   i got  bunch of ml interview questions with answers   here is another list real time machine learning interview questions for beginners http://bit.ly/2h2g8up     https://cloudxlab.com/blog/machine-learning-interview-questions-part-1-core-machine-learning     this is great.thanks everyone   here is the updated machine learning interview questions   http://onlinetutorials.today/machine-learning/machine-learning-interview-questions-and-answers/    i have compiled a list of 100+ machine learning questions hope it may be useful for you   https://theprofessionalspoint.blogspot.com/2019/01/100-basic-machine-learning-interview.html    great tutorial   i have created a quiz on machine learning which contains 100+ objective ml questions you may have a look   http://onlinemlquiz.com/    interesting videos! if anyone prefers a written guide i open sourced  my interview guide here    for deep learning interview questions and answers please visit my this article: http://theprofessionalspoint.blogspot.com/2019/06/100-basic-deep-learning-interview.html,22,0.9533180254446828,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
139164_kg,thanks for introducing the pipeline concept excellent kaggle notebook firat   thanks a lot  @mpwolke   it s a work in progress i ll try to add more stuff with more info and comments when i find time appreciate the interest!   really important and useful content for beginners thanks @frtgnn   thank you very much  @olavomendes   will try to make it better   easy guide for such an important concept thank you @frtgnn    thanks it s a work in progress   well explained the concept of pipeline 👍  good job @frtgnn    thanks  @masoudmzb     thank you for sharing   thanks   nice @frtgnn    👍    nice work @frtgnn !!   👍    nice post @frtgnn hope you doing well thanks for share your knowledge...   hope this helps   nice starter pack!   glad you liked it  @podsyp  !   awesome thanks you @frtgnn    👍    thanks for introducing the pipeline concept   thanks for checking out my notebook!   nice work @frtgnn    thanks  @shahules     cool   👍    good one firat !   thanks  @atulanandjha     nice work!   👍    really important and useful content for beginners thanks @frtgnn   ,16,0.9531974162402579,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
48221_kg,please provide me some suggestions on how to get started with data science.i know basics of python and new libraries   learning data science can be intimidating especially when you are just beginning your adventure what techniques to focus on? how much statistics to learn? do i need to learn to code? these are some of the many questions you need to answer as part of your journey.i would suggest going to the following links and get a firm idea about how to start the data science  tips for starting career in data science: https://www.analyticsvidhya.com/blog/2017/10/tips-people-starting-career-data-science/   data science plan: https://www.analyticsvidhya.com/blog/2017/01/the-most-comprehensive-data-science-learning-plan-for-2017/   good way to start data science and resources: https://www.quora.com/what-are-good-ways-to-get-started-with-data-science-for-a-complete-novice   all the best on your adventure in data science feel free to ask any questions.thank you   okay thanks ,22,0.9529440867368659,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
127809_kg,good visualization! plotly is awesome :  i also like visualization and i m making a lot of eda kernels if you like it please upvote    road to viz expert 2 - plotly &amp seaborn     thanks  @subinium   and sure i ll check these out   great and clean visualizations thanks for sharing!   thanks for the appreciation  @xvivancos     nice one!   interesting work!   thanks for appreciation  @ankita17shah     thank you  @michau96     comments are very understandable thankyou for sharing    thank you  @shubhamsemwal   i am happy to contribute !!   спасибо что поделились интересная тема   спасибо я рад внести свой вклад   cool visualizations  liked it !! thanks for sharing .   thanks for appreciation  @holasharma     very impressive visualization  @rajnaruka0698   upvoted!! i am always fan of story telling from visualization  refer my kernel also for this  if you like please up vote https://www.kaggle.com/kushbhatnagar/guidefornewbie-eda-featureeng-modeling-evaluation    thank you for the appreciation  @kushbhatnagar   i sure will check this out,16,0.9528089971457403,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
84701_kg,cv 0.936 lb 0.876.. just learned from microsoft malware a few days ago..   amazing    yes you can trust local validation in this competition    i also think about it....some of my cv got 0.920 but lb only got 0.893....i will choose one best cv score one best lb score as my final score   most everyone has reported that their local cv is within 0.001 to their lb score although some have reported cv a little higher than local scores ex 0.907 cv vs 0.904 lb your cv vs lb difference of ~0.06 indicates that you re overfitting quite a bit probably we obviously won t know until the competition is over so no i wouldn t trust your cv   some of my cv got 0.932 and lb 0.899   amazing   it s definitely  over-fitting.try adding a regularization parameter and set it to a value &gt;0 and see what it gives you.you can test many regularization parameters depending on your model for lightgbm you have lambda_l1 and lambda_l2   good luck!   it seems like cv and lb agree up to a point i ve got a 0.9042 with lower fold to fold sd than the top public kernel but the lb is only in the low 0.900 probably because some of the engineered features generalize poorly to test however the top public kernel has a cv that s pretty close to its lb   there are as many ways to overfit cv as to overfit lb so make it as hard as possible to improve cv score and look for an alignment of cv improvement with lb improvement,14,0.9527560759817836,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
103254_kg,that s a great starter for the competition! thanks for sharing @dataraj !   thanks aleksandra   nice one sir    good one   thanks trinath    thanks  @ganeshnimmala     this is very nice!@dataraj    thanks  @vikumsw     very nice sir   thanks for sharing your knowledge 🙏    it s a nice work @dataraj ! i upvoted!would you please check out my kernel as well?appreciate if you can upvote my kernel as well or give me any recommendation for improvement.thank you!  kernel  https://www.kaggle.com/caesarlupum/speech-recognition-timealignedspectrogramsn interesting approach!✔️    good one!   thanks!   its a nice work   thanks  @caesarlupum  going through your kernel    thanks  @shoaib944     thanks  @dataraj  !    thanks  @jfflfreitas     thanks  @gauravindia,16,0.9517365243321952,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
125871_kg,great visualizations thanks for sharing!!   like this kernel💕  @alenavorushilova   thank you for sharing   good thanks for share! 💯    thank you   thanks   very cool good job!   thank you👍    nice 👍  keep up !   will do👍   very interesting thank you alena👍    upvoted! good kernel and very useful for future references thank you!   you are welcome   good kernel ...............nice visualization... thanks ..off course upvoted   thank you   great viz! .. you can enhance your skills by checking  these top 50 matplotlib visualizations – the master plots    thank you i actually used them i did like them👍    very useful kernel! thanks   good kernel 👍 thanks for sharing   great work!! i m certainly gonna use ir as a resource thank you for sharing the knowledge :   @alenavorushilova excellent visualizations! this notebook can help as a reference to create good visualizations   1 vote from me   hey great work! will be adding some of your matplotlib tips on my kernal,16,0.9515611111020453,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
30128375_so,algorithm maps python clustering algorithms for a set of data points i have a collection of points objects containing latitude and longitude along with a few other irrelevant properties i want to form clusters i.e collections of points that are close together relative to other points   alternatively i would like an algorithm which if given a list of clusters containing close-by points and a new point determines which cluster the new point belongs to and adds it to a new cluster if it doesn t belong to an existing cluster  i looked at hierarchical clustering algorithms but those run too slow the k-means algorithm requires you to know the number of clusters beforehand whcih is not really very helpful  thanks try density based clustering methods.dbscan is one of the most popular of those  i am assuming you are using python check out this   http://scikit-learn.org/stable/modules/generated/sklearn.cluster.dbscan.html    http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html   when you cluster based on gps lat/lon you may want to use a different distance calculation method than dbscan s default use its   parameter to use your own distance calculation function or distance matrix for distance calculations check out,23,0.9514109283744908,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
59028984_so,c++ crop edge-detection image-preprocessing opencv opencv processing - edge detection and cropping how do i remove the irregular white pixels from the preprocessed image  i have tried doing erosion and that would make all pixels black  after preprocessing       requirement       my code   looking for suggestions i m not sure what you mean by removing the irregular white pixels from the preprocessed image but if your goal is to extract a roi of the object then here s an approach   convert image to grayscale and gaussian blur to smooth image  adaptive threshold to obtain a binary image  find contours and filter using contour area  extract the largest contour in the image and crop the roi    here s the result       if you cropped the roi on the thresholded image here s the result       i implemented it in python but you can follow the same steps in c+,20,0.951140767853727,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
74571_kg,beautiful!!!!!   great!   amazing visualizations! will take your kernel as a reference lots to learn from your work thanks for sharing xavier!   great kernel ! nice visualizations as janio said !   thank you so much for kernel :   thank you!! please  @abdullahsahin   upvote if you like it! ^^   yes upvote please! why do so many people forget that ..... :-   hey guys who will learn r after this powerful kernel like me !that s great work ma friend  keep going &lt;3   i love your visualizations a pleasure to read it !   omg! mind-exploded! it s so easy to read and catch your point! love the visual and your work!   great kernel! thanks for sharing xavier! @xvivancos   great visualization thanks for share   thanks for sharing great work!   thank you so much! please  @iorideepp  upvote if you like it ^^   awesome!   excellent work my friend   this is so amazing and beautiful kudos to you @xvivancos    awesome work @xvivancos thanks for sharing!!   thank you so much!! please  @rajeshjnv  upvote if you like it! ^^ if you want  here  you can check the first part! :   already upvoted  @xvivancos  yaa i check your 2nd part also your work is so amazing your very beautiful visualization and excelent explanations make your kernel perfect.thanks for sharing both parts of kernel!!   great kernel!   @xvivancos you never fail to impress us with your kernels!! as it is great kernel :   good kernel!   thanks for sharing   thank you!! please  @snakayama  upvote if you like it! ^^   wow very nice kernel great story telling thanks for sharing!   thank you so much!! please  @frtgnn  upvote if you like it ^^   perfect!   just did sorry i forgot!   this kernel is so interesting thanks for sharing!i like the story and the visualisations are awesome   fabulous work! barcelona has a lot of insights :d   terrific job! and sorry for your wallet! ,16,0.9507530364324334,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
47325813_so,"keras machine-learning nlp tensorflow concatenation of list of 3-dimensional tensors along a specific axis in keras i have written the above snippet where  y_word_max_len  = 9  and  main_decoder  is a tensor of shape none,9,256  and  y_char_max_len  = 7  58 is the size of my outputafter the snippet was excecuted the output was     sub decoder output is  tensorreshape_2/reshape:0 shape=? 1 7,  58 dtype=float32      sub decoder output is  tensorreshape_3/reshape:0 shape=? 1 7,  58 dtype=float32      sub decoder output is  tensorreshape_4/reshape:0 shape=? 1 7,  58 dtype=float32      sub decoder output is  tensorreshape_5/reshape:0 shape=? 1 7,  58 dtype=float32      sub decoder output is  tensorreshape_6/reshape:0 shape=? 1 7,  58 dtype=float32      sub decoder output is  tensorreshape_7/reshape:0 shape=? 1 7,  58 dtype=float32      sub decoder output is  tensorreshape_8/reshape:0 shape=? 1 7,  58  dtype=float32      sub decoder output is  tensorreshape_9/reshape:0 shape=? 1 7,  58  dtype=float32      sub decoder output is  tensorreshape_10/reshape:0 shape=? 1 7,  58 dtype=float32    now i want to concatenate all the tensors 9 thus obtained into a single resultant tensor of    shape ?,9,7,58    how can i achieve that in keras.thanks add a concatenate layer   for that the best is to create a list of the subtensors and use the loop to append to this list",5,0.9494919913972462,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
54424808_so,"image-enhancement image-preprocessing image-processing image-thresholding opencv how to reduce invasive adaptative threshold i m trying to use threshold and other methods in order to clean an image with opencv i have already tried with simple thresholding,adaptive thresholding,otsu’s binarization combined blur median blur gaussian blur bilateralfilter and morphological transformations reduce noise histogram equalization in order to find the best solution..  my best approach was adaptive gaussian thresholding combined with medianblur but i have problems because the thresholding is invasive and cut the letters   raw image         using adaptive gaussian thresholding        as you can see there are cut letters  i found a really good solution but using imageramp of docufi ",20,0.9490408963991236,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
56287_kg,"nice analysis!   thanks xavier 😊   thanks for sharing ankur   welcome ganesh !   very good graphs    hi ankur great visualizations and analysis in r thanks for sharing such a valuable and helpful code    nice explanation!!   thanks arunsankar !   thanks sban ! your maps are awesome !   thanks raj !   great visualizations..very helpful for understanding!!   thanks kartik !   thats why i love r great work!! hoping your feedback on my notebook!!  cheers!   nice graphs   thanks i,coder !   good work!   i m just wowed with the insight i got from reading this  really appreciable work ankur please suggest me how i can also improve my notebook as well. https://www.kaggle.com/nikhilkumar15508/understanding-donor-a-complete-eda    good work especially the last section!!   thanks aashita !    thanks bukun !   thanks ! i will look in sometime and give my suggestion   great work.kindly check my new  kernel  and give feedback or if you like this kernel give upvote.advance thanks",16,0.9482877065300119,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
51166368_so,"python tensorflow tensorflow python how to append a scalar to each row in a tensor if i have a 2-d tensor with the first dimension being dynamic how can i append a scalar value to the end of each row?  so if i feed [[1,2] [3,4]] to a tensor i want to make it [[1,2,5] [3,4,5]]  example doesn t work   this gives me:valueerror can t concatenate scalars use tf.stack instead for  concat_3  op  concatv2  with input shapes [] [?,2] []  i assume this needs some combination of tf.stack tf.tile and tf.shape but i can t seem to get it right here is one way to do it   expand the dimensions on the scalar tensor that you want to append to make it rank 2  use  tf.tile  to repeat the rows  concatenate both tensors along the last axis   for example",5,0.9479778987265502,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
18314_kg,first i d like to thank each and every one of you for your participation it s been a great competition i know some of you asked for the story behind the creation of the competition we will share this with you soon   the results on the leaderboard are final  the leaderboard prize goes to potassium cyanide     the rudolph prize goes to woshialex &amp weezy  with a total of 18.69 days as the top of the leaderboard second place is 16.46 days    if you think you qualify for the xpress prize we want to hear from you!  please send an email to competitions.admin@kaggle.com with your solution and your final ranking on the leaderboard and fico will evaluate your solution please do so before next wednesday 1/13    hello all   after fico s review of the submitted solutions the xpress prize will go to  master.exploder@deepsense.io  congrats!!  for those of you that are interested in the story behind the creation of this competition we have released a new  blog post  about it i hope you enjoy the story,17,0.9471931305936602,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
51869401_so,python tensorflow how does the tensorflow session.run method knows the name of the placeholder variables from the tensorflow tutorial section  https://www.tensorflow.org/guide/low_level_intro#feeding the following code creates the placeholders and assign it to variables  x  and  y  and is passed to the run method   how does the sess.run method know the name of the variables  x  and  y  ie how does the run method know the keys of the feed_dict argument is there a mechanism in the python to figure out the name of the variables  most of objects in tensorflow can be found with a string  when you invoke   tensorflow will do the following   create a node with the   op  add this node to default graph  return the node output tensor   you can set a name for any node say   if you don t specify a node name tensorflow will generate one you can use   to see the name of the op  a tensor is named with the node name plus the output index for example   you will see something like   which is the tensor name  so in you code tensorflow can first get tensor name from   and iterate the default graph to find proper node  you can also use string for feed_dict,7,0.9471116484186858,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
44566_kg,"as all of you have seen! the big gap between public lb and private lb happened  i am really confused now   is it any good advice to select a model with good generalization  how to deal with the relationship among local cv public lb and private lb?    i ended up submitting the stack that yielded highest local cv it was a good choice since it resulted being my 4th best solution on private lb and got me a silver medal it scored better than the one i had with highest public lb which was derived from the mighty kagglemix public kernel which surprisingly scored decently on private too!  however my best single model who had lower cv score than the stack but slightly higher public lb proved to be the best on private  still a silver medal but if i had chosen it i would have been in the top 40   yeah when people mentioned what happened in santander/mercedes i just focused on good cv i still wasted one of my subs on a public kernel mix because of public leaderboard since i got scared if i had submitted my 2nd best stacker i would ve placed almost top 50 so just gonna rely on cv way more than public lb from now on   @den3b  you mean your best single model has a higher public lb than your stack model，ok，my stack model always do better than my single model ,may be my single model has too much room for improving~   yeah best single model which was also included in the stack had fairly lower local cv but slightly higher public and private scores",14,0.9466387361753892,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
9580_kg,"we revealed the &quot;private leaderboard&quot;   congratulations to the winners 1st prize 1st place:&nbsp;antonio sutera arnaud joly,&nbsp;aaron qiu,&nbsp;vincent fran&#231;ois-lavet gilles louppe team aaagv 2nd prize 3rd place ildefons magrans 3rd prize 4th place:&nbsp;lukasz romaszko team lukasz 8000   the second place participants decided not to reveal their code the results of verifications will be available shortly for review sorry for the delay   will you recalculate official kaggle private leaderbard?   no the verifications are only for prize attribution they do not affect the leaderboard",17,0.946605296859281,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
64477_kg,the final medals will be released based on the total team with cheaters removed therefore the number of medals will be less than we currently see your position will move forward if there are cheaters before you but it s also possible that you will lose your medal if you are at the last several positions of medal section since the total team count is reduced don t be happy too early until you receive your medal i lost a silver in avito competition another sad story is in santander competition ended last week.. https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/64166   cheaters are really annoying i bet there are a lot in home credit competition...good luck to you guys!   wow i was overjoyed when i saw that i might win my first bronze in kaggle finished in top 9% after 3 months of work now i m scared i might lose it :/    unfortunately cheaters are always present in competitions nowadays   hi i m new to kaggle i want to know what s the cheaters? why can anyone cheat in this?   usually kaggle cheaters are users who create multiple accounts to have more submission per day and probe the leaderboard   got it! thanks for the clarification!   cheater removal has already started...67 teams have been removed in first 5 hours since the competition closed...7198 teams on lb now...let s see how many more are removed.,17,0.946291186019551,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
126936_kg,wov! great job    @muhammetikbal  thank you very much :   great kernel ratan 👍      @marcovasquez  thank you very much buddy :   awesome visualization great analysis!! @ratan123    great kernel! thanks for sharing!   thank you very much  @tavoosi  !    @veeralakrishna  thanks buddy :   great job! nice descriptions and vizualization.thanks for sharing.it will be interesting for me to look it again in details   great job   thanks  @georgezakharov  i m happy you liked :   thank you very much!  @wolfdale229  can you please consider upvoting    that s great kernel!    @dasmehdixtr  thanks buddy :    great job,16,0.9449108656366727,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
122065_kg,wow great ! congrats @subbuvolvosekar !   could you check this kernel   another great comp !  https://www.kaggle.com/caesarlupum/ashrae-ligthgbm-simple-fe    thanks bro.. learning is about giving and taking :   great work!   @subbuvolvosekar great work!!   if you like it plz upvote it helps me to work more!!!   the figures are so cool upvoted   thanks great figures especially sunburst chart   thanks for good works helpful for my study!   thanks for sharing! this is insightful :   great eda!   totally amazing work! well done!!   excellent kernel @subbuvolvosekar  very thourough with a great story got my upvote! :   excellent eda work! thanks a lot!   so excellent!!,16,0.9437991171645732,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
66649_kg,"i have three files i want to join using the command line:crime_data_2015.csv crime_data_2017_1.csvcrime_data_2016_29.csv  below is what i have done and what results i get does anyone know how to get these three to join and do line count on the combined files  chriskehl@chriss-mbp:~/documents/louisville-crime$ cat crime_data_2015.csv | wc -l   79775  chriskehl@chriss-mbp:~/documents/louisville-crime$ cat crime_data_2016_29.csv | wc -l   84417  chriskehl@chriss-mbp:~/documents/louisville-crime$ join crime_data_2015.csv crime_data_2016_29.csv &gt;joinedfiles.csv  chriskehl@chriss-mbp:~/documents/louisville-crime$ cat joinedfiles.csv | wc -l       1  chriskehl@chriss-mbp:~/documents/louisville-crime$ lscrime_data_2015.csv crime_data_2017_1.csv   lmpd_op_bias_7.csvcrime_data_2016_29.csv  joinedfiles.csv  chriskehl@chriss-mbp:~/documents/louisville-crime$ joined -t crime_data_2015.csv crime_data_2016_29.csv &gt;joinedfiles.csv-bash joined command not found  chriskehl@chriss-mbp:~/documents/louisville-crime$ join -t crime_data_2015.csv crime_data_2016_29.csv &gt;joinedfiles.csv  chriskehl@chriss-mbp:~/documents/louisville-crime$ cat joinedfiles.csv | head -5incident_number,date_reported,date_occured,uor_desc,crime_type,nibrs_code,ucr_hierarchy,att_comp,lmpd_division,lmpd_beat,premise_type,blo,date_reported,date_occured,uor_desc,crime_type,nibrs_code,ucr_hierarchy,att_comp,lmpd_division,lmpd_beat,premise_type,block_address,city,zip_code,id  chriskehl@chriss-mbp:~/documents/louisville-crime$ cat joinedfiles.csv incident_number,date_reported,date_occured,uor_desc,crime_type,nibrs_code,ucr_hierarchy,att_comp,lmpd_division,lmpd_beat,premise_type,blo,date_reported,date_occured,uor_desc,crime_type,nibrs_code,ucr_hierarchy,att_comp,lmpd_division,lmpd_beat,premise_type,block_address,city,zip_code,id  chriskehl@chriss-mbp:~/documents/louisville-crime$ join crime_data_2015.csv crime_data_2016_29.csv incident_number,date_reported,date_occured,uor_desc,crime_type,nibrs_code,ucr_hierarchy,att_comp,lmpd_division,lmpd_beat,premise_type,block_address,city,zip_code,id  chriskehl@chriss-mbp:~/documents/louisville-crime$ join -t crime_data_2015.csv crime_data_2016_29.csv incident_number,date_reported,date_occured,uor_desc,crime_type,nibrs_code,ucr_hierarchy,att_comp,lmpd_division,lmpd_beat,premise_type,blo,date_reported,date_occured,uor_desc,crime_type,nibrs_code,ucr_hierarchy,att_comp,lmpd_division,lmpd_beat,premise_type,block_address,city,zip_code,id  chriskehl@chriss-mbp:~/documents/louisville-crime$ join crime_data_2015.csv crime_data_2016_29.csv | join - crime_data_2017_1.csv &gt output.csv  chriskehl@chriss-mbp:~/documents/louisville-crime$ cat output.csv | head -5incident_number,date_reported,date_occured,uor_desc,crime_type,nibrs_code,ucr_hierarchy,att_comp,lmpd_division,lmpd_beat,premise_type,block_address,city,zip_code,id  chriskehl@chriss-mbp:~/documents/louisville-crime$ cat output.csvincident_number,date_reported,date_occured,uor_desc,crime_type,nibrs_code,ucr_hierarchy,att_comp,lmpd_division,lmpd_beat,premise_type,block_address,city,zip_code,id  chriskehl@chriss-mbp:~/documents/louisville-crime$ cat output.csv   i will give it a try thanks   it seems to work thanks a lot  i ve got a lot to learn",19,0.9433639168175472,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
147685_kg,islrbest introductory book to machine learning theory even paid books are seldom better a good introduction to the maths and also has practice material in r cannot praise this book enough     neural networks and deep learning    this free online book is one the best and quickest introductions to deep learning out there reading it takes only a few days and gives you all the basics about deep learning    pattern recognition and machine learning   it is one of the most famous theoretical machine learning books so you don’t need to write much of an intro    deep learning book   the bible of deep learning this book is an introduction to deep learning algorithms and methods which is useful for a beginner and practitioner both   understanding machine learning from theory to algorithms   really good treatise on machine learning theory   seven steps to success machine learning in practice   non technical product managers and non-machine learning software engineers entering the field should not miss this tutorial very well written slightly old and doesn’t cover deep learning but works for all practical purposes   rules of machine learning best practices for machine learning engineering   wonder how google thinks about its machine learning products? this is a really good tutorial machine learning product management   a brief introduction to machine learning for engineers   monologue covering almost all techniques of machine learning easier to understand maths for people afraid of difficult mathematical notations   brief introduction to machine learning without deep learning   monologue covering almost all techniques of machine learning easier to understand maths for people afraid of difficult mathematical notations    introductory machine learning notes   machine learning guide for absolute beginners   very nice resources,22,0.9430863278719149,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
22220792_so,matlab matrix pca principal component analysis i am strugling with pca stuff  so for example i have     and to do reduction to our data we have to eliminate the number of eigen value and eigen vector based on k  for example    so the number of    eigenvalue will become 2*2  eigenvector = 2*2    1st ques is that right?   and then we have to project out matrix    2nd ques how we can calculate this because the size of eigenvalue and substractdata are different?   and another question    3rd ques if we want to use the reduction data we should use the project?    4th ques if we want to show the principal components which is first and second  columns of eigen vector we have to plot that principal components along with the data   initial data or with substractdata let x denote the original normalized 100x3 data matrix then the decomposition is x *x=v*d*v  where v is an orthogonal and d a diagonal 3x3 matrix by some magic u=x*v is a matrix with orthogonal columns and x=u*s*v  where s the diagonal matrix of singular values is the square root of d this is also called the  singular value decomposition  and can be directly computed without forming the numerically bad product x *x  now you want the first two columns of u all relevant libraries return d resp s with descending diagonal entries using the svd you have direct access to them using the eigenvalue decomposition u12=x*v12 that is as per  cyon  the submatrix u12 of u containing the first two columns left singular vectors is obtained from the submatrix v12 of v containing the first two columns right singular vectors of v  your eigenvalue 3*3 matrix is a diagonal matrix the eigenvalues are scalars along the diagonal to reduce the dimensionality you pick the   eigenvectors that correspond to the two largest eigenvalues so you need to sort your eigenvectors based on their corresponding eigenvalues and pick the two that have the two largest eigenvalues  so you will have eigenvalue = 2*2 only two eigenvalues and eigenvector 3*2 after reduction  since your eigenvectors are now 3*2 you can project the data onto the 2-dim subspace using   you will need to add the mean back after reconstruction to show the data along with the principal components,23,0.9429880914861648,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
147558_kg,"introduction to data science specialization ibm beginner specialization  applied data science specialization ibm beginner specialization  data science specialization by johns hopkins university beginner specialization  executive data science specialization by johns hopkins university beginner specialization  applied data science with python specialization by university of michigan intermediate  data science at scale specialization by university of washington intermediate specialization  advanced data science with ibm specialization advanced specialization  data mining specialization intermediate specialization  recommender systems specialization intermediate specialization  machine learning specialization intermediate specialization  big data specialization beginner specialization  data analysis and interpretation specialization beginner specialization  recommender systems specialization intermediate specialization   all of them are great courses    🙌    great courses,try adding their links so that it would be easy for people to go to that course directly   applied data science with python is a great one! currently i m enrolled in that and there s more practical learning than we get to do in other courses   🙌 .thank you .please do upvote   🙌    deeplearning speacialization is awesome and i love it a lot   🙌    i d like to add one to the list mathematics for machine learning specialization by imperial college london i tried to go directly from a beginner level data science specialization to an advanced machine learning class and found out in the first lecture that i needed a refresher from college the specialization is a good review of linear algebra multi-variate calculus and principle component analysis   thank you brother",22,0.9422796320107094,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
129712_kg,great visualizations thanks for sharing!! 😊    awesome! thank you!   thanks for sharing very nice plots   thanks for sharing incredible plots!   delightful violins histograms jointplots pairplots and many more👍    @goldens great visuals   thanks  @anshumoudgil  !   thanks  @mpwolke  !   amazing visualizations   thanks  @prashant111     hi  @gatunnopvp    i am glad you liked it!   nice kernel   thanks!   good eda   good visuals nice work i liked it 😃    great   great visuals really interesting and informative,16,0.9421853898966875,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
72496_kg,great first programming book for anybody that wants to learn python for data science  it won t take you to an expert level but it s awesome if you re just getting started or are transitioning to python from r or sas  check it out - highly recommended  👉 free pdf  https://lnkd.in/gucxfap   👉 online lessons  https://lnkd.in/gqqyg6c   👉youtube lectures  https://lnkd.in/gknzdae   👉 link to amazon  https://lnkd.in/gg4p5ei   👉 dsdj mailing list for future recommendations  https://lnkd.in/g7ayg72,22,0.9421837930777226,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
31447_kg,please suggest good books/online courses which provide practical knowledgeprogramming based approach on artificial intelligence in market i have found many books on artificial intelligence but all gives theoretical knowledge i want to study theoretical and practical part of artificial intelligence parallely.please help thanks in advance    https://www.udacity.com/course/intro-to-artificial-intelligence--cs271     artificial intelligence is the latest technology most of the industries work on artificial intelligence you can study online as well as offline but online is a wider area many data or information are available you can t identify which information or data are right or not i will suggest you should join the  artificial intelligence institute  because they give the opportunity to work on live project as well as they give basic knowledge of artificial intelligence,22,0.9418255694088118,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
30858872_so,"bigdata database hadoop why relational database not support by hadoop nosql database support by hadoop system   may i know why hadoop system not support relational database    how to manage large relational database  the following are the difference between hadoop and rdbms   hadoop does not have support for atomicity consistency isolation,and durability  low latency retrieval of data is not possible in hadoop unlike inrdbms there is no guarantee of how much time hadoop will take tocomplete a job  basically hadoop has faster write and rdbms has faster read fasterread is because of the usage of b-tree data structure for storage  hadoop doesn t have a schema rdbms has a schema   you can query a large structured data stored in hdfs using hive pig hbase etc but the retrieval won t be as fast as in rdbms my opinion would be not to use hadoop for relational operations    rdbms can store data up to some terabytes and renewing licenses is always a pain  eg sql mysql  here comes mppsmassive parallel processing. mpp systems can handle huge data than a single node of rdbms database since it stores data in a cluster but there is a limit  eg netezza teradata. etc  above mentioned rdbms &amp mpps can handle structured data up to some tbs and give fast response. can be used for oltp  finally our hadoop. which is mainly designed to handle huge volumespetabytes of data while storing and processing on commodity hardware. which is scalable. hadoop is not meant for oltp",15,0.9417505027122386,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
83219_kg,"nice analysis great kernel!   thanks ahmad!   that s very well   thanks   top quality kernel.well done   great! really liked it   thanks nitin!   thanks,maunish!   sorry for upvoting a kernel that was just forked from this one which is the original i downvoted the other kernel great work and extensive analysis!! don t let people who just copy your wor demotivate you keep up the awsome effort you are putting in your kernels have an awsome day!   thanks janio i really appreciate it   great job !! keep sharing your kernels with us.    thanks anas!   nice visualisations!    thanks ahan!   good kernel! thanks for sharing   thanks grecnik!   very nice kernal!!!thanks for sharing with us!!!   very clearly explained !!! really great work !!!   thanks chanchal!   thanks siddharth!   great one! thanks for sharing    thanks piyush!   thanks for sharing! upvoted   thanks arushi!   great kernel   thanks   thank you for sharing this kernel!    amazing kernel @ishivinal    great! especially the one determing the risk factor of the heart disease!   thanks for sharing ! very useful !    could you check this dataset and upvote or comment if you like   https://www.kaggle.com/caesarlupum/mortality-among-children",16,0.9412760239042167,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
50421014_so,machine-learning reinforcement-learning what is it called when the action doesnt affect the state in reinforcement learning in reinforcement learning is there a name for algorithms where the action taken doesnt affect the state? e.g armed bandit in the rl setting  armed bandits  are considered stateless so naturally actions do not affect the state there are just actions and rewards  if you add a state but the actions do not have an effect on what the next state will be they are called  contextual bandits  contextual bandits have states actions and rewards your state or context may affect your action but not the other way around i.e there are no transition rules like in a normal rl,3,0.9410871137224562,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
97531_kg,great kernel @tavoosi ! thanks for sharing keep up the great work :   great work! love the charts   nice work!   thank you that s very helpful    @carolynmford  i m glad you found it helpful!   a clear and concise introduction thanks!   its quite insightful saba    brilliant article!    good work!   very informative !   nice work very informative thanks for sharing   great kernel @tavoosi    thank you very much! i like all the comments/explanations made it much easier to understand for me! ,16,0.9408988221109239,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
82056_kg,"hi all:  our team best single model such as just one lightgbm model public lb is about 3.672 without any post process as a new kaggler i want to know more about this competition thank you!   3.663 plb  3.600 prilb  stacking    老哥互粉下嘛 upvote   this is a stacking result so how about your single model result?   3.667（lb 372 features cv3.641   哈哈，刚给你点了赞。   加个微信？ scuwangjianfei   很厉害！   3.6352 3.674 3.604   cv 3.629 public 3.680 private 3.603   thank you    我也想加大佬微信，2333333333   best single model 3.666  ！！！ 加了老哥   i have used 399 features and get 3.689 in public lb 3.611 in private lb and 3.645 in 5folds cv without stacking as a novice i was surprised at the difference between public and private leadboard    good job!   me too   one more question your team single model public lb is 3.680? so how can you get 3.59x private lb thank you!   only use stacking our stack model score is cv 3.616,public 3.664,and private 3.593   unfortunately  i did not choose that submission but my best single model in private leaderboard is 3.605 in private 3.692 in public very hard for me to figure out  the performance of that single model in private leaderboard next time i think i should have a team    you are really good with out 2 single model ensemble get 3.666 public cv but private only 3.599   my best single model is a lightgbm with cv:3.6144,lb:3.668,pb:3.593   very cool! thank you!   best single model lgbm 10-fold skfold 3.6434 cv 3.682 public 3.609 private",14,0.9408270419752129,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
58981036_so,cluster-analysis computational-geometry finding optimal 2-center clustering from max-diameter 2-clustering given a set of points in euclidean space we want to partition them into 2 clusters such that the maximum diameter of all the clusters gets minimized the definition of cluster diameter is given below   the diameter of a cluster is the diameter of the minimum enclosing circle of the points on that cluster 2-center clustering  the diameter of a cluster is the maximum possible distance between any two points on that cluster max diameter 2-clustering   consider we have an exact solution for max diameter 2-clustering we know that these two clusterings are not equivalent is there any way we can find the exact 2-center clustering from the exact solution of max diameter 2-clustering ,23,0.9405020730165277,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
14754_kg,"dear all  this is my code for the competition i hope it is helpful for you i feel great to share the same with you  libraryrandomforest my.train_01 &lt;- read.csv&quot;train.csv&quot; my.test_01 &lt;- read.csv&quot;test.csv&quot; we &lt;- read.csv&quot;weather.csv&quot; train_we &lt;- merge.data.framemy.train_01,we test_we &lt;- merge.data.framemy.test_01,we train_we &lt;- train_we[1:nrowmy.train_01 ] test_we &lt;- test_we[1:nrowmy.test_01 ] train_we$species &lt;- as.charactertrain_we$species test_we$species &lt;- as.charactertest_we$species test_we$species &lt;- mapplynormalize,test_we$species train_we$species &lt;- factortrain_we$species test_we$species &lt;- factortest_we$species train_we$preciptotal &lt;- mapplyprecip,train_we$preciptotal test_we$preciptotal &lt;- mapplyprecip,test_we$preciptotal test_we$tavg &lt;- as.integertest_we$tavg train_we$tavg &lt;- as.integertrain_we$tavg test_we$tavg &lt;- mapplyavg,test_we$tavg train_we$tavg &lt;- mapplyavg,train_we$tavg fol_rf &lt;- formulawnvpresent ~ species + preciptotal + tavg + latitude + longitude model_rf &lt;- randomforestfol_rf  data=train_we predictions_rf &lt;- predictmodel  newdata = test_we predic &lt;- predictions_rf[1:116293] submissionfile&lt;-cbindtest_deb_001$id,predic colnamessubmissionfile&lt;-c&quot;id&quot;,&quot;wnvpresent&quot; write.csvsubmissionfile,&quot;submit_randomforest_004.csv&quot;,row.names=false,quote=false",19,0.9404374524931528,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
49894_kg,first you need to choose the langauge python or r than getting started with one of them i suggest you python python is one of the best languages for me  for python you can choose data camp course  https://www.datacamp.com/tracks/data-scientist-with-python    after completing this course track you will be on  halfway there  then you can choose for advanced in machine learning    https://www.coursera.org/learn/machine-learning  then you can be started with  coursera course advanced machine learning specialization   https://www.coursera.org/specializations/aml  then you need to learn  deep learning this i also from course with andrew ng   https://www.coursera.org/specializations/deep-learning   now you became the most advanced person in the data science and machine learning field believe me you can solve many problems after completing these specializations.for any doubt you can comment below...can you? if you have any better solution apart from this please suggest me   happy learning   what i found quite inspiring was this series of videos where proffesionals generally talk about how to pursue a career of a data scientist from those i saw i especially liked talks by sebastian gutierrez and chris albon   https://www.thisismetis.com/demystifying-data-science-recordings,22,0.9403279473370654,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
5894_kg,what are the best universities to study data science in us?   u can find&nbsp;colleges with data science&nbsp;degrees from this link  http://datascience101.wordpress.com/2012/04/09/colleges-with-data-science-degrees/   anyone know of canadian datascience programs?   [quote=curtis mabilangan;31669]  anyone know of canadian datascience programs?  [/quote]  university of toronto and university of montreal both have very well regarded machine learning programs.&nbsp   i ve read that utoronto is top 10 in cs around the world   here s another list some &nbsp;additional to above link are posted here it seems&nbsp  &nbsp  http://whatsthebigdata.com/2012/08/09/graduate-programs-in-big-data-and-data-science/   i took andrew ng s course its nice very nice&nbsp  one more &nbsp;https://class.coursera.org/datasci-001/ &nbsp by bill howe was very good&nbsp  &nbsp,22,0.9399867527625991,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
98112_kg,"great job!thank you for sharing ;   thanks buddy!  @kageyama  happy that you liked it :   it seems clear that you put so much efforts on it,,tremendous work mate,keep it up,i believe you can win kaggle someday! best of luck ratan :     @mobassir  thanks mate for your appreciation!   great job @ratan123 .keep going!    @sriharipramod  thank you sir ! :   great kernel! thanks for sharing @ratan123 !   nicely explained @ratan123  upvoted!!  you can also have a look at my kernels here: https://kaggle.com/ankitjha/kernels     @ankitjha  happy that you liked and thanks : ! sure i will go through your kernels :    @aleksandradeis  happy that you liked it :   wow just loved this kernel great explanations     @abhinand05  happy broo! that you liked it :   yes please do visit   wow  this really is inspirational ! well done !   great explanation   this kernel depicts your hard work    thank you very much  @dataraj     good kernel 1 vote from me 👍    great work...   very informative!!   excellent work!😍upvoted!pls also have a look at my notebook and upvote it if you like it. https://www.kaggle.com/mehmetmarcelo/data-all-about-data    thanks a lot for sharing this this notebook is so informative",16,0.9399114472443829,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
54402316_so,cluster-analysis distance-matrix geolocation latitude-longitude python finding clusters with max intra-distance based on geo co-ordinates i have dataset that contains lat long data   using this data i have computed the distance matrix where m[i][j] is the distance between id:i and id:j  the distance is computed using the below code   is there a best way to find clusters that are within the x miles of radius  most of the current clusters like dbscan k-means provide options for minimum distance and minimum samples however i am looking for clustering method which provides maximum distance  secondly i am ok not to calculate distance matrix if thats not required do complete linkage hierarchical clustering  if you cut the tree at the distance x any two points in the same cluster will have a distance at most x it s not optimal because that would be np complete but good enough usually,23,0.9398126254708551,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
80479_kg,i believe that this is an invaluable resource which will help any beginner understand the fundamentals  to deep learning and computer vision the course is structured by the famous computer vision researcher fei-fei and is taught by former phd students justin johnson and serena yeung  the website provides a detailed syllabus lecture notes assignments and youtube links to the class lectures   http://cs231n.stanford.edu/     thanks michael for sharing this!  i know about 2 more courses on deep learning/ computer vision which i found very informative   this course intro to deep learning is provided by iit madras india  https://www.youtube.com/watch?v=apfkyu_qif4&amp;list=plyqspqzte6m9gcgajvqbc68hk_jkgbayt    this course deep learning for visual computing is provided by iit kharagpur india  https://www.youtube.com/playlist?list=plagfg6qiehggvnlseinzezzsglwvwmn2h   hth,22,0.9397644084194511,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
40326169_so,deep-learning python tensorflow how to do matmul operation in specific dimension in tensorflow i have a 3d tensor  sequence_length batch_size word_dim  i need to do matmul operation with  word_dim dimension  so that i can change tensor into  sequence_length batch_size hidden_dim  it seems that matmul operation can only be used in 2d tensor and i can not change the 3d tensor into 2d because of the batch_size how can i do i would first reshape your tensor to be  sequence_length * batch_size word_dim  do the matmul to get  sequence_length * batch_size hidden_dim  then reshape again to get  sequence_length batch_size hidden_dim  there is no copying involved with reshape and this is equivalent to multiplying each of the batch_size matrices individually if you only have one matrix to multiply them with,5,0.9396589158359109,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
70309_kg,nice exploration thanks for sharing!   thanks for your comment joshua :   good work   thank you :   excellent work!   thank you osman ali :   thank you for your sharing good work   i hope you liked it : thanks   nice analysis   thank you ahmad :   thank for sharing good analysis    thank you daniel 😃    cool efe! ;     ; thanks mate   *  good work efe *     good job last chart is very nice @efeergun96    thank you :   thank you :   nice kernel!   thanks nida ,16,0.939176197617234,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
116397_kg,hello guys here are the top notebooks from last year s competition   https://www.kaggle.com/headsortails/what-we-do-in-the-kernels-a-kaggle-survey-story    https://www.kaggle.com/sudalairajkumar/where-do-people-learn-ml-ds    https://www.kaggle.com/robikscube/a-tale-of-4-kaggler-types-by-ide-use-2018-survey    https://www.kaggle.com/andresionek/what-makes-a-kaggler-valuable    https://www.kaggle.com/harriken/storytelling-the-2018-kaggle-survey   if you have any other notebooks that you really like! post them in comment section   great idea!  i liked this notebook a lot  https://www.kaggle.com/artgor/russia-usa-india-and-other-countries/   also  https://www.kaggle.com/headsortails/what-we-do-in-the-kernels-a-kaggle-survey-story,16,0.9389702289148103,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
54702_kg,at start our team had two submissions and chose those as our team s final results then i submitted my final submissions two hours early before the competition ends  and our team leader chose the newest two submissions half hours early before the competition ends it indicates that selected submissions updated     [it displays 7:30 because i  live in utc/gmt+08:00]  however when the competition ends the scores of our submissions are 0.574two hours early before ending 0.483 and 0.530 and only 0.483 is chosen another strange thing is that we get 0.530 in the lb which is not chosen  i don t know how to do... is there any chance to change the score? help!!!   i also had an issue with my selection being ignored  it did not harm us in the end but you seem to have been less lucky than us unfortunately  i hope kaggle team will look at this issue very soon   thanks cpmp what confuse me is that 0.530 our current score is not chosen either maybe i should have received 0.483 ???   what a pity! maybe you should email the administrator of kaggle,17,0.9387089654669384,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
127697_kg,nice kernel thanks for sharing!!   thanks xavier really appreciate your feedback   nice kernel thanks for sharing!   nice eda!! well boxplots 👍   i also like visualization and i m making a lot of eda kernels if you like it please upvote    road to viz expert 2 - plotly &amp seaborn    awesome matplotlib cheatsheet     thank you for the feedback! i just checked your kernels great work   sure akhilesh thanks!   the visualizations are very nice! thanks for sharing!   thank you for your feedback!   good notebook and visualizations   thank you  @mpwolke,16,0.9379006901487104,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
50424167_so,python pytorch concatenating two tensors with different dimensions in pytorch is it possible to concatenate two tensors with different dimensions without using for loop  e.g tensor 1 has dimensions 15 200 2048 and tensor 2 has dimensions 1 200 2048 is it possible to concatenate 2nd tensor with 1st tensor along all the 15 indices of 1st dimension in 1st tensor broadcast 2nd tensor along 1st dimension of tensor 1 while concatenating along 3rd dimension of 1st tensor? the resulting tensor should have dimensions 15 200 4096   is it possible to accomplish this without for loop  you could do the broadcasting manually using     before the concatenation using,5,0.9371086384774517,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
122060_kg,this forum is dedicated to mentoring for careers in data science for university students  kindly share your brief bio and your queries here   hi ma am i am currently pursuing b.tech in cse and aspire to be a data scientist which fields do i need to develop and which programs should be my cup of tea??   hi mam  i am samuel currently pursuing 2nd year b.tech cse . i want to build a career in data science.it feels great to have a experienced mentor.thank you mam   nice to see this initiative usha ma am     @gshanbhga525  thank you so much for your kind words gunesh    @mikemax  python programming skills is a must you can start with data camp s free course for python for data science  https://www.datacamp.com/courses/intro-to-python-for-data-science  its a free course once you complete the course  let me know i will tell you how to proceed further    @samuelcool  thank you samuel its encouraging to have great students like you   hi mam..done with python and git mam..what should be the next steps mam,22,0.9367595445605733,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
27964_kg,i just want to check is this statement in the timeline saying that competition rules have to be explicitly accepted somehow or that a submission must be made prior to this date?  entry deadline you must accept the competition rules before this date in order to compete   [quote=joel mcleod;157422]  i just want to check is this statement in the timeline saying that competition rules have to be explicitly accepted somehow or that a submission must be made prior to this date?  entry deadline you must accept the competition rules before this date in order to compete  [/quote]  competition rules must be accepted before downloading the data so most likely you have done it already it used to be that one had to make at least one submission prior to the deadline as well but i don t think that is required any longer  if you accept the rules but never make a submission i am pretty sure it doesn t show up in your timeline   thanks tilii just double-checking,17,0.9365954089855804,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
88571_kg,hi  i am doing a master in big data and data science with a spain university i am from colombia.actually i am looking a director for my thesis   descriptive and predictive analysis of ufo sightings around the world   anyone interested? the director must have university degree and with knowledge applying machine learning/python/tableau/r/cartodb/etc  techniques and obviously knows/interested about ufo sightings fields  please write me an email to jnishikuni@gmail.com  sincerely  jorge nishikuni,22,0.936203219093281,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
56548_kg,"incredibly beautiful kernel! thanks for sharing!  i didn t know about  folium    elegant and beautiful ...  best notebook.. motivational for me   awesome visualizations..   hi pavan,i love your kernel.. thanks for sharing..    thank you    thank you nishant   thank you yavuz   neat work - thanks for this - very insightful   great insights and visualizations beautifully summarized!   thank you jaghadish   thank you ketaki bhalerao   impressive work and awesome visualizations thanks for sharing!   thank you xavier",16,0.9358365548628362,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
109162_kg,very nice kernel @alekhya as it is your first trykeep it upand i have also made kernel regarding this check this out if you like it please share and upvote https://www.kaggle.com/sahib12/nyc-airbnb this was also my first kernelsecond is  https://www.kaggle.com/sahib12/ipl-match-analysis hope you will like these   thank you  @sahib12  for your encouraging words i shall definitely have a look at your kernel   beautiful kernel @alekhyabotta i loved the colors you used for the plots looking very vibrant and beautiful a nice structured approach of data visualization and exploration thanks for sharing this beautiful kernel   thank you  @errolpereira  for your kind words ,16,0.9347285380420783,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
73272_kg,looking at the historical transactions from for example jan 2017 we can find some transactions with month lag of -6 -4 but even -1 so although the majority of transactions from this month have the lag of -13 suggesting feb 2018 some of the observations do not make sense any ideas?   i think that the month lag is based on the max purchase date from the historical transactions data set:for the historical transactions the month lag could be:   month lag = month of current transaction purchase date - max month of purchasewhile for the new transactions is   month lag = max month of purchase - month of current transaction purchase date   @kathia when you say for the new transactions  do you mean in the new merchant data? that may not be true as month_lag only has 1 2 two values,8,0.9347131091378207,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
60799_kg,"hi i completed my machine learning course and did some standard ml projects but now i need a set projects which are unique and will help my resume to stand out when i apply for an internship please suggest me good projects.thanks   great question!!thank you very much for asking  if you are searching for machine learning project ideas you can check out the links below -     https://elitedatascience.com/machine-learning-projects-for-beginners    https://cs.brynmawr.edu/courses/cs380/spring2011/project.html    https://machinelearningmastery.com/self-study-machine-learning-projects/    http://cs229.stanford.edu/projects.html    https://analyticsindiamag.com/10-popular-machine-learning-projects-github/    the above links are provided for reference purpose only you will surely find something interesting!!all the best  &nbsp    thanks this was  really helpful   you are welcome and it is my pleasure   hey there,i am new here and i want to learn ml.can you recommend ml course  i should take as a beginner as i like to work in python thanks    https://www.coursera.org/learn/machine-learning  for theory https://www.youtube.com/channel/ucwn3xxrkmtpmbkwht9fue5a  https://www.youtube.com/user/sentdex python    hello,can anyone please suggest me some ai capstone projectsi m a masters student in it securitythank you   this was very helpful!  thank you!   i want to do mtech final year project so please send me the latest project topics",22,0.9346679942353868,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
100556_kg,how have you taken these values please apprise   df = df[df[ pickup_longitude ] &gt -78 &amp df[ pickup_longitude ] &lt -70 &amp            df[ dropoff_longitude ] &gt -78 &amp df[ dropoff_longitude ] &lt -70 &amp            df[ pickup_latitude ] &gt 37 &amp df[ pickup_latitude ] &lt 45 &amp            df[ dropoff_latitude ] &gt 37 &amp df[ dropoff_latitude ] &lt 45 &amp            df[ passenger_count ] &gt 0 &amp df[ passenger_count ] &lt 7 &amp;           df[ fare_amount ] &gt;= 2.5 &amp df[ fare_amount ] &lt 500,19,0.934460094422238,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
40903141_so,python tensorflow how to use embedding_lookup with a batch of different length sequences in tensorflow say i have an embedding tensor   i have a list of sequences   i d like to lookup the   and pad zeros to make each sequence has the same length   i tried   but got an error     valueerror argument must be a dense tensor [[0 1 2 3] [3 2]] -  got shape [2] but wanted [2 4]   is it possible to achieve this without prepending   to   the     function only accepts dense rectangular tensors as the   argument in general the same goes for all tensorflow operators that expect a     or tensor-like argument such as a numpy array.  for sparse data you can use     which accepts a     as its argument which can represent sequences of different lengths a   is defined from three separate dense tensors representing the indices of the non-zeroes the values of the non-zeroes and the overall dense shape for  your example of inputs the representation would be,5,0.9341876160846665,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
109706_kg,really nice kernel vitallii thanks for sharing upvoted 👍    hello @vbmokin   useful and informative kernel it s great work i upvoted it  i have also written a kernel on comprehensive eda + preprocessing + fe + modelling could you please take a look at it and upvote it if you like it?  kernel  comprehensive eda + preprocessing + fe + modelling   https://www.kaggle.com/prashant111/comprehensive-eda-preprocessing-fe-modelling   thank you   nice kernel   thank you!   it is awesome   thanks really effective kernel 👍 👍 👍    good job!   useful kernel! good job!   interesting!   really good job! upvoted! ,16,0.9339397356145138,"0.064*""kernel"" + 0.041*""great"" + 0.041*""work"" + 0.040*""share"" + 0.028*""nice"" + 0.025*""good"" + 0.025*""kaggle"" + 0.019*""https"" + 0.016*""www"" + 0.016*""notebook"""
115294_kg,i think i have a good grasp of the basics of machine learning and looking for some good books that go further into machine learning topics like computer vision and natural language processing some of the books i ve seen recommended are over 10 years old and i m not sure if they re still worth reading now   i have a list of book and i m reading them check them.these books are not what you want but may help  book #1 - the hundred page machine learning book by andrej burkov   book #2 - python machine learning 2nd edition by sebastian reschka  book #3 - grokking deep learning by andrew trask  book #4 - probabilistic programming and bayesian methods for hackers by cameron davidson  book #5 - doing data science straight talk from the frontline by rachel schutt  book #6 - reinforcement learning by sutton and barto  book #7 - the book of why by judea pearl  book #9 - quantum machine learning by peter wittek   i started with r for machine learning so couple of resources with r as programming language but note that the theory provided in these texts is invaluable and guide you through structured thinking process on analysing data and fitting machine learning models    an introduction to statistical learning is a comprehensive book on learning the nuts and bolts of machine learning this is a free book available for download plenty of math context while not being too intimidating supporting code and exercises in r but the theory is still amazing to go for    applied predictive modeling by max kuhn creator of caret package for machine learning in r this book is a gem for case studies has solutions hosted online as well    for python i just started with hands-on machine learning with scikit-learn and tensorflow early days will let you know as time goes   o reily series might be helpful.....they are up to date   i tried to learn r once for a course and just could not wrap my head around it i stick to python now,22,0.933822573840364,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
44021702_so,"algorithm cluster-analysis cluster points by spheres in 3d space there is 3d space limited with a cube with edge=2000  the center of coordinate system is point 0 0 0 so the maximum/minimal coordinate value is 1000/-1000  there are 10000 points generated with discrete uniform distribution inside of k spheres located in the cube  radius r of each sphere is 250  centers of spheres are located at the distance of not less than 2*r  it is required to determine which point related to which sphere  input array of 10000 structures like   where number is unique id of the point x,y,z - it s coordinates  output   array of 10000 structures like   where cluster_id is unique cluster id of a sphere that point belongs to  initially i considered a following solution  1 find euclidian distance for each point from  center of coordinates 0;0;0 to point s coordinates  2 sort this array of distances in descending order  3 get the point from the sorted array of distances and put in a new set of cluster maximals  4 compare following point from the array to each value from the set of cluster maximals initially 1 value  if it s euclidian distance less than or equal to 2*r then  mark this point as belonging to kth cluster range=1..n otherwise add the point to the set of cluster maximals  5 repeat step 4  two concerns i have  1 there is an issue that my algorithm would work only in case if claster maximals are located on the surface of the spheres  2 plus according to the task requirements there could be the case when 2 spheres can have 1 and only common point  i think in case if point belongs to 2 spheres it is ok to mark it with cluster_id of any of these 2 shperes  could you please provide a proper solution to the task as the radius is given find the point with the most neighbors  take the average of its neighbors as center and remove everything within the radius  repeat until no dense points remain  perform some postprocessing to further optimize for unassigned points and to ensure the minimum distance",23,0.9335553404922246,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
53260323_so,"apache-spark bigdata hadoop hdp yarn does enabling cpu scheduling in yarn will really improve the parallel processing in spark yarn with capacity scheduler will take only memory into account when it is allocating resources for user requests if i submit a spark job like this  --master yarn --deploy-mode client --driver-memory 4g --executor-memory 4g --num-executors 1 --executor-cores 3  yarn will allocate an executor with  4gb memory and 1 vcpu  but when it is executing tasks it will execute 3 tasks parallelly  is it using that single core alone to execute all tasks as a set of 3 at a time?  so if i enable cpu scheduling and cgroups in hdp cluster will yarn assign 3 vcpu cores and will that set of 3 tasks will get executed in each cpu? will it really improve the processing time?  as for now i could not enable cpu scheduling in my cluster hdp 2.6.5 centos 7.5 due to the below error in starting node manager not able to enforce cpu weights cannot write to cgroup at /sys/fs/cgroup/cpu,cpuacct no vcores and vcpus are really a logical construct that are not related to what is actually on the system but more closely related to how many processes are running  the os linux in this case will migrate work to all cpus if the process is designed for this  most long running java applications will do this due to the multiple threads running  yarn doesn t control cpu cores unless you enable cgroups  the only thing yarn controls is the memory usage  the reason this doesn t matter is because typical hadoop workloads are i/o bound not cpu bound  references    using cgroups with yarn",15,0.9335550884970865,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
27327_kg,"hi   can anyone suggest some website or material to learn data science and sas if anyone has material for it can you share it  thanks,tarun   for machine learning &amp other related topics following sites could be a good way to start your journey   www.coursera.org various online courses   https://www.udemy.com  various online courses   https://www.youtube.com/playlist?list=pld63a284b7615313a&amp;spfreload=1  lectures on machine learning   wish you luck!   hello there - you can use hackerrank for practice - there are lots of categories that you may find useful however if you are looking for something to study then go for edx or coursera for data science courses- they are really useful   edx and udacity courses are great.covers both introductory and advanced topics!   in addition to what other have mentioned i would also recommend to take statistics class this youtube channel is great for statistics  https://www.youtube.com/channel/ucfrjdcimgcqvyfbk04mbeha",22,0.933362646771196,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
116794_kg,"훈련 데이터 로드 및 라벨 설정  ```df_data = pd.read_csv /kaggle/input/2019-pr-midterm-musicclassification/data_train.csv   df_data.drop[filename] axis=1 inplace=true  label=df_data[label].copy # labeldf_data.drop[ label ],axis=1,inplace=true```pandas를 이용해 csv 파일을 df_data에 저장하였다.drop을 이용해 filename에 들어있는 문자값을 지우고 따로 label에다가 label값만 빼내서저장하였고 그리고 df_data에는 label 탭도 삭제 시켰다.  데이터 샘플링 &amp validation 25%  ```split = stratifiedshufflesplitn_splits=10 test_size=0.25 random_state = 42  for train_index cross_index in split.splitdf_data label:    strat_train_set=df_data.iloc[train_index]    strat_cross_set = df_data.iloc[cross_index]    music_labels=label[train_index]  music = strat_train_set.copymusic = scalemusic;```stratifiedshufflesplit 모듈을 이용해서 데이터를 75프로 분류시켰다.strat_train_set에 훈련데이터들을 저장시키고 music_labels에 훈련라벨들을 저장시킨다.scale함수를 통해 music 데이터를 정규화 시켜서 저장한다  분류기   kernel에 rbf cost 값 조정해서 분류기를 돌려서 테스트 해보았으나 poly가 제일 괜찮은 성능을 보였다  테스트 데이터 준비  ```  load datasets  dataframe 을 이용하면 편리하다  df_data = pd.read_csv /kaggle/input/2019-pr-midterm-musicclassification/data_test.csv df_data.drop[filename] axis=1 inplace=true  x_test = df_data.droplabel axis=1y_test = df_data[label].copyx_test_prepared = scalex_test```학습데이터 준비과정과 마찬가지로 filename label 속성을 지워주고 정규화시킨다  테스트 데이터 예측   predict를 통해 예측을 한다  결과값을 csv 파일로 변환  ```  numpy 를 pandas 이용하여 결과 파일로 저장  각 장르에 따라 숫자로 변경 후  id label 라벨을 추가해서 저장하기  import pandas as pds = pd.seriesresultdata={ id :range1,51 label :s}printresult.shapedf = pd.dataframedatadf.index += 1 df = df.replace blues ,0df = df.replace classical ,1df = df.replace country ,2df = df.replace disco ,3df = df.replace hiphop ,4df = df.replace jazz ,5df = df.replace metal ,6df = df.replace pop ,7df = df.replace reggae ,8df = df.replace rock ,9df.to_csv results-yk-v2.csv ,index=true,index_label= id  header=true,columns=[label]```나온 예측된 라벨값인 result를 pandas 모듈을 이용해 주어진 양식으로 변환을 시켜준다.각 라벨은 숫자로 변환되어야 하므로 replace를 통해 숫자로 바꿔준다",19,0.9333587945352048,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
51651240_so,cluster-analysis r doing clustering with some data points always clustered together is there some r functions to perform clustering hclust kmeans ect. on   data points   with the constraint that some points   are always clustered together? or equivalently is there some approach to perform clustering with given initial clusters found a solution if using hclust set the dist values within the same initial cluster as 0 so that the points within each initial cluster will always be clustered together if using the kmeans represent each initial cluster by a new point defined as the centroid of the cluster,23,0.93308521297178,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
51226011_so,tensorflow tensorflow-serving tensorflow.js tensorflow frozen graph to savedmodel i ve been trying to use tensorflow.js but i need the model in the savedmodel format so far i only have the frozen graph as i used tensorflow for poets codelab  how can i convert the frozen graph into savedmodel?  i ve been using the latest python version and tensorflow 1.8 the savedmodel is really just a wrapper around a frozen graph that provides assets and the serving signature for a code implementation  see this answer,7,0.9330434330082397,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
87227_kg,"hello all  good day to you i used to work as an information coordinator but i also have a beginner experience in python programming.i have now switch to data science and i like you support with tasks and freelance work anything you have to offer is important my most important question is how do i develop my skill on data science?   thank you all   this is awesome! i don t currently have tasks or freelance work but may i recommend you sign up for data camp? it is an amazing place to learn all about data science!   cognitiveclass.ai has a free intro to python in the data sciences which will give you a very quick and easy overview it s small but they have lots of other courses that are free as well so you can start diving more into it.i d also look at their ibm s professional data science certificate on coursera and their advanced data science specialization as well the courses include key concepts programming and even a project to get you started.coursera i really enjoy for just getting a bit more into these topics they are short enough cheap enough,and self-paced enough while giving you a certificate just so you have the record as you go through   this is great !!! anderw ng coursera machine learning course is the best choice for data science   i have the same purpose like you and looking for a good course to develop my skills.i am learning some course in edx which you can refer as well   hi oluwole  greetings..!!  data science is a vast field to stuy  in my humble opinion i would suggest you to implement every concept you read to ensure that you rememeber them and know how to implement them when required  i hope you enjoy learning  best regards,akash bhiwgade",22,0.932587329089865,"0.033*""learn"" + 0.027*""datum"" + 0.024*""machine"" + 0.019*""learning"" + 0.015*""data"" + 0.014*""good"" + 0.013*""https"" + 0.013*""python"" + 0.011*""science"" + 0.010*""start"""
145440_kg,hello! in any competition i can not create a new notebook or edit an old one it is loading and loading..... there is permanent indicator  draft session  starting restarting a session does not help any help ? thank you    could you provide any more details?javascript console / network tab showing errors with firestore or kkb-production?does using a different browser help? what browsers have you tried?are you on a vpn/proxy have antivirus / browser ext / adblocker that might interfere with the connection?reliable/reasonably fast internet connection?happening for all notebooks or specific ones/settings?   @dmitri9149     xpost.ts:179 uncaught in promise domexception failed to read the  localstorage  property from  window  access is denied for this document.    at s  https://www.kaggle.com/next/kernels/editor.js?v=1587602950:219:40313     at  https://www.kaggle.com/next/kernels/editor.js?v=1587602950:219:41485     at new promise     at  https://www.kaggle.com/next/kernels/editor.js?v=1587602950:219:41201     at  https://www.kaggle.com/next/kernels/editor.js?v=1587602950:391:167267     at  https://www.kaggle.com/next/kernels/editor.js?v=1587602950:219:78682     at object.next  https://www.kaggle.com/next/kernels/editor.js?v=1587602950:219:78787     at  https://www.kaggle.com/next/kernels/editor.js?v=1587602950:219:77724     at new promise     at l  https://www.kaggle.com/next/kernels/editor.js?v=1587602950:219:77498   this is the error message from chrome usually i always use the chrome browser as you advised i try firefox now and everything works fine with the firefox i can edit and create new notebooks  thank you    xpost.ts:179 uncaught in promise domexception failed to read the  localstorage  property from  window  access is denied for this document.    at s  https://www.kaggle.com/next/kernels/editor.js?v=1587602950:219:40313     at  https://www.kaggle.com/next/kernels/editor.js?v=1587602950:219:41485     at new promise     at  https://www.kaggle.com/next/kernels/editor.js?v=1587602950:219:41201     at window._events  https://www.kaggle.com/next/kernels/editor.js?v=1587602950:391:168394     at window._events.dispatch  https://kkb-production.jupyter-proxy.kaggle.net/k/32545019/eyjhbgcioijkaxiilcjlbmmioijbmti4q0jdluhtmju2iiwidhlwijoislduin0..n9zpafea0o5bxcu3lnytaq.fuil_odnqkcqegwjrnl-iknope4pnesmjh09ip7iv_hvqyfarjsihdymzpa-aromkcz5hdsih4lu80zq3xdorg.bzz9i7naym3q35btqutnuq/proxy/static/notebook/js/main.min.js?v=1b0256649fd5326c7cad4be834633ffd:3:7537     at window._events.r.handle  https://kkb-production.jupyter-proxy.kaggle.net/k/32545019/eyjhbgcioijkaxiilcjlbmmioijbmti4q0jdluhtmju2iiwidhlwijoislduin0..n9zpafea0o5bxcu3lnytaq.fuil_odnqkcqegwjrnl-iknope4pnesmjh09ip7iv_hvqyfarjsihdymzpa-aromkcz5hdsih4lu80zq3xdorg.bzz9i7naym3q35btqutnuq/proxy/static/notebook/js/main.min.js?v=1b0256649fd5326c7cad4be834633ffd:3:5620     at trigger  https://kkb-production.jupyter-proxy.kaggle.net/k/32545019/eyjhbgcioijkaxiilcjlbmmioijbmti4q0jdluhtmju2iiwidhlwijoislduin0..n9zpafea0o5bxcu3lnytaq.fuil_odnqkcqegwjrnl-iknope4pnesmjh09ip7iv_hvqyfarjsihdymzpa-aromkcz5hdsih4lu80zq3xdorg.bzz9i7naym3q35btqutnuq/proxy/static/notebook/js/main.min.js?v=1b0256649fd5326c7cad4be834633ffd:4:4818     at object.trigger  https://www.kaggle.com/next/kernels/editor.js?v=1587602950:391:163616     at window._events  https://kkb-production.jupyter-proxy.kaggle.net/k/32545019/eyjhbgcioijkaxiilcjlbmmioijbmti4q0jdluhtmju2iiwidhlwijoislduin0..n9zpafea0o5bxcu3lnytaq.fuil_odnqkcqegwjrnl-iknope4pnesmjh09ip7iv_hvqyfarjsihdymzpa-aromkcz5hdsih4lu80zq3xdorg.bzz9i7naym3q35btqutnuq/proxy/static/notebook/js/main.min.js?v=1b0256649fd5326c7cad4be834633ffd:4:5328    usually i use chrome as you advise i try ferifox now and all is working fine in the firefox i can edit and create new notebooks thank you    one more message from devtools  devtools failed to load sourcemap could not load content for  https://www.kaggle.com/service-worker.js.map  http error status code 404 net::err_http_response_code_failure   thanks  @dmitri9149  ! i ll investigate what s going on with chrome it may very well be connected with localstorage being disabled as you mentioned   thank you all is working fine    awesome your report helped me deploy the fix for this issue,4,0.9325220626549232,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
90418_kg,hi all emails will be sent today to all the winners with instructions on how to redeem prizes i truly apologize for the delay with this competition s winner announcements – i know many people have worked hard   winner emails have been sent out! if you did not receive one and should ve please email me directly at mark@kaggle.com i may be a bit slow to respond but will get back to all inquiries regarding this competition thank you   thanks mark i got the emails   thank you mark !! i have received the email regarding top100 prize just wanted to confirm if the fun prizes are also selected if yes it would be great if you could share the winners list thank you :   hi  has kaggle chosen and sent emails to the winners of the top 5 creative team names competition and the other special prizes as well?  nan  hi mark was the top 5 team name prize available? if so please publish the winner list thanks,17,0.9320199138748594,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
101746_kg,hello  i have two datasets and one utility kernel added to my kernel s workspace and its status doesn t change from loading... killing kernel s session restarting it and changing the version of docker have not been helpful  any help would be appreciated!       @amiralisa  we were experiencing site issues at the time but this should now be resolved are you still experiencing this issue? if so please reply back with the kernel url    @ian  yes i m still experiencing the same issue the kernel is private so please let me know how can i share the url    @amiralisa  can you disable all of your browser extensions and try to access your account again? i m wondering if one of them is preventing your kernel from connecting    @ian  i can connect to my kernel but the workspace list on the right side is constantly loading which does not allow me to add or remove datasets!     @amiralisa  what browser are you using? what is the url of your kernel? can you try to log into your account in incognito or private mode then tell us what happens when you try accessing the kernel again here?    @ian  i also have faced the same issue tried different browsers incognito mode no difference my url  https://www.kaggle.com/soheilsadeghii/maskrcnn-v01/edit/run/18239896  can you please help me with that?    @ian  browser chrome v75kernel url  link   i removed all local session and cache storages on my browsers i also checked the kernel in incognito mode but it didn t get fixed! seems the issue isn t caused by cookies!     @soheilsadeghii  you can download your notebook then create a new kernel and upload the downloaded notebook on it  please notice that you might lose the previous versions of your codings,4,0.9318550618546294,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
38461816_so,serialization tensorflow example to save and load a sub graph in tensorflow i created a model within a variable/name scope and would like to store its graph definition and variables to disk to later load it without defining the graph again how can i save and load all operations and variables within a given variable/name scope?  conveniently i would like to just use     its   has an option to store the meta graph but   does not seem to import it moreover in the saver constructor i can specify a list of parameters but not a name scope to control what operations are saved  there is also     but i couldn t find an explanation of what it is and how it relates to the saver class and meta graph ,7,0.9317206220401157,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
101693_kg,hello everyone!  please help me to understand which of the following is correct and why  i  1 x_train x_test  split the training set into training and test sets2 x_train_std      standardize x_train3 x_train_res      oversample x_train_std4 model.fit        train the model using x_train_res5 x_test_std       standardize x_test using the parameters calculated in 26 model.evaluate   evaluate the model using x_test_std  ii  1 x_train x_test  split the training set into training and test sets2 x_train_std      standardize x_train3 x_train_res      oversample x_train_std4 x_train_res_std  standardize x_train_res5 model.fit        train the model using x_train_res_std6 x_test_std       standardize x_test using the parameters calculated in 47 model.evaluate   evaluate the model using x_test_std  thanks in advance,1,0.9313122389823513,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
35675816_so,c++ character detection opencv extracting part of an image outlined with a red box with opencv c+ i have the following image  example image     i need to recognize the character within it to do this i want to produce a mask to remove everything but the red box  what is the best method i could use to do this?   currently i use a hsv filter to produce a mask and use the mask to crop the image to just the red square   this produces a poor mask as it has the t itself excluded depending on how i view the image i need a more robust approach   -i was wondering if there is a way to make a box around the significant white region and use the box as my mask instead however i m not sure on how to implement that on opencv  with the mask i apply a canny edge detection then i find the contours and fill the contours   my results  contour output and mask   the result i get isn t robust enough i ideally need to be able to detect a large sign on a grass field from an aerial video feed so it needs to work with the red square with different sizes  is there any way in which i can improve this process in general?  the character recognition method hasn t been decided yet if you just want to recognize the character    convert image to gray scale  since the character is white and rest of image is colored the character in the gray image will still be white so take a threshold and suppress all non white pixels  run your classifier to recognize the character    if you want to extract the red box    locate the red pixels then crop image,20,0.9303615467270362,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
32095_kg,congrats everyone especially plantsgo for first place and  faron for a big coming back at private lb!  and big shout out to all in top 5 when the leak got revealed! silogram mike kim vicens gaitan and manel you are all amazing!!!  well before sharing solutions i would like to share my best model and hopefully people can blend theirs with it and see how far teaming up could at least get  mine is a result of 3 level stacking the score is just the one in the private lb   50/50 average with mine   public score   0.49142   private score   0.48997   i think that means it blends ;   congrats! nice finish    55average with mine  0 0.9740178249867536 0.01 0.97784785762407112 0.02 0.98650724792319544 0.0  private:0.48995public:0.49077  private ~faron s   nice!very curious about how can you perform 0.0018 better than public.have some tricks?   pearsonr:0.98606428106480981 0.00.97714043105030801 0.00.97912725894633068 0.07:3 with mine scorespublic:0.49327private:0.49228   thanks for sharing! i m also curious about your best single model before stack and stacking strategy if you don t mind to share for me my linear stack and xgb just don t provide any good haven t try stacknet yet      low 0.98489397793611533medium 0.97527199635114747high 0.97440052990826242     private  0.49146  public 0.49222  i am very admire you sincerely grandmaster!   high              medium            low  0.973187140294704  0.974392738809743  0.985509375724451  and my 50/50 average score is  public 0.49187   private 0.49108   you also had a huge jump on last day what was your secrete? :   the power of stacknet?    you also had a huge jump on last day what was your secrete? :    the power of stacknet?   yes !  i made a two-level stacknet consisting of mostly gbms and nns on the first layer and 1 gbm 1 nn and 1 linear model in the second layer  the linear model surprisingly over-fitted though!   stacking gave me about +0.01 in total for this competition as my best single model was 0.507x before stacking and 0.497x after  stacking,14,0.9300024190354054,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
16973_kg,tried to submit my first submission but seems like they are not accepting anymore entries  the deadline does not specify any time zone   &quot;october 12 2015 - first submission deadline your team must make its first submission by this deadline&quot  is there a way to contact the administrator of this competition   it s in the competition rules all times are utc pretty sure that goes for almost all kaggle competitions  &quot;competition timeline  start date 8/14/2015 2:23:08 pm utc  merger deadline 10/12/2015 11:59:00 pm utc  first submission deadline 10/12/2015 11:59:00 pm utc  end date 10/19/2015 11:59:00 pm utc&quot   https://www.kaggle.com/c/springleaf-marketing-response/rules,17,0.9297447729204156,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
59270347_so,deep-learning machine-learning python pytorch is my pytorch code something wrong? the submission file get around 5% always i m practicing image classification with cifar10  but this train result showed like  but when i submit the file it only shows very low score   please check my code       ================================ 0 ================================ 0 [  451   452   453 .. 21514 21515 21516] [    0     1     2 .. 18402  18403 18404] | epoch 01 | train loss 0.993 | train acc 60.42% |  val loss 0.771 | val acc 70.26% | 1 [    0     1     2 .. 21514  21515 21516] [  451   452   453 .. 18847 18848 18849] | epoch 01 |  train loss 0.608 | train acc 76.40% | val loss 0.770 | val acc:  69.69% | 2 [    0     1     2 .. 21514 21515 21516] [  902   903   904 .. 19292 19293 19294] | epoch 01 | train loss 0.506 | train  acc 80.91% | val loss 0.723 | val acc 72.83% | 3 [    0     1   2 .. 21514 21515 21516] [ 1353  1354  1355 .. 19737 19738 19739] |  epoch 01 | train loss 0.440 | train acc 83.44% | val loss 0.622 |  val acc 77.80% | 4 [    0     1     2 .. 21514 21515 21516] [ 1803   1804  1805 .. 20182 20183 20184] | epoch 01 | train loss 0.394 |  train acc 85.42% | val loss 0.498 | val acc 81.00% | 5 [    0   1     2 .. 21514 21515 21516] [ 2253  2254  2255 .. 20626 20627  20628] | epoch 01 | train loss 0.358 | train acc 87.03% | val.  loss 0.476 | val acc 82.19% | 6 [    0     1     2 .. 21514 21515  21516] [ 2703  2704  2705 .. 21070 21071 21072] | epoch 01 | train  loss 0.334 | train acc 87.72% | val loss 0.417 | val acc 84.53%  | 7 [    0     1     2 .. 21070 21071 21072] [ 3153  3154  3155 ...  21514 21515 21516] | epoch 01 | train loss 0.321 | train acc 88.36%  | val loss 0.439 | val acc 83.53% |  ================================ 1 ================================ 0 [  451   452   453 .. 21514 21515 21516] [    0     1     2 .. 18402  18403 18404] | epoch 02 | train loss 0.282 | train acc 89.77% |  val loss 0.349 | val acc 87.34% | 1 [    0     1     2 .. 21514  21515 21516] [  451   452   453 .. 18847 18848 18849] | epoch 02 |  train loss 0.273 | train acc 90.36% | val loss 0.316 | val acc:  88.26% | 2 [    0     1     2 .. 21514 21515 21516] [  902   903   904 .. 19292 19293 19294] | epoch 02 | train loss 0.258 | train  acc 90.70% | val loss 0.308 | val acc 88.73% | 3 [    0     1   2 .. 21514 21515 21516] [ 1353  1354  1355 .. 19737 19738 19739] |  epoch 02 | train loss 0.238 | train acc 91.72% | val loss 0.316 |  val acc 88.79% | 4 [    0     1     2 .. 21514 21515 21516] [ 1803   1804  1805 .. 20182 20183 20184] | epoch 02 | train loss 0.233 |  train acc 91.46% | val loss 0.311 | val acc 88.37% | 5 [    0   1     2 .. 21514 21515 21516] [ 2253  2254  2255 .. 20626 20627  20628] | epoch 02 | train loss 0.225 | train acc 91.99% | val.  loss 0.291 | val acc 89.71% | 6 [    0     1     2 .. 21514 21515  21516] [ 2703  2704  2705 .. 21070 21071 21072] | epoch 02 | train  loss 0.209 | train acc 92.53% | val loss 0.235 | val acc 90.95%  | 7 [    0     1     2 .. 21070 21071 21072] [ 3153  3154  3155 ...  21514 21515 21516] | epoch 02 | train loss 0.195 | train acc 93.05%  | val loss 0.242 | val acc 91.30% |  ================================ 2 ================================ 0 [  451   452   453 .. 21514 21515 21516] [    0     1     2 .. 18402  18403 18404] | epoch 03 | train loss 0.197 | train acc 92.96% |  val loss 0.240 | val acc 91.13% | 1 [    0     1     2 .. 21514  21515 21516] [  451   452   453 .. 18847 18848 18849] | epoch 03 |  train loss 0.186 | train acc 93.13% | val loss 0.195 | val acc:  93.16% | 2 [    0     1     2 .. 21514 21515 21516] [  902   903   904 .. 19292 19293 19294] | epoch 03 | train loss 0.179 | train  acc 93.60% | val loss 0.241 | val acc 91.04% | 3 [    0     1   2 .. 21514 21515 21516] [ 1353  1354  1355 .. 19737 19738 19739] |  epoch 03 | train loss 0.166 | train acc 94.07% | val loss 0.210 |  val acc 91.95% | 4 [    0     1     2 .. 21514 21515 21516] [ 1803   1804  1805 .. 20182 20183 20184] | epoch 03 | train loss 0.161 |  train acc 94.28% | val loss 0.220 | val acc 91.81% | 5 [    0   1     2 .. 21514 21515 21516] [ 2253  2254  2255 .. 20626 20627  20628] | epoch 03 | train loss 0.158 | train acc 94.18% | val.  loss 0.203 | val acc 93.05% | 6 [    0     1     2 .. 21514 21515  21516] [ 2703  2704  2705 .. 21070 21071 21072] | epoch 03 | train  loss 0.149 | train acc 94.73% | val loss 0.197 | val acc 93.18%  | 7 [    0     1     2 .. 21070 21071 21072] [ 3153  3154  3155 ...  21514 21515 21516] | epoch 03 | train loss 0.154 | train acc 94.35%  | val loss 0.218 | val acc 91.24% |  ================================ 3 ================================ 0 [  451   452   453 .. 21514 21515 21516] [    0     1     2 .. 18402  18403 18404] | epoch 04 | train loss 0.150 | train acc 94.64% |  val loss 0.142 | val acc 94.86% | 1 [    0     1     2 .. 21514  21515 21516] [  451   452   453 .. 18847 18848 18849] | epoch 04 |  train loss 0.143 | train acc 95.04% | val loss 0.173 | val acc:  93.62% | 2 [    0     1     2 .. 21514 21515 21516] [  902   903   904 .. 19292 19293 19294] | epoch 04 | train loss 0.157 | train  acc 94.46% | val loss 0.182 | val acc 93.51% | 3 [    0     1   2 .. 21514 21515 21516] [ 1353  1354  1355 .. 19737 19738 19739] |  epoch 04 | train loss 0.137 | train acc 95.17% | val loss 0.225 |  val acc 91.43% | 4 [    0     1     2 .. 21514 21515 21516] [ 1803   1804  1805 .. 20182 20183 20184] | epoch 04 | train loss 0.136 |  train acc 95.17% | val loss 0.164 | val acc 94.18% | 5 [    0   1     2 .. 21514 21515 21516] [ 2253  2254  2255 .. 20626 20627  20628] | epoch 04 | train loss 0.124 | train acc 95.60% | val.  loss 0.147 | val acc 94.85% | 6 [    0     1     2 .. 21514 21515  21516] [ 2703  2704  2705 .. 21070 21071 21072] | epoch 04 | train  loss 0.122 | train acc 95.73% | val loss 0.149 | val acc 94.64%  | 7 [    0     1     2 .. 21070 21071 21072] [ 3153  3154  3155 ...  21514 21515 21516] | epoch 04 | train loss 0.119 | train acc 95.88%  | val loss 0.155 | val acc 94.36% |  ================================ 4 ================================ 0 [  451   452   453 .. 21514 21515 21516] [    0     1     2 .. 18402  18403 18404] | epoch 05 | train loss 0.126 | train acc 95.49% |  val loss 0.117 | val acc 95.92% | 1 [    0     1     2 .. 21514  21515 21516] [  451   452   453 .. 18847 18848 18849] | epoch 05 |  train loss 0.119 | train acc 95.79% | val loss 0.132 | val acc:  95.32% | 2 [    0     1     2 .. 21514 21515 21516] [  902   903   904 .. 19292 19293 19294] | epoch 05 | train loss 0.115 | train  acc 96.00% | val loss 0.129 | val acc 95.39% | 3 [    0     1   2 .. 21514 21515 21516] [ 1353  1354  1355 .. 19737 19738 19739] |  epoch 05 | train loss 0.108 | train acc 96.16% | val loss 0.146 |  val acc 94.93% | 4 [    0     1     2 .. 21514 21515 21516] [ 1803   1804  1805 .. 20182 20183 20184] | epoch 05 | train loss 0.116 |  train acc 95.78% | val loss 0.139 | val acc 95.04% | 5 [    0   1     2 .. 21514 21515 21516] [ 2253  2254  2255 .. 20626 20627  20628] | epoch 05 | train loss 0.113 | train acc 96.05% | val.  loss 0.136 | val acc 94.75% | 6 [    0     1     2 .. 21514 21515  21516] [ 2703  2704  2705 .. 21070 21071 21072] | epoch 05 | train  loss 0.111 | train acc 96.08% | val loss 0.114 | val acc 95.88%  | 7 [    0     1     2 .. 21070 21071 21072] [ 3153  3154  3155 ...  21514 21515 21516] | epoch 05 | train loss 0.100 | train acc 96.52%  | val loss 0.120 | val acc 95.74%  ,13,0.928864156800828,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
49243416_so,python tensorflow add row to batch of tensorflow tensors i have rank 3 tensors [batch_size num_rows num_cols] to which i would like to append rows of the appropriate size resulting in rank 3 tensors with dimensions [batch_size num_rows + 1 num_cols]  for example if i have the following batch of 2x2 matrices   and a new row   i would like to append then the desired result is   is there a simple way to do this in tensorflow?  here is what i tried   to clarify the terms     has dimensions      has dimensions      has dimensions      and   both have dimensions     what i want to do   add vector   to   resulting in a tensor with dimensions    add vector   to   resulting in a tensor with dimensions    add a 1 to   resulting in a tensor with dimensions     thank you for your help you can use     to do this   output,5,0.9279108431827442,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
7700_kg,"hi iam amogh ,iam new to kaggle and iam lloking for team members with whom i can work with in this competition  please contact me @ amogh.gupta@gmail.com  thanks   hey amogh  hope you re doing good can i join your team?  cheers  rajiv   i m also interested in joining a team.&nbsp   yes sure   hello ruth i think you should go ahead make a team and we can all join in and then start doing work asap   i dont know if it is late can i also join the team   can all of you guys email me with your contact information? &nbsp;neilmpatel@gmail.com   rajiv55bits@gmail.com   subgeeth@gmail.com   amogh.gupta@gmail.com   psa there is no point in forming teams with email addresses you need real people that can work with you",17,0.9267604075244589,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
57070164_so,python tensorflow variables how to retrieve all the tf.variable values after initialization by looping through the graph object i used a loop to iterate over the tensorflow graph and retrieve the values of constant tensors  i tried to find a similar way to retrieve the values of variable tensors by iterating through the elements but i did not find any solution  here is a sample code:the session run method is already invoked.this loop iterates over the graph and retrieves the values of tensor constants     the snippet  n.attr.get value .tensor.int_val[0]  gets the value of constant if it is a single number    otherwise the statement bellow retrieves the values of the tensor and stores them into a ndarray  tensor_util.makendarrayn.attr[ value ].tensor    so i tried this   i am aware that i can retrieve the values of the variables with session run or eval methods for the specified elements.but here i would like to loop over the graph elements  related links      how do i get the current value of a variable?      https://www.tensorflow.org/guide/variables      how to access tensor_content values in tensorproto in tensorflow resolved  after debugging and observing the tensorboard graph i realized that only the variable_weights/initial_value node has the actual values after session run so the solution above is working since variable_weights/initial_value is a constant tensorflow node that is automatically created and is the input to the assigned node of tensorflow variable  every variable in the tensorflow graph has 4 operations/nodes the variable identity assign and const which is the initial_value  at first i thought that the  variable  node will return the values  but eventually i invoked the snippet bellow in initial_value node and gets the values  solution,7,0.9266867364379507,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
104030_kg,"hi all,i am new to kaggle and its a fantastic experience here!a few days back when i was having fun running kernels and submitting the limit was 5 submissions but today it s 3 is it because today is the last day?  cheers!   5 might be for a different competition  this competition it was always 3 i guess.   must be true :p   can you still submit and get lb score after the competition ends?      you may select up to 2 submissions to be used to count towards your final leaderboard score if 2 submissions are not selected they will be automatically chosen based on your best submission scores on the public leaderboard in the event that automatic selection is not suitable manual selection instructions will be provided in the competition rules or by official forum announcement   isn t it 2?   not for final scoring for public lb scores   per day submission limit  i think thats what he is asking   the daily limit for this competition has always been 3 other competitions are typically 5   yes all completed competitions let you submit afterward and get a score of course it doesn t affect your final standing in the competition",17,0.9265340718726952,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
45836979_so,c++ python tensorflow tensorflow r1.3 estimator.dnnclassifier save and load graph i am using the latest tensorflow release 1.3.0 and created a dnnclassifier via   and trained it in python  how can i save and reuse the graph/model in c++?i only found tutorials to load the   which is not what i would like to do.. i know that checkpoints are saved automatically but i would like to load the created graph to make predictions in c++ and the only file saved automatically is a   besides many   and   filfes can i load that file like a   ,7,0.9264964175245067,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
39382725_so,json python tensorflow saving python list containing tensorflow sparsetensors to file for later access i m creating a list of sparsetensors in tensorflow i want to access them in later sessions of my program i ve read online that you can store python lists as json files but how do i save a list of sparsetensors to a json file and then use that later on?  thanks in advance a tensor in tensorflow is a node in the graph which when run will produce a tensor so you can t save the sparsetensor directly because it s not a value you can serialize the graph if you do evaluate the sparsetensor you get a sparsetensorvalue object back which can be serialized as it s just a tuple,7,0.9256148482067559,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
14331_kg,we re in the process of going through submissions and catching the cheaters yes for those of you that didn t cheat you will likely move up places  since this competition is the most popular ever in kaggle history it s taking longer than normal please be patient and we ll announce it when it s final.&nbsp  in the mean time we like seeing all these scripts and the sharing in the community keep them coming!   wow.. number of teams dropped from 3560 to 3514...&nbsp   there was one person in the top 20 i wasn t surprised got removed otto was this person s&nbsp;first and only contest while that s possible of course it also reeks of cheating   it was 3590 participants not 3560 i know because i ended up at 360 on the private lb ;   [quote=inversion;79593]  there was one person in the top 20 i wasn t surprised got removed otto was this person s&nbsp;first and only contest while that s possible of course it also reeks of cheating  [/quote]  who?   [quote=abhishek;79596]  [quote=inversion;79593]  there was one person in the top 20 i wasn t surprised got removed otto was this person s&nbsp;first and only contest while that s possible of course it also reeks of cheating  [/quote]  who?  [/quote]  my mistake wasn t removed just moved down the private lb   cheaters removal is done!   [quote=william cukierski;79612]  cheaters removal is done!  [/quote]  points coming soon?   [quote=abhishek;79771]  points coming soon?  [/quote]  points have arrived!   tiny bug public leaderboard rankings are displayed in profiles   [quote=c&#233;dric gouy-pailler;79774]  tiny bug public leaderboard rankings are displayed in profiles  [/quote]  i confirm that   fixed now and thanks for pointing that out it was still cached and needed a kick to refresh   is it what it is now,17,0.9252549803330363,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
108506_kg,some of the top teams got removed from the leaderboard as mentioned  here  i m sure that kaggleand competition organizers have valid reasons for that.some of those reasons could making fake accounts as confessed  here  or merging with somebody who is guilty of violating the rules i cannot talk for everybody who got removed but i think  @lanjunyelan   whose work i have been following closely in this and other  competitions  is skilled enough to secure top positions in kaggle competitions even without cheating/breaking rules as can be seen in his  profile  sadly he got removed maybe for merging :participating in a kaggle competitions and making into top5 takes a lot of time hard-work and dedication and when all of that goes away you have to feel for that person   i hope we all learn from this experience and merge with people who wants to compete within the spirit of the competition   thank you for your understanding yeah i feel upset about the results i guess the main reason for our result being removed is one team member having multiple accounts he has already deleted all his accounts by far hope it s a lesson for every kaggler good luck to everyone     @lanjunyelan  i know you will earn many more golds so let us move forward   i am sure  @lanjunyelan  that you will get more golds my best wishes for other competitions    thank you let s move forward,17,0.9248082939571306,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
37090828_so,apache-spark bigdata hadoop yarn which mode we should use when running spark on yarn i know there are two modes while running spark applications on yarn cluster  in  yarn-cluster  mode the driver runs in the application master inside a yarn cluster in  yarn-client  mode it runs in the client node where the job is submitted  i wanted to know what are the advantages of using one mode over the other ? which mode we should use under what circumstances there are two deploy modes that can be used to launch spark applications on yarn     yarn-cluster  the spark driver runs within the hadoop cluster as a yarn application master and spins up spark executors within yarn containers this allows spark applications to run within the hadoop cluster and be completely decoupled from the workbench which is used only for job submission an example   note that in the example above the –queue option is used to specify the hadoop queue to which the application is submitted     yarn-client  the spark driver runs on the workbench itself with the application master operating in a reduced role it only requests resources from yarn to ensure the spark workers reside in the hadoop cluster within yarn containers this provides an interactive environment with distributed operations here’s an example of invoking spark in this mode while ensuring it picks up the hadoop lzo codec     so when you want interactive environment for your job you should use  client mode  the yarn-client mode accepts commands from the spark-shell  when you want to decouple your job from spark workbench use yarn cluster mode,15,0.9242583880001715,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
77774_kg,"can the people on 0.700 on the public lb kindly share their local cv scores i m at 0.6811 5 fold whenever my local cv increases above 0.6811 my public lb falls to 0.695 or something should i trust my local cv over the public lb ?   my score cv :0.6803lb :0.7i got the same observation with you about the 0.6811 thing i dont know whether should i trust the my cv or lb now haha   0.6749   cv 0.6725 5 fold lb:0.700it s an overfitting result though   cv 0.6884lb 0.7b.t.w relation between my cv and lb is very strange,i don t have any idea about this   admittedly i ve only made a single submission as i m just starting but am getting a cv over 0.69 so far   cv 693 lb 697cv 691 lb 701cv 692 lb 702cv 690 lb701cv 690 lb 697cv 695 lb 693upadate:cv 698 lb still 695cv 699 lb still 694....cv 700 lb still 694...   my score cv :0.6795lb :0.7   my score cv --&gt 0.6782 lb --&gt 0.703   hi i notice that val score is very similar to your public kernel may i ask what changed to get you up on  lb? it doesn t have to be very specific just the direction maybe more preprocessing or a different architecture or ensembling?    i got local 0.692-&gt lb0.702   cv 0.6777 lb 0.704amazing,trying to reproduce it   cv 0.6786 lb 0.701   really strong cv   sorry it was 0.6786 my mistake   cv 0.6811 lb 0.702   no problem makes sense now   cv 0.6909 loss 0.0958 correlation 0.9515 lb 0.702  another submission cv 0.6804 lb 0.702  the first one is only slightly better than the second :   cv = 0.696892lb = 0.702   i have two modelscv 683 lb 704cv 679 lb 705",14,0.9234526959588542,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
50072480_so,tensorflow tensorflow eager store and restore trainable variables i ve written a custom model with tensorflow eagersimilar to this  example  i want to store/restore just my trainable variables - something similar to the following non-eager logic how can i do this within eager eager execution in tensorflow encourages encapsulating model state in objects for example in   objects the state of these objects the checkpointed values of variables can then be saved and restored using      note that the   class is compatible with both eager and graph execution  you ll see this used in examples in the tensorflow repository such as  this  and  this   hope that helps,7,0.9230717592587633,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
54977125_so,"keras python tensorflow feeding input into keras sequential model i m working on time series prediction with keras i have 10 timesteps in my input data which is of the shape   i.e train_x.shape and train_y.shape is 2688 10 1.i am getting the following error while i try to feed it into the model   the input shape that i am giving to the first lstm layer  **     am i reshaping train_y properly?   * if you expected shape 2688 10 1 then it cant be input_shape=1 time_steps it should input_shape=time_steps,1    i think the error is here you should have given the time steps between shape[0] and shape[1] i.e..   here the value  10  denotes the time steps",5,0.9228481216999291,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
104869_kg,i am doing  news category prediction  of indian news articles  i have used using pre trained fasttext crawl 300d 2m    my vocab size is approx 34500 in unknown words are approx 8500 unknown words are like  [ tiktok   pulwama   nyay   mpmp   kumaraswamy   amethi   samajwadi   jaitley   kalank   mamata   mlas   balakot   ysrcp   aiadmk   sumalatha   trinamool   chandrababu   fadnavis   avengersendgame   vadra   bytedance   evms   desam   msci   ysr   polycab   bareli   vvpat   anantnag   samithi   deora   mcfeely   fortnite   beresheet   munnetra   yeddyurappa   gdpr   aimim   rajnath   dravida   dhfl   mainpuri   fpis   kazhagam   uddhav   mindtree   adityanath   baramati   canalys   nasscom   ambareesh  ] how i can handle these words in word embedding   can you please elaborate    mark all unknown words as unk and then create a word embedding for unk word to represent all unknown words  use character level embedding so that during training if any unknwon words occurs then model will try to learn its representation using character embeddings,12,0.922749722699274,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
52088754_so,c++ protocol-buffers tensorflow what is a difference between tf.graphdef.fromstring and tf.graphdef.parsefromstring what is a difference between  tf.graphdef.fromstring  and  tf.graphdef.parsefromstring  ? i cannot find anything for fromstring in tensorflow documentaion   i am trying to run a model protobuf file in c++ but the prediction output is empty in python example the model is loaded using  tf.graphdef.fromstring  function in c++ i am using  readbinaryproto  method i am wondering if there is some other way to load the model in c++ that corresponds to  tf.graphdef.fromstring ,7,0.9220642157525833,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
85003_kg,"my best single model  is  cv score 0.9112lb:0.901can you tell me the cv score and pb score of your best signal model??????????   our best single modellgbm   cv = 0.901983 // lb = 0.901    my best single model is cv 0.9018 lb 0.901  btw there is already a topic for it  best single model    thank you could i asking you that how do you get this score? fe or tuning parameters?   oh! i don t find it thank you   used both of them but we didn t put much effort on tuning hyper parameters   i guess you used fe to get this high cv right?   yeah,but i m overfitting",14,0.9217784004899978,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
46258416_so,tensorflow create indices for a 2d tensor i m trying to do something like this  suppose the input tensor is a   tensor with the value like   i am flattening the 2d tensor into 1d by doing   so the input now becomes    but i also create a 1d tensor that indexes the previous tensor so the desired output is   how should i create this tensor in tf?  in general if the input tensor has a shape of   i would like to create a 1d tensor that looks like   where each value is repeated y - 1 times here is one way to do it what this does is first create a single row indices and then repeat each indice by the number of columns the original tensor has using   reshaping the 2d indices back gives what you need,5,0.9216940067411424,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
37464879_so,c# emgucv image-segmentation opencv segmenting only face in an image in emgucv i am hoping to achieve something similar to what is shown in this  video    i have been able to detect face in image and then cropping a rectangle containing the face using haar cascade classifier but because faces are not completely rectangle some of the background are still shown in the cropped image   i am trying to achieve what was shown in the video so i can remove the background part of the cropped image   is there any way to do it using emgucv?   thank you ,20,0.9208380317523774,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
3521_kg,"the&nbsp;lean startup conference&nbsp;prize of $2,000 will be awarded at the end of the hospital quest competition &nbsp;to be eligible to win the prize a team must include one or more members registered with the lsu conference 2012  &nbsp;see the  rules  for more details on eligibility for the lsu prize &nbsp  if you were registered at the conference you can record your eligibility for the prize by sending an email to lsuprize@kaggle.com before the submission deadline on february 17 2013 &nbsp;the email should have subject line &quot;lsu prize&quot and it should include the relevant team member s full name display name and the email address used when registering for the conference  if you already registered your eligibility via an email to kaggle support you do not need to register again",17,0.9205680291139297,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
39052558_so,"artificial-intelligence machine-learning optimization regularized cost function with very large λ consider the cost function with regularization in machine learning        why will the parameter θ towards to zero when we set the parameter λ to be very large please also note that the summation after lambda doesn t include theta0 hope this helps!  the regularized cost function is penalized by the size of the parameters θ   the regularization term dominates the cost in case     it is worth noting that when λ is very large most of the cost will be coming from the regularization term   and not the actual cost   hence in that case it s mostly about minimizing the regularization term   by tending θ towards 0     why minimizing   results in     consider the regularization term   to minimize this term the only solution is to push     is a positive constant and the   term is also positive  and since   terms are squared   is always positive the only way is to push the   parameters towards 0 hence   means     so to sum up in this case of very large λ   minimizing the cost function is mostly about minimizing   which requires minimizing   which requires     some intuition to answer the question in the comment   think of λ as a parameter for you to tell how much of a regularization you want to happen e.g if on the extreme you set λ to 0 then your cost function is not regularized at all if you set λ to a lower number then you get less of a regularization  and vice versa the more you increase λ the more your asking your cost function to regularized so the smaller the parameters θ will have to be in order to minimize the regularized cost function   why do we use θ² in the regularization sum rather than θ？   because the goal is to have small θ less prone to overfitting.if the regularization term uses θ instead of θ² in the sum you can end up with  large θ values that cancel each other ,e.g θ_1 = 1000000 and θ_2 = -1000001 the   here is -1 which is small vs if you took   absolute value or   squared you d end up with a very big value  in that case you may end up overfitting because of large θ values that escaped the regularization because the terms cancel each other out",3,0.9204062896813827,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
90339_kg,1st place solution  by sandeep    3rd place solution  by abzaliev   4th place solution  by justin   5th place solution  by ken   7th place solution  by bo   8th place solution  by louisclouatre   9th place solution  by rakesh   11th place solution  by hikkiiiiiiiii   12th place solution  by pavel   15th place solution  by ilia   22nd place solution  by yury   26th place solution  by ivan   33rd place solution  by pavel   will update this as we get more solutions from the toppers     read the rules first and don t blame people without any foundations for that,17,0.9202492669170252,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
53987906_so,pytorch scalar tensor how to multiply row-wise by scalar in pytorch when i have a tensor   of shape   and a vector   of scalars with shape   how can i multiply each row of   with the corresponding scalar in   you need to add a corresponding singleton dimension     has size of   when multiplying a   tensor by a   tensor pytoch knows to  broadcast    along the second singleton dimension and perform the element-wise product correctly,5,0.920174709153588,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
51161950_so,opencv python ubuntu-16.04 linking cxx executable ../../bin/opencv_test_videostab collect2 error while installing opencv  executing  make -j1   i am getting the following error   built target opencv_test_videoiobuilt target opencv_perf_videoio_pch_dephelpbuilt target pch_generate_opencv_perf_videoiobuilt target opencv_perf_videoiobuilt target opencv_xobjdetect_pch_dephelpbuilt target pch_generate_opencv_xobjdetectbuilt target opencv_xobjdetectbuilt target opencv_waldboost_detectorbuilt target opencv_test_highgui_pch_dephelpbuilt target pch_generate_opencv_test_highguibuilt target opencv_test_highguibuilt target opencv_superres_pch_dephelpbuilt target pch_generate_opencv_superresbuilt target opencv_superresbuilt target opencv_test_superres_pch_dephelpbuilt target pch_generate_opencv_test_superresbuilt target opencv_test_superresbuilt target opencv_perf_superres_pch_dephelpbuilt target pch_generate_opencv_perf_superresbuilt target opencv_perf_superresbuilt target opencv_bioinspired_pch_dephelpbuilt target pch_generate_opencv_bioinspiredbuilt target opencv_bioinspiredbuilt target example_bioinspired_openexrimages_hdr_retina_tonemappingbuilt target opencv_test_bioinspired_pch_dephelpbuilt target pch_generate_opencv_test_bioinspiredbuilt target opencv_test_bioinspiredbuilt target example_bioinspired_retinademobuilt target opencv_perf_bioinspired_pch_dephelpbuilt target pch_generate_opencv_perf_bioinspiredbuilt target opencv_perf_bioinspiredbuilt target opencv_dpm_pch_dephelpbuilt target pch_generate_opencv_dpmbuilt target opencv_dpmbuilt target example_dpm_cascade_detect_camerabuilt target example_dpm_cascade_detect_sequencebuilt target opencv_test_features2d_pch_dephelpbuilt target pch_generate_opencv_test_features2dbuilt target opencv_features2d_pch_dephelpbuilt target pch_generate_opencv_features2dbuilt target opencv_features2dbuilt target opencv_test_features2dbuilt target opencv_perf_features2d_pch_dephelpbuilt target pch_generate_opencv_perf_features2dbuilt target opencv_perf_features2dbuilt target opencv_test_line_descriptor_pch_dephelpbuilt target opencv_line_descriptor_pch_dephelpbuilt target pch_generate_opencv_line_descriptorbuilt target opencv_line_descriptorbuilt target example_line_descriptor_knn_matchingbuilt target example_line_descriptor_lsd_lines_extractionbuilt target pch_generate_opencv_test_line_descriptorbuilt target opencv_test_line_descriptorbuilt target example_line_descriptor_compute_descriptorsbuilt target opencv_perf_line_descriptor_pch_dephelpbuilt target pch_generate_opencv_perf_line_descriptorbuilt target opencv_perf_line_descriptorbuilt target example_line_descriptor_matchingbuilt target example_line_descriptor_lines_extractionbuilt target example_line_descriptor_radius_matchingbuilt target opencv_saliency_pch_dephelpbuilt target pch_generate_opencv_saliencybuilt target opencv_saliencybuilt target example_saliency_computesaliencybuilt target opencv_text_pch_dephelpbuilt target pch_generate_opencv_textbuilt target opencv_textbuilt target example_text_textdetectionbuilt target example_text_end_to_end_recognitionbuilt target opencv_test_text_pch_dephelpbuilt target pch_generate_opencv_test_textbuilt target opencv_test_textbuilt target example_text_cropped_word_recognitionbuilt target example_text_segmented_word_recognitionbuilt target example_text_character_recognitionbuilt target example_text_dictnet_demobuilt target example_text_webcam_demobuilt target opencv_test_calib3d_pch_dephelpbuilt target pch_generate_opencv_test_calib3dbuilt target opencv_calib3d_pch_dephelpbuilt target pch_generate_opencv_calib3dbuilt target opencv_calib3dbuilt target opencv_test_calib3dbuilt target opencv_perf_calib3d_pch_dephelpbuilt target pch_generate_opencv_perf_calib3dbuilt target opencv_perf_calib3dbuilt target opencv_ccalib_pch_dephelpbuilt target pch_generate_opencv_ccalibbuilt target opencv_ccalibbuilt target example_ccalib_multi_cameras_calibrationbuilt target example_ccalib_omni_calibrationbuilt target example_ccalib_random_pattern_calibrationbuilt target example_ccalib_random_pattern_generatorbuilt target example_ccalib_omni_stereo_calibrationbuilt target opencv_datasetsbuilt target example_datasets_ar_hmdb_benchmarkbuilt target example_datasets_tr_chars_benchmarkbuilt target example_datasets_tr_icdar_benchmarkbuilt target example_datasets_slam_kittibuilt target example_datasets_ar_sportsbuilt target example_datasets_or_pascalbuilt target example_datasets_msm_middleburybuilt target example_datasets_pd_caltechbuilt target example_datasets_tr_icdarbuilt target example_datasets_fr_lfw_benchmarkbuilt target example_datasets_fr_lfwbuilt target example_datasets_is_bsdsbuilt target example_datasets_or_sunbuilt target example_datasets_slam_tumindoorbuilt target example_datasets_ir_affinebuilt target example_datasets_or_mnistbuilt target example_datasets_tr_charsbuilt target example_datasets_is_weizmannbuilt target example_datasets_track_votbuilt target example_datasets_msm_epflbuilt target example_datasets_gr_chalearnbuilt target example_datasets_pd_inriabuilt target example_datasets_ar_hmdbbuilt target example_datasets_hpe_parsebuilt target example_datasets_gr_skigbuilt target example_datasets_tr_svtbuilt target example_datasets_ir_robotbuilt target example_datasets_fr_adiencebuilt target example_datasets_or_imagenetbuilt target example_datasets_hpe_humanevabuilt target example_datasets_tr_svt_benchmarkbuilt target opencv_rgbd_pch_dephelpbuilt target opencv_test_rgbd_pch_dephelpbuilt target pch_generate_opencv_test_rgbdbuilt target pch_generate_opencv_rgbdbuilt target opencv_rgbdbuilt target opencv_test_rgbdbuilt target example_rgbd_odometry_evaluationbuilt target example_rgbd_linemodbuilt target opencv_perf_stereo_pch_dephelpbuilt target opencv_stereo_pch_dephelpbuilt target opencv_test_stereo_pch_dephelpbuilt target pch_generate_opencv_test_stereobuilt target pch_generate_opencv_stereobuilt target opencv_stereobuilt target opencv_test_stereobuilt target pch_generate_opencv_perf_stereobuilt target opencv_perf_stereobuilt target example_stereo_samplebuilt target opencv_test_structured_light_pch_dephelpbuilt target pch_generate_opencv_test_structured_lightbuilt target opencv_structured_light_pch_dephelpbuilt target pch_generate_opencv_structured_lightbuilt target opencv_structured_lightbuilt target opencv_test_structured_lightbuilt target example_structured_light_cap_patternbuilt target example_structured_light_capsinpatternbuilt target example_structured_light_projectorcalibrationbuilt target example_structured_light_pointcloudbuilt target opencv_tracking_pch_dephelp ,2,0.9198886738010117,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
21597778_so,"computer-vision image-processing opencv merging with background while thresholding i am doing a project on license plate recognition system.but i am facing problem in segmenting license plate characters.i have tried cvadaptivethreshold with different window sizes,otsu and niblacks algorithm  but in most of the cases license plate characters merge with thebackground.sample images and outputs given below              in the first image all the license plate characters are connected by a white line in the bottom hence using thresholding algorithm i couldn t extract characters how can i extract characters from those  images.. ??    in the second image noise  in the background merges with foreground which connects all the characters together. how can i segment characters in these  types of images..??    is there any segmentation algorithms which can segment characters in the second image.  preprocessing find big black areas on your image and mark it as background do this for example with treshold another way might be to use  findcontours  contourarea to get the size on the result.this way you know what areas you can colour black after step 1    use otsu top image right column blue title background   colour everything you know to be background black  use opening/closing or erode/dilate not sure which will work better to get rid of small lines and to refine your resultsalternatively you could make an edge detection and merge all areas that are close together like the second 3 in your example you could check if areas are close together with a distance between the bounding box of your contours   ps i don t think you should blur your image since it seems to be pretty small already",20,0.9195169875443863,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
46653668_so,restore save tensorflow tensorflow - assign name to optimizer for future restoration i create model in tensorflow and one of last lines in it is      i wonder if i can give this tensor/operation a name so that that i can restore it by name after saving to disk?  alternatively if i cannot give it a name how can i find it in output ofthe following command according to  the docs for    yes yes you can     you can then restore the op later with     you can also store the training operation in a collection and restore it by  importing the meta graph  adding to a collection and saving looks like     and restoring looks like,7,0.9194452355567904,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
58975690_so,"algorithm cluster-analysis data-mining hierarchical-clustering how to find few similar vectors in a huge amount of vectors assume a huge amount e.g a billion of vectors e.g stored in a database all the vector have the same number of numerical values e.g each vector has 100,000 integer values there is a distance function that tells the distance between two of the vectors may be simple euclidan or something more specific most of the vectors are very distant but it might be that there are a few groups e.g around 1,000 vectors each but each group with different size that are very close to each other or even similar which algorithm can be used to find the those groups efficiently?  hierarchical clustering agglomerative should be able to find all cluster in such a dataset but i m not interested in the whole set of clusters is there any way to limit the search or using a different algorithm ",23,0.9190970867874184,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
26095886_so,android android-ndk c++ c++11 opencv error  to_string  is not a member of  std it could be duplicate but i tried all the solutions that i found on and out stackoverflow  i m making a library on c++ with opencv and trying to compile it for android  i can t use  but i m not able i tried to modify my makefile too many times my last configuration is this on   android.mk      local_path := $call my-dir      include $clear_vars      opencv_camera_modules:=off       opencv_install_modules:=on      include $local_path/jsoncpp/android.mk       include /users/rafaelruizmunoz/desktop/androiddevelopment/opencv-2.4.9-android-  sdk/sdk/native/jni/opencv.mk      opencv_lib_type:=shared      local_c_includes += $local_path       local_c_includes += /users/rafaelruizmunoz/opencvscan/opencvtry/       local_c_includes += /users/rafaelruizmunoz/desktop/rd/opencvtry/libraries/jsoncpp-  master/include      local_path := jni       local_allow_undefined_symbols := true       local_module := libxyz       local_module_name    := mylibxyz       local_src_files := androidclass.cpp main.cpp utils.cpp       local_ldlibs     += -llog -ldl      local_cppflags    := -std=c++11 cflags=-g -wall -wextra -std=c++11 -wno-write-strings   ../../include/boost      local_shared_libraries := libjsoncpp libopencv_java      include $build_shared_library   and this is my  application.mk      app_stl := gnustl_static       app_cppflags := -frtti -fexceptions       app_abi := all       app_modules := libxyz libjsoncpp      app_cppflags := -std=gnu++0x       app_cppflags += -frtti       app_cppflags += -fexceptions       app_cppflags += -ddebug       app_cppflags += -std=c++11       ndk_toolchain_version := 4.8       local_c_includes += ${android_ndk}/sources/cxx-stl/gnu-libstdc++/4.8/include      app_use_cpp0x := true   thanks in advance i ran into this issue too to_string is not available in gnu-libstdc++ out of the box i searched the sources and found that std::to_string is indeed in the lib sources/cxx-stl/gnu-libstdc++/4.9/include/bits/basic_string.h  but opted out by    after adding -d_glibcxx_use_c99 to the build std::to_string is opted in  android ndk 9+ comes with  llvm-libc++  which has full support for cpp11 features to enable it all you have to do is modify these in application.mk   and   or   you may try this,21,0.9190756291228767,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
110718_kg,i tried to do this but im only getting an accuracy of 68% please `imgsize = 64  model = sequential  model.addkeras.layers.conv2dfilters=48 padding= same  activation=  relu  kernel_size=5 input_shape=imgsize imgsize 1model.addkeras.layers.batchnormalizationmodel.addkeras.layers.activation relu model.addkeras.layers.maxpool2d  model.addkeras.layers.conv2dfilters=24 padding= same  activation=  relu  kernel_size=5 input_shape=imgsize imgsize 1model.addkeras.layers.batchnormalizationmodel.addkeras.layers.activation relu   model.addkeras.layers.conv2dfilters=12 padding= same  activation=  relu  kernel_size=5 input_shape=imgsize imgsize 1model.addkeras.layers.batchnormalization  model.addkeras.layers.flattenmodel.addkeras.layers.dense256 activation= relu model.addkeras.layers.dense1 activation= sigmoid `   hi this is a really helpful notebook i just wondering what kind of architecture that you used? or is it your research or something like that,13,0.9189025347970127,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
57083881_so,"python tensorflow tensorflow 2.0 saving trained parameters to be restored in a new file i need to save trained variables of a tensorflow 2.0 model using one of tf s built in functions like tf.train.checkpoint or any other and want to call them in a new file i am not using tf.keras.sequantial and don t want to use something like model.save_weights  i have tried tf.train.checkpoint to save variables but not sure how to restore them i used to work with tf.train.saver in tf 1.0 to save variables using sessions and restore them using tf.train.import_meta_graph and tf.train.latest_checkpoint however i haven t been able to find equivalent functionalities in tf 2.0 documentation so far   try checkpoint saver in tensorflow 2.0 format to save trained parameters w b_v b_h  saver = tf.train.checkpoint  saver.listed = [w b_v b_h]  saver.mapped = { w :saver.listed[0] b_v :saver.listed[1],  b_h :saver.listed[2]}  save_path = saver.save trained_parameters   in a new file  restorer = tf.train.checkpoint  restorer.restore trained_parameters   calling the parameters by their previously mapped names doesn t work not sure how to go about this ",7,0.9185431788932835,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
53201297_so,"python tensorflow how to perform element wise multiply for two 4d tensor of shape [1,16,16,3] and [1,4,4,3 i want to multiply element-wise two 4d tensor and store the result in a 4d tensor.i have a tensor say  a  of shape [batch_size,16,16,3] and tensor  b  of shape [batch_size,4,4,3] i want to perform a sort of tiling operation such that each 4x4x3 block of tensor  a  does element wise multiplication with tensor  b .the result is stored in a tensor  c  of shape same as tensor  a  i.e [batch_size,16,16,3] as tensor  b  has height and width are multiples of height and width of tensor  a  i should concatenate or accumulate or assign the results of 4 elementwise multiplication in tensor  c this can be done by reshaping and using  broadcasting",5,0.9179676999408861,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
48782758_so,logistic-regression machine-learning python regularized how to add l1 normalization in python i am trying to code logistic regression from scratch in this code i have i thought my cost derivative was my regularization but i ve been tasked with adding l1norm regularization how do you add this in python? should this be added where i have defined the cost derivative? any help in the right direction is appreciated regularization adds a term to the cost function so that there is a compromise between minimize cost and minimizing the model parameters to reduce overfitting you can control how much compromise you would like by adding a scalar   for the regularization term  so just add the l1 norm of theta to the original cost function   since this term is added to the cost function then it should be considered when computing the gradient of the cost function   this is simple since the derivative of the sum is the sum of derivatives so now just need to figure out what is the derivate of the term   since it is a linear term then the derivative is constant it is = 1 if theta >= 0 and -1 if theta &lt 0 note there is a mathematical undeterminity at 0 but we don t care about it   so in the function   we add,3,0.9179266223990706,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
60335_kg,"hey guys  i am confuse about this model please give same insight for this modelhere i have attach the model structure model accuracy/loss and two images  please give same inputs     images of accuracy and loss      model structure     model = sequentialmodel.addlayers.conv2d32 3 3 input_shape=img_width img_height 3model.addlayers.activation relu model.addlayers.maxpooling2dpool_size=2 2,strides=2 2  model.addlayers.conv2d32 3 3model.addbatchnormalizationmodel.addlayers.activation relu model.addlayers.maxpooling2dpool_size=2 2  model.addlayers.conv2d64 3 3model.addlayers.activation relu model.addlayers.maxpooling2dpool_size=2 2,strides=2 2  model.addlayers.conv2d64 3 3model.addbatchnormalizationmodel.addlayers.activation relu model.addlayers.maxpooling2dpool_size=2 2  model.addlayers.flattenmodel.addlayers.dense256model.addbatchnormalizationmodel.addlayers.activation relu model.addlayers.dropout0.2  model.addlayers.dense64model.addbatchnormalizationmodel.addlayers.activation relu model.addlayers.dropout0.2  model.addlayers.dense2,w_regularizer=keras.regularizers.l20.02model.addlayers.activation sigmoid   model.compilekeras.optimizers.adamlr=1e-5,loss= binary_crossentropy ,metrics=[ accuracy ]  model.summary    model accuracy and loss  epoch 1/2040/40 [==============================] - 166s - loss 0.7398 - acc 0.6250 - val_loss 3.0177 - val_acc 0.3333epoch 2/2040/40 [==============================] - 173s - loss 0.5535 - acc 0.7819 - val_loss 2.3651 - val_acc 0.3500epoch 3/2040/40 [==============================] - 176s - loss 0.4797 - acc 0.8417 - val_loss 1.4494 - val_acc 0.4242epoch 4/2040/40 [==============================] - 170s - loss 0.4429 - acc 0.8639 - val_loss 1.0453 - val_acc 0.5197epoch 5/2040/40 [==============================] - 169s - loss 0.4007 - acc 0.8958 - val_loss 0.8197 - val_acc 0.5606epoch 6/2040/40 [==============================] - 178s - loss 0.3724 - acc 0.9250 - val_loss 0.6715 - val_acc 0.6788epoch 7/2040/40 [==============================] - 177s - loss 0.3980 - acc 0.8875 - val_loss 0.6172 - val_acc 0.7273epoch 8/2040/40 [==============================] - 179s - loss 0.3269 - acc 0.9569 - val_loss 0.5640 - val_acc 0.7636epoch 9/2040/40 [==============================] - 170s - loss 0.3437 - acc 0.9431 - val_loss 0.5311 - val_acc 0.7879epoch 10/2040/40 [==============================] - 175s - loss 0.3013 - acc 0.9611 - val_loss 0.5720 - val_acc 0.7273epoch 11/2040/40 [==============================] - 175s - loss 0.3173 - acc 0.9444 - val_loss 0.5052 - val_acc 0.8182epoch 12/2040/40 [==============================] - 175s - loss 0.2766 - acc 0.9764 - val_loss 0.5077 - val_acc 0.8061epoch 13/2040/40 [==============================] - 176s - loss 0.2676 - acc 0.9778 - val_loss 0.4601 - val_acc 0.8485epoch 14/2040/40 [==============================] - 175s - loss 0.2800 - acc 0.9681 - val_loss 0.4818 - val_acc 0.8333epoch 15/2040/40 [==============================] - 168s - loss 0.2869 - acc 0.9653 - val_loss 0.4474 - val_acc 0.8636epoch 16/2040/40 [==============================] - 168s - loss 0.2480 - acc 0.9819 - val_loss 0.4207 - val_acc 0.8985epoch 17/2040/40 [==============================] - 167s - loss 0.2540 - acc 0.9847 - val_loss 0.4113 - val_acc 0.9091epoch 18/2040/40 [==============================] - 165s - loss 0.2637 - acc 0.9736 - val_loss 0.4231 - val_acc 0.8864epoch 19/2040/40 [==============================] - 178s - loss 0.2692 - acc 0.9681 - val_loss 0.4216 - val_acc 0.8939epoch 20/2040/40 [==============================] - 168s - loss 0.2465 - acc 0.9806 - val_loss 0.4119 - val_acc 0.8788     from what i can see it is not over fitting if that would be the case than you should see the training loss going lower and lower while the validation loss should start getting larger and larger after a while  this is how over fitting looks like:    thanks  @gaborvecsei",13,0.9178130898488137,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
98327_kg,there are some github repo that implement many gans by pytorch and keras. https://github.com/eriklindernoren/pytorch-gan  https://github.com/facebookresearch/pytorch_gan_zoo  https://github.com/eriklindernoren/keras-gan    self-attention-gan: https://github.com/heykeetae/self-attention-gan   fid pytorch-implement https://github.com/mseitzer/pytorch-fid,13,0.9176582476650454,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
54768657_so,python tensorflow how to get only the first component of each hidden vector generated by lstm i have the following implementation of lstm   as far as i understood   contains a sequence of hidden vectors   generated by the lstm in more details it is a list in which elements corresponds to the time steps and each element ins a 2d tensor in which the axis 0 corresponds to the batch index and the axis 1 corresponds to the dimensionality of the hidden vectors  now i would like to take the first component of each hidden vector to combine it with the corresponding input vector x how can i do it?   added   more formally i would need to take something like    however i am not sure if something like that is going to work since  outputs is not a 3d tensor it is a list of 2d tensors if you really want to use a static rnn btw static rnn are available in core tensorflow now through     then you could do it like this   if you want to have those values as a tensor instead of a list of tensors you would do   the other option would be to use a dynamic rnn to get a tensor as output,5,0.9176394946185246,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
94319_kg,my model s public lb = 1.47957 so i merged my prediction with  the great kernel  and my public lb goes from 1.47957 to 1.42195 but private lb goes from 2.48248 to 2.51561 unfortunately i use the latter for final score.my best model s public lb = 1.57065 not a high score but its private lb = 2.46863  i should trust my own val_mae   never trust completely in the public lb build a good local validation strategy and trust on it   thank you yes that s a bloody lesson i just couldn t resist the public score,14,0.9174947139455115,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
56831972_so,"python tensorflow tensorflow concatenate/stack n tensors interleaving last dimensions assume we have 4 tensors       and   which all share the same dimensions of   we want to create a new tensor   which has the shape   where the   is interleaved looping between all of the tensors  for example if       and   were tensors of all ones twos threes and fours respectively we d expect   to be something like i think another option is to use  tf.tile    it seems to me that your example array actually has the shape   rather than   anyway you can get what you need with tf.concat tf.reshape and tf.transpose a simpler example in 2d is as follows   you concatenate a and b to get a matrix of shape 2,6 then you reshape it which interleaves the rows to do this in 3d the dimension which is multiplied by 4 needs to be the last one so you may need to use tf.transpose interleave using concat and reshape then transpose again to reorder the dimensions",5,0.9173137614508033,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
142721_kg,i created the coronawhy plus dataset as a quick way to unblock folks wrestling with the kaggle vs pickle issue on the coronawhy dataset as that dataset has moved to gcp i do not plan to update it further and plan to remove the v6_text folder soon please let me know when you have repointed your kernel    https://console.cloud.google.com/storage/browser/coronawhy/nlpdatasets/v7_preprocessed?pli=1,4,0.9170590626358112,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
109047_kg,"hi can anyone help? i can t upload my data by clicking new dataset in my account page only empty page after clicking my browser is chrome on mac high sierra.thank you   hi there  can you include a screenshot of the button you re clicking? instead of kicking this off from your account page could you go to  https://www.kaggle.com/datasets  and click the new dataset button there?  cheers,timo   yeah i clicked the button in my account page it works now through click new dataset in  https://www.kaggle.com/datasets   thank you",4,0.9169832837004411,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
57093511_so,"classification conv-neural-network image-recognition keras tensorflow how to increase the accuracy of my cnn model i have 4 different types of images like bicyle,car,airplane and musicalinstrument and i tried to make image classification with this dataset.then when i train the model i get this accuracy  0.62what should i do to increase the accuracy?   here is the result     epoch 1/10  18620/18620 [==============================] - 987s 53ms/step - loss 2.0487 - acc 0.39380/18620 [=======>......................] - eta 11:57 - loss 4.0915 - acc 0.278410500/18620 [===============>..............] - eta 7:07 - loss 2.7013 - acc 0.325015500/18620 [=======================>......] - eta 2:45 - loss 2.2196 - acc 0.3754  epoch 2/10  18620/18620 [==============================] - 985s 53ms/step - loss 1.1145 - acc 0.5409ta 14:05 - loss 1.1721 - acc 0.4987 7750/18620 [===========>..................] - eta 9:31 - loss 1.1378 - acc 0.5288 - eta 2:44 - loss 1.1183 - acc 0.5392  epoch 3/10  18620/18620 [==============================] - 978s 53ms/step - loss 1.0331 - acc 0.5830ta 14:17 - loss 1.0323 - acc 0.5845  epoch 4/10  18620/18620 [==============================] - 975s 52ms/step - loss 1.0032 - acc 0.5942ta 9:37 - loss 1.0127 - acc 0.5875 9750/18620 [==============>...............] - eta 7:41 - loss 1.0119 - acc 0.5892 - eta 5:19 - loss 1.0122 - acc 0.5902  epoch 5/10  18620/18620 [==============================] - 973s 52ms/step - loss 0.9680 - acc 0.6137ta 11:27 - loss 0.9670 - acc 0.6137 7000/18620 [==========>...................] - eta 9:58 - loss 0.9718 - acc 0.6066 15000/18620 [=======================>......] - eta 3:08 - loss 0.9694 - acc 0.6115  epoch 6/10  18620/18620 [==============================] - 979s 53ms/step - loss 0.9308 - acc 0.62960/18620 [=============>................] - eta 8:36 - loss 0.9311 - acc 0.633110500/18620 [===============>..............] - eta 7:05 - loss 0.9310 - acc 0.6304  epoch 7/10  18620/18620 [==============================] - 976s 52ms/step - loss 0.9052 - acc 0.63860/18620 [==========>...................] - eta 10:02 - loss 0.9112 - acc 0.6347 - eta 9:11 - loss 0.9055 - acc 0.6368 - eta 5:19 - loss 0.9105 - acc 0.6362  epoch 8/10  18620/18620 [==============================] - 1008s 54ms/step - loss 0.8755 - acc 0.6507/18620 [==================>...........] - eta 5:52 - loss 0.8746 - acc 0.6513  epoch 9/10  18620/18620 [==============================] - 994s 53ms/step - loss 0.8479 - acc 0.66140/18620 [===>..........................] - eta 14:12 - loss 0.8474 - acc 0.6560 3500/18620 [====>.........................] - eta 13:27 - loss 0.8437 - acc 0.6566 - eta 11:54 - loss 0.8318 - acc 0.6672 - eta 9:30 - loss 0.8273 - acc 0.6681 9500/18620 [==============>...............] - eta 8:08 - loss 0.8390 - acc 0.6653 - eta 6:09 - loss 0.8399 - acc 0.6660 - eta 1:53 - loss 0.8473 - acc 0.6628  epoch 10/10  18620/18620 [==============================] - 997s 54ms/step - loss 0.8108 - acc 0.67490/18620 [=======>......................] - eta 11:54 - loss 0.8146 - acc 0.6650 - eta 10:45 - loss 0.8196 - acc 0.6652  4656/4656 [==============================] - 40s 9ms/stepeta 1s  validation accuracy 0.6265034364261168  validation loss 0.964772748373628 at the first you can increase cnn filters 8 or 16 is not enoughand then use batchnormalization layers after maxpool layers if it s not work change the optimizer like sgd etc",13,0.9167428911707954,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
60192_kg,does  imputation fill missing values with numbers only?   you could build another model to predict the factor variable that you are missing using the information that you actually have then use the imputed values to build your final model i haven t seen much of this however as you say kind of imputation tends to happen and be easier to do with numeric variables where you can take the mean or median etc    imputation can fill your missing data with below values   median :- only be used in numerical case  mean :- only be used in numerical case  most frequent :- can be used in numerical case or string case  fill value:- can provide any value of your choice to fill   imputation can be used in both cases,2,0.916737598665799,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
133640_kg,i tried twice to submit this am gmt - 6 and both failed  since i can t resubmit until tomorrow will i be able to continue competing?  thanks in advance   it is mentioned     march 3 2020 - entry deadline you must accept the competition rules before this date in order to compete   nothing about submissions so i think you are safe   thanks @nososund! i hope you re right  the  rules page  seems is unclear on whether entry = submission   competition timeline start date december 11 2019 at 5:00:00 pm utcmerger deadline march 3 2020 at 11:59:00 pm utcentry deadline march 3 2020 at 11:59:00 pm utcend date final submission deadline march 31 2020 at 11:59:00 pm utc,17,0.9163876472487347,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
48541725_so,c++ eye-tracking haar-classifier image-processing opencv can haar cascade detect sinle eye in livestream i want to track eye from an head mount camera and i am using haar cascade @ eyecascade   i am able to detect eye when two eyes are in the frame and unable to track when only single eye is in the frame of the camera  does eyecascade in haar cascade recognize when only one eye is in the frame of the camera ,20,0.9150360608122615,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
95231_kg,congrats my teammate yuanhao @wuyhbb for becoming grandmaster!    congrats!!!!   congrats   !!!!   congrats!!!!   congrats!!!!   congrats!!!!!   congrats!!!!!   congrats!!!!   congratulations !!!    congrats!!!!   congrats!!!!   congrats!!!!!   congrats!   congrat! :-   congrats!!!!   congratulations..!!   thanks!   congrats!!!   congrats!!!!   congrats!!!!!!   congrats!!!!   congrats for your achievement!   congrats!!!!!   congrats,14,0.9150007098917444,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
24956639_so,algorithm cluster-analysis graph python from matrix of community co-occurences to the index of community for every node i have an   matrix   where the  -th entry is 1 if node   and node   in a graph belong to the same cluster and 0 otherwise that matrix is a result of an optimization algorithm to find communities in a graph  i want to transform that matrix in a list with   entries where for every  -th entry i can associate an integer that represent the separate cluster that the  -th node belongs to  for example in python my matrix is the following in this case nodes 0 and 1 belong to community a while nodes 2 and 3 belongs to community b   that means that node 0 belong to the same community nodes are from 0 to n-1how is possible to extract from that matrix a list like this   where the i-th element of the list represent the index of the community the node belongs?i m using a and b just for being more clear but those indices are in fact integers assuming this relation you have is   symmetric     and   transitive     you can regard your matrix as a graph   where each index   is a node and   is in   if and only if    so your communities are actually  connected components  of the graph. finding connected components is fairly easy with any graph discovery/traversal algorithm such as  bfs  and  dfs  using the following high-level pseudo code,23,0.9148573142521048,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
142723_kg,i created the v6_text folder in the coronawhy plus dataset as a quick way to unblock folks wrestling with the kaggle vs pickle issue on the coronawhy dataset as that dataset has moved to gcp i do not plan to update it further and plan to remove the v6_text folder soon    https://console.cloud.google.com/storage/browser/coronawhy/nlpdatasets/v7_preprocessed?pli=1,4,0.9145011572697327,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
7475271_so,opencv opencvdotnet xamarin.ios is there any opencv wrapper for monotouch opencv open source computer vision is a library of programmingfunctions for real time computer vision and augmented reality   http://opencv.willowgarage.com/wiki/   i ve only found a couple of ios ports   https://github.com/macmade/opencv-ios    https://github.com/bloodaxe/opencv-ios-template-project   and a specific ios folder and makefile in the official repository   https://code.ros.org/svn/opencv/trunk/opencv/ios/   is there any opencv c# wrapper for monotouch?  thanks in advance just created example project for using opencv on xamarin.ios see here  https://github.com/trinnguyen/xamarin.ios-opencv   not quite sure about monotouch but  emgucv  is a wrapper for c#/.net since monotouch declares .net libraries compability is should suit to your needs,21,0.9143470844629562,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
106662_kg,i am a little confused.in stage 1 there is a public leaderboard and a private leaderboard in stage 2 there is also a public leaderboard and a private leaderboard so which one is the   public leaderboard and  private leaderboard?i noticed that now in stage 2 the stage 1 submissions was not allowed to choose in the submissions page does it mean that in stage 2 we should choose two submissions and these two will be calculated and shown in the  public leaderboard and  private leaderboard?   i am confused about what s the final leaderboard?   the final leaderboard is only the private stage 2 leaderboard by the end of stage 2 sep 4 you must make your 2 final submission selections.these will be what your private leaderboard score will be based on  stage 2’s test set is new so the stage 1 submissions are no longer valid this is why you must make your final submissions only based on stage 2 submissions   it s the private lb,17,0.9139902647498787,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
63056_kg,hi  i have a dataset which has both numerical and categorical value columns i am trying to use  fancyimpute  library for imputing missing values but fancyimpute takes only numerical values so i have to one-hot encode categorical values before feeding to fancyimpute but the problem is my dataset contains of categorical values such as gender married education etc which have missing values when i use sklearns one-hot encoding or panda s get_dummies missing values in categorical features are get filled with 0 s  i want missing values remain as missing values or nan after one-hot encoding so that fancyimpute takes care of missing values  thankschetan,2,0.913783886793707,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
57212521_so,azure bigdata interactive azure cloud service for interactively querying data processed and stored in azure blob storage by hdinsight spark cluster we use hdinsight spark cluster for processing and storing large amounts of data in azure blob storage we use external hive metastore for managing the data catalog  once the processed data is stored in azure blob storage we would like to interactively query the data for further analysis   in aws for similar problem i was using athena it shares the same hive metastore it was glue metastore for emr and athena and queries the data directly from s3  is there any such native service in azure that can query the data directly from storage and using the external hive metastore ,15,0.9134554958097617,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
1342_kg,the rule says  &quot a team s designation of a milestone prize entry must be made by the team leader if an entrant does not designate one milestone prize entry by the applicable milestone prize deadline his/her/its entry with  the lowest prediction score on the leaderboard   will be automatically designated for judging .&quot  however in the &quot;submission&quot page it says  &quot your team leader can select up to 1 submission that will be used to calculate your team s final leaderboard score if your team leader does not select them up to 1 entry will be chosen for your team  based on your team s most recent submissions    &quot  thanks,17,0.9133779554855269,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
58022629_so,"keras python tensorflow how to divide slices of a keras 3d tensor with elements of a vector i have to perform a tensor operation where each slice of the tensor is divided by the corresponding element from a vector for example a tensor k of shape 4,80,50 have 4 slices of shape80,50 along the axes-0 each of the 4 slices have to be divided by elements of the vector p of shape 4,1 ie k[0,:,:] /p[0]  k[1,:,:]/p[1] etc is there a keras function which can perform this  since   and   have the same size of 0-axis you need to expand dimension of   at the end in tf2.0 here is an example",5,0.9132121097322403,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
5229_kg,hi  &nbsp  can you guys tell us your final cross validation score and the leaderboard scores please?   leaderboard 0.91880  10 fold cv 0.909  what is yours?   cv fold 0.9138  leaderboard 0.91884  i have observed that as cv fold increases the leaderboard score becomes closer to it did anyone else observe that?   yup - but the standard deviation goes up along with it..    mean cv 0.901913 | board 0.91786  mean cv 0.903254 | board 0.91817  here are mine. pretty conservative as that mean cv is on a 50-fold i ve used such an high fold only to get the best regularization parameter!&nbsp   &nbsp  cv 0.9191 | board 0.9211   cv 0.903448 | board:&nbsp 0.91294   mean cv=0.904152  leaderboard= 0.91155   mean cv=0.921336  leaderboard=0.92382   mean cv 0.9157451  leader board 0.91762   mean cv 0.9137  leaderboard 0.9215   5 folds 0.905 and&nbsp;10 folds 0.908  leaderboard 0.917  &nbsp   5 folds cv 0.896188  leaderboard 0.91501   looks like huge variance between cv and leaderboard -&nbsp  cv 0.921  leaderboard 0.925  &nbsp  but the score varies across the folds - this means to me that the final leaderboard could be very different from private   [quote=konrad banachewicz;27789]  yup - but the standard deviation goes up along with it..  [/quote]  important point - what is the point if you standard deviation is 0.03?   [quote=tks;27808]  5 folds cv 0.896188  leaderboard 0.91501  [/quote]  this means that the leaderboard probably represents one of your folds where the model did well   5 folds cv:&nbsp;0.9129498  leaderboard:&nbsp;0.92053  &nbsp  5 folds cv:&nbsp;0.9198344 leaderboard:&nbsp;0.91938    &nbsp   10 folds cv 0.90432  leaderboard 0.91573,14,0.913112824297473,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
32795_kg,under  submission limits  at rules section you may submit a maximum of 5 entries per day   so why doesn t let me submit over  3  entries per day ?   fixed now limit is 3/day   it s now 2/day as of thurs jun 22 ~ 6pm    submission limits   you may submit a maximum of  3 entries  per day  you may select up to  2 final submissions  for judging   how does it work with the 5 hour time limits then? cant seem to do more than 2 per 5 hours? i ve been climbing the leaderboard slowly but im a little confused on this point   you should have 3 entries per day report it at  https://www.kaggle.com/contact,17,0.9128615845035527,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
49229234_so,"keras python tensorflow how to multiply by batches in keras backend or tf i have two tensors of shape batch size,15,500  batch size,500,98i want to multiply them as matrix multiplication for each batch size to obtain batch size,15,98how can i do that in tensorflow or keras backendcan i use batch dot you can use    this says contract on index j which is what a single matrix multiplication would look like and repeat that for index i",5,0.9128107126826778,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
29568533_so,apache-spark bigdata hadoop yarn what is the difference between yarn and spark processing engine based on real time application i understood yarn and spark but i want to know when i need to use yarn and spark processing engine what are the different case studies in that i can identify the difference between yarn and spark apache spark can be run on yarn mesos or standalone mode   spark in standalone mode - it means that all the resource management and job scheduling are taken care  spark inbuilt  spark in yarn - yarn is a resource manager introduced in mrv2 which not only supports native hadoop but also spark kafka elastic search and other custom applications  spark in  mesos  - spark also supports mesos this is one more type of resource manager  advantages of spark on yarn   yarn allows you to dynamically share and centrally configure the same pool of cluster resources between all frameworks that run on yarn  yarn schedulers can be used for spark jobs only with yarn spark can run against kerberized hadoop clusters and uses secure authentication between its processes    link for more documentation on yarn spark   we can conclude saying this if you want to build a small and  simple cluster independent of everything go for standalone if you want to use existing hadoop cluster go for yarn/mesos  you cannot compare yarn and spark directly per say yarn is a distributed container manager like mesos for example whereas spark is a data processing tool spark can run on yarn the same way hadoop map reduce can run on yarn it just happens that hadoop map reduce is a feature that ships with yarn when spark is not  if you mean comparing map reduce and spark i suggest reading  this other answer,15,0.9121943989445027,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
51397198_so,python tensorflow tensorflow-estimator tensoflow estimator how to use tf.graph_util.convert_variables_to_constants i would like to know if it is possible to use the function   tf.graph_util.convert_variables_to_constants   in order to store the frozen version of the graph in a train/evaluation loop while i m using a custom estimators for example to use the function   you need the graph and the session of your model  after going through the  tensorflow code defining the estimators  it appears that   this code is deprecated  the graph is created on the fly and not easily accessible at least i was not able to retrieve it   thus we will have to use the good old method  when you call   checkpoints of your model are being saved in a specified directory   you can use those files to access the graph and session and freeze the variables as follow  1 load meta graph   2 load weights   3 freeze variables,7,0.912181674141141,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
40958983_so,deep-learning numpy numpy-einsum python theano how to use batch_tensordot in theano like numpy.einsum i have a tensor3 with shape 3 4 5 and another tensor4 with shape 3 4 7 5.in numpy   but in theano  how to do it the first step is to transpose and reshape your tensor so that only the first dimension gets preserved in that case it is quite simple you just have to combine the first two dimensions   then you specify to   that you are going to sum axis 1 of   with axis 2 of     finally reshape   to get the first two dimensions,5,0.9121354382197687,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
36520_kg,is there a limit on the number of persons registered as a team?   we don t have any hard limit on number of people in the team  entire winner team will be invited to present at nips competition track so you decide who actually go and present but we don t sponsor travel and registration as mentioned in t&amp;c  also kaggle will be distributing free google cloud credits for several top teams in the first dev round each team is eligible to receive this no more than once as explained in here  https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack/discussion/36088    hi alex   is there any team merger deadline or is it just the final submission deadline?   there is no team merger deadline for now.you may see n days to go until merger deadline but actually it s just a time before submission for first dev round   is this still the case for now?  the page still says e.g 5 hours to go until merger deadline   this is again temporary merger deadline for the second dev round after second dev round is done and we will resume accepting submissions deadline will be updated,17,0.9119995914448366,"0.055*""competition"" + 0.034*""submission"" + 0.026*""kaggle"" + 0.025*""team"" + 0.014*""submit"" + 0.014*""score"" + 0.011*""leaderboard"" + 0.011*""make"" + 0.009*""rule"" + 0.009*""stage"""
49709616_so,"python python-3.x tensorflow create a matrix with dimension [n,d] from tensor with dimension [n i have a tensor with dimension n and i would like to replicate it to  create a tensor with dimension nxd being each column the initial vector   thank you you want first to expand/reshape your tensor to a   shape before tiling it   times in the 2nd dimension     documentation    tf.expand_dims    tf.tile",5,0.9108595388764977,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
49840_kg,congrats winners! and thanks to those who ran it  it was fun :  edit and that was quite a change in scores my goodness!   lots of shake up i must say...congrats to the winners most especially tony did a great job    i agree what a shake up :o  congrats to the winners!  had a lot of fun and learned many things :   i think that might be the  case for a few people i didnt have that but i definitely didnt have my best score selected   me too...my final two s private scores rank 15th and 16th in my 81 public scores.. really hard to control the selection of final two...   my best private score is 0.0502 but i could not select it because i got the winning model with a lower validation score   my 2nd script in r public kernel was my best model  .0591 on private lb  what was your best gp result,14,0.9108454327755034,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
59034268_so,c++ image-stitching keypoint opencv problem stiching images from a drone with opencv due to a poor quality of the images i am working with opencv and a quad ardrone parrot 2.0.i m capturing the images from the bottom camera of the quad and i wish to stitch them in order to get a larger image i m trying to detect the squares marked in the images  i tried to perform keypoint detection with orb sift surf and brisk  and changing their parameters to different values and there weren t good results from that i am unsure about the quality of the images so maybe a preprocessing would help?  images   1    2    3    4    5 ,20,0.9107629238130459,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
52915515_so,keras python keras loss value not changing i am trying to apply a deep learning network on the loan status dataset to check if i can get a better result than conventional machine learning algorithms  accuracy seems to be very low even lower than using normal logistic regression how can i improve it?  things i ve tried:- changing the learning rate- increasing number of layers- increase/decreasing number of nodes**      epoch 1/50       - 1s - loss 4.9835 - acc 0.6873      epoch 2/50       - 0s - loss 4.9830 - acc 0.6873      epoch 3/50       - 0s - loss 4.9821 - acc 0.6873      epoch 4/50       - 0s - loss 4.9815 - acc 0.6873      epoch 5/50       - 0s - loss 4.9807 - acc 0.6873      epoch 6/50       - 0s - loss 4.9800 - acc 0.6873      epoch 7/50       - 0s - loss 4.9713 - acc 0.6873      epoch 8/50       - 0s - loss 8.5354 - acc 0.4397      epoch 9/50       - 0s - loss 4.8322 - acc 0.6743      epoch 10/50       - 0s - loss 4.9852 - acc 0.6873      epoch 11/50       - 0s - loss 4.9852 - acc 0.6873      epoch 12/50       - 0s - loss 4.9852 - acc 0.6873      epoch 13/50       - 0s - loss 4.9852 - acc 0.6873      epoch 14/50       - 0s - loss 4.9852 - acc 0.6873      epoch 15/50       - 0s - loss 4.9852 - acc 0.6873      epoch 16/50       - 0s - loss 4.9852 - acc 0.6873      epoch 17/50       - 0s - loss 4.9852 - acc 0.6873      epoch 18/50       - 0s - loss 4.9852 - acc 0.6873      epoch 19/50       - 0s - loss 4.9852 - acc 0.6873      epoch 20/50       - 0s - loss 4.9852 - acc 0.6873      epoch 21/50       - 0s - loss 4.9852 - acc 0.6873      epoch 22/50       - 0s - loss 4.9852 - acc 0.6873      epoch 23/50       - 0s - loss 4.9852 - acc 0.6873      epoch 24/50       - 0s - loss 4.9852 - acc 0.6873      epoch 25/50       - 0s - loss 4.9852 - acc 0.6873      epoch 26/50       - 0s - loss 4.9852 - acc 0.6873      epoch 27/50       - 0s - loss 4.9852 - acc 0.6873      epoch 28/50       - 0s - loss 4.9852 - acc 0.6873      epoch 29/50       - 0s - loss 4.9852 - acc 0.6873      epoch 30/50       - 0s - loss 4.9852 - acc 0.6873      epoch 31/50       - 0s - loss 4.9852 - acc 0.6873      epoch 32/50       - 0s - loss 4.9852 - acc 0.6873      epoch 33/50       - 0s - loss 4.9852 - acc 0.6873      epoch 34/50       - 0s - loss 4.9852 - acc 0.6873      epoch 35/50       - 0s - loss 4.9852 - acc 0.6873      epoch 36/50       - 0s - loss 4.9852 - acc 0.6873      epoch 37/50       - 0s - loss 4.9852 - acc 0.6873      epoch 38/50       - 0s - loss 4.9852 - acc 0.6873      epoch 39/50       - 0s - loss 4.9852 - acc 0.6873      epoch 40/50       - 0s - loss 4.9852 - acc 0.6873      epoch 41/50       - 0s - loss 4.9852 - acc 0.6873      epoch 42/50       - 0s - loss 4.9852 - acc 0.6873      epoch 43/50       - 0s - loss 4.9852 - acc 0.6873      epoch 44/50       - 0s - loss 4.9852 - acc 0.6873      epoch 45/50       - 0s - loss 4.9852 - acc 0.6873      epoch 46/50       - 0s - loss 4.9852 - acc 0.6873      epoch 47/50       - 0s - loss 4.9852 - acc 0.6873      epoch 48/50       - 0s - loss 4.9852 - acc 0.6873      epoch 49/50       - 0s - loss 4.9852 - acc 0.6873      epoch 50/50       - 0s - loss 4.9852 - acc 0.6873 **i was able to get a slight improvement by making the network deeper &amp adding dropouts but i still think this can be improved further as using normal logistic regression gives a much better accuracy 80%+  does anyone know a way to achieve further improvement?*,13,0.9107487344104638,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
108370_kg,how to delete notebook old commit ?  i want to delete some old commit i made before    hi  @tduan007  - you can only delete the entire kernel not a specific commit  the kernel can be deleted from the kernel listing or from the kernel viewer in the overflow menu  alternatively if you don t like the commit history being available you can use the copy and edit button in the overflow menu on the viewer publish the copy and delete the original  hope that helps!   hi jim got it  thanks for your answer,4,0.9105018788797272,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
30019054_so,"java machine-learning stanford-nlp tokenize text tokenization with stanford nlp  filter unrequired words and characters i use   for string tokenization in my classification tool i want to get only meaningful words but i get non-word tokens like       etc. and not important words like       stop words does anybody know a way to solve this problem in stanford corenlp there is a  stopword removal annotator  which provides the functionality to remove the standord stopwords you can also define custom stopwords here as per your need i.e ---,&lt;, etc  you can see the example  here    here in the above example tokenize,ssplit,stopwords are set as custom stopwords  hope it ll help you....!!  this is a very domain-specific task that we don t perform for you in corenlp you should be able to make this work with a regular expression filter and a  stopword  filter on top of the corenlp tokenizer  here s  an example list of english stopwords",12,0.9103912567315905,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
52497450_so,python tensorflow followup on question use coo_matrix in tensorflow in the answer to the  question  was mentioned   i m trying to understand why one needs to transpose a scipy sparse matrix when using tensorflow thanks in  advance if you look at the documentation of       is expected to be a 2-dimensional tensor with dimensions   where   is the number of non-zero values in the sparse tensor and   is its number of dimensions for a sparse matrix two dimensions each row will contain the row and the column of the corresponding value in    in the snippet   is an array of row indices of the sparse matrix and   is an array of column indices   will be an array with two rows and   columns which is the opposite order of what a sparse tensor expects so transposing it with   you get the   indices tensor not that you are not transposing the sparse matrix the indices still remain the same you are just giving them to   in the required order you could get the same result by doing for example,5,0.9102946348187366,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
88563_kg,as the competition is near its final moments i thought that it would be interesting to see the cv of our solutions single model or not it is said that one should trust the cv so let s compare and contrast  our solution is at 0.9245 cv at the moment but i am not very confident that it will perform well on the private lb so ironically i don t trust our cv   lgbm  0.915 cv 0.914 lb   it d also be good to know training scores just to compare the notes      so ironically i don t trust our cv   why?   cv 0.919 lb 0.914 and seems there is no leaks or overfitting according to train score very strange   you may trust your cv only if you re sure your approach is not overfiting :   i believe we ve committed some mistakes when constructing the cv or more specifically the stacking makes us overfit cv the oof predictions are trained on different folds i.e different seeds this might or might not be a large issue we will see in a day or so   my cv/lb was 0.914 but i have just raised it to 0.917 without tuning kfolds or stacking i am trying to make a new fe based on an interesting property i found and then tune it tonight hopefully i will reach 0.920+  edit just got a 0.920 cv :d   isn t it golden rule for kagglers to trust your cv? ^_^   i am sure i don’t know how to be sure 🎱 s not working right now..   unlike many others my cv is smaller than lb cv is 0.9115 but lb is 0.913 i think this is not good and there will be shakeup for me   cv 0..916 lb .915   high fold .923 low fold .911 which is what scares me about the private lb   it s the same as it was 5 weeks ago! 😢   jokes aside i m looking forward to the solutions a couple of days and some sleep!   i have been stuck at .915 for a couple days i actually got a cv of .921 but it was over fit lb .910   0.910 cv0.911 lbi am scared of the shakeup i am definitely overfitting since my train auc was around 0.99 for some folds    havent submited mine yet hope its not overfitting   my current cv/lb is exact cv=0.9181 and lb=0.918x and looking at my score compared to other 0.918’s i can tell it’s at least at the lower end of the values    our nn model cv is 0.917+ but on lb is 0.920 not sure why the gap is so different comparing to lgbm model   or maybe it is...?   what a jump!!  @interneuron  good job!!   thanks jiwei! you ve been inspiring here for real  credit must go to my teammate niwad i am just the sorcerer s apprentice    cv 922 lb 920 wish i had a couple more days,14,0.9100346005582334,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
54254974_so,"deep-learning python tensorflow iterate a tensor over a none dimension in tensorflow in the case i have a tensor with a none first dimension corresponding to the batch size for example   and now i have a tensor function myfunc acting on a tensor on size [256,256,3] that i want to apply as many times as the number of batch to get as a result an output of size [none 256 256,3] if the shape was not dynamic i would simply do    how could i do with a dynamic shape  if you really want to do that you can use  tf.map_fn    otherwise you can try to directly deal with the original tensor with the first dimension = none and do the operations on the proper axes no need to loop",5,0.9099270624415022,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
45701834_so,lstm rnn tensorflow shape of dynamic_rnn i implemented a stacked lstm network in tensorflow using   where   is defined as   i use a batch size of 20 and a sequence length of 200 the 200 is a maximum the rest is padded with zeros i use a dynamic_rnn where i pass the sequence length for each sample   when i look at the last output using   the   vector has shape   where   is simply the number of units in the top lstm layer 128 in my case equal to    where does the 2 come from? in my understanding i should simply have 128 outputs for each sample in the batch not 2 times that number  thanks in advance ,5,0.9099270624415022,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
48442034_so,"indexing numpy python tensorflow tensorflow access elements in tensor using tenors on indices how can i access tenor elements in tensorflow   using tensor indices as follows   i get these errors     tensorflow.python.framework.errors_impl.invalidargumenterror shape  must be rank 1 but is rank 2 for  strided_slice_2  op:   stridedslice  with input shapes [100,100] [2,1000] [2,1000] [2]      valueerror shape must be rank 1 but is rank 2 for  strided_slice_2   op  stridedslice  with input shapes [100,100] [2,1000] [2,1000],  [2 ",5,0.9089989509466601,"0.043*""shape"" + 0.035*""input"" + 0.035*""tensor"" + 0.032*""tensorflow"" + 0.024*""array"" + 0.023*""lstm"" + 0.022*""dimension"" + 0.020*""output"" + 0.020*""size"" + 0.018*""batch"""
85289_kg,"country year            sex         age      suicides.no    population  suicides.per.100k.pophungary 1991    male    75+ years   333           188235            176.91hungary 1991    male    35-54 years 1271              1420586    89.47hungary 1991    male    55-74 years 751           874916             85.84hungary 1991    female  75+ years   263           363039     72.44  what is population calculated against?thank you very much.g   population appears to be at a country-year-sex-age level so taking your first example there were 188,235 men aged 75+ in hungary in 1991   if you grouped the data by country and year and summed up the population you should get the population of each country over time hope this helps :   thanks liam",8,0.9087024615257983,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
21455_kg,sorry to ask an r syntax question here but what s a simple and performant way to do a three-way merge/join/reshape between all these and drop the other columns   itempairstrain.itemid_1 iteminfotrain.itemid to join iteminfotrain.categoryidas categoryid_1  itempairstrain.itemid_2 iteminfotrain.itemid to join iteminfotrain.categoryid as categoryid_2   i did check so and the dplyr and reshape doc   here s a dplyr way using nested inner_joins    anyway this is all irrelevant since it turns out categoryid_1 == categoryid_2 throughout all of train and test,19,0.9085635977658859,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
146806_kg,i need a dataset of covid19  please help me .   you can find plenty of covid-19 datasets here: https://www.kaggle.com/datasets?search=covid-19    thanks sahid   hi sahid  will u help me how to upload file in kaggle . because i have written in jupyternotebook  and kaagle only accept csv file .   you can upload a new notebook by visiting the  notebooks page  click on new notebook and then create under file you will find the option to upload your own notebook   hi  @kundanrai12  you can find the covid-19 dataset from  here,4,0.9084641351404438,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
82936_kg,i ve tried ensembling using weighted average of predictions but my scores on lb are much worse than a single model can someone share what ensembling approaches work?   i m also interested in ensembling techniques as i ve only used weighted average before also what models are you ensembling?   i am trying xgb + lgbm but no improvement so far   i m still working on a single lgb model but i will also ensemble those two   i didn t get any improvement by ensembling using weighted average i tried ridge using stacking models it didn t work too not sure what is wrong but i got really high qwk on validation set 0.47 by stacking but lb score was 0.428 not sure why,14,0.9083948765123514,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
122679_kg,"in the variable decription on mortdue it is stated as amount due on existing mortgage what exactly do you mean by existing mortgage? is it any mortgage taken on the same property from the same bank or different bank? is it a mortgage taken on a different property? please elaborate   a home equity loan in the us is secured by a mortgage or a deed of trust there is usually an outstanding loan on the house from purchase or refinance which is said to be senior in priority of payment the equity is the difference between the current estimated market value of the home and the balance due on the senior mortgage for example a property appraised at $400,000 with a $300,000 balance has an equity of $100,000  trust me i was a mortgage backed securities lawyer",8,0.9080407113968778,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
21352101_so,"gradient-descent logistic-regression machine-learning matlab is my implementation of stochastic gradient descent correct i am trying to develop stochastic gradient descent but i don t know if it is 100% correct   the cost generated by my stochastic gradient descent algorithm is sometimes very far from the one generated by fminuc or batch gradient descent  while batch gradient descent cost converge when i set a learning rate alpha of 0.2 i am forced to set a learning rate alpha of 0.0001 for my stochastic implementation for it not to diverge is this normal?     here are some results i obtained with a training set of 10,000 elements and num_iter = 100 or 500    gradient descent implementation for logistic regression     stochastic gradient descent implementation for logistic regression     for reference here is the logistic regression cost function used in my example there is a reason for small value of the learning rate  briefly when the learning rates  decrease with an appropriate rate and subject to relatively mild assumptions stochastic gradient descent converges almost surely to a  global minimum  when the objective function is  convex  or  pseudoconvex  and otherwise converges almost surely to a  local minimum  this is in fact a consequence of the  robbins-siegmund  theorem     robbins herbert siegmund david o 1971 a convergence theorem  for non negative almost supermartingales and some applications in  rustagi jagdish s optimizing methods in statistics academic press   this is pretty much ok if you are worried about choosing the appropriate learning rate   you should think about applying a  line search  method  line search is a method which chooses an optimal learning rate for gradient descent at every iteration which is better than using fixed learning rate throughout the whole optimization process optimal value for learning rate   is one which locally from current   in the direction of the negative gradient minimizes cost function  at each iteration of the gradient descent start from the learning rate   and gradually increase   by the fixed step   for example recalculate parameters   and evaluate the cost function since the cost function is convex by increasing   that is by moving in the direction of negative gradient cost function will first start decreasing and then at some moment increasing at that moment stop the line search and take the last   before cost function started increasing now update the parameters   with that   in case that the cost function never starts increasing stop at      note  for big regularization factors     it is possible that   is too big and that gradient descent diverges if that is the case decrease   10 times     until you get to the appropriate   for which gradient descent converges  also you should think about using some terminating condition other than the number of iterations e.g when difference between cost functions in two subsequent iterations becomes small enough less than some    the learning rate is always between 0 to 1 if you set the learning rate very high then it follows the desired to a lesser extent because of skipping so take a small learning rate even though it takes more time the output result will be more convincing",3,0.9078653157888424,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
76763_kg,in my experiment lb is not consistent with local cv at times how about your model?  3-fold local cv       ||  lb0.685                      || 0.6770.680                      || 0.685  and i find that some public kernels have high lb score without high local score   maybe a high lb score need some luck but i think it is hard to keep this luck in private lb how do you think about this,14,0.9076968552205961,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
44251328_so,tensorflow tensorflow print all placeholder variable names from meta graph i have a tensorflow model for which i have the .meta and the checkpoint files i am trying to print all the placeholders that the model requires without looking at the code that constructed the model so that i can construct a input feed_dict  without knowing how the model was created for reference here is the model construction code in another file     now in another file i have the following code to restore     however when i print all the variables as above i do not see v1:0 and v2:0 as variable names anywhere how to identify what tensor names placeholders had without looking at the code for creating the model mrry s answer  is great the second solution really helps but the op name of the placeholder changes in different tensorflow versions here is my way to find out the correct placeholder op name in the graphdef part of the   file   in the   file we can easily find out the placeholder s correct op names and other attrs here is part of my output file   obviously in my tensorflow version1.6 the correct placeholder op name is   now return back to mrry s solution use   to get a list of all the placeholder ops  thus it s easy and convenient to perform the inference operation with only the ckpt files without needing to reconstruct the model for example   the tensors   and   were created from     ops whereas only     objects are added to the   or   collections there is no general collection to which   ops are added so your options are    add the   ops to a collection using     when constructing the original graph you might need to add more metadata in order to suggest how the placeholders should be used    use   to get a list of placeholder ops after you import the metagraph,7,0.9074986048232221,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
61882_kg,total seats 272  currency market associates cmkapti = 107pml-n = 79ppp = 30others = 56  topline pti = 85-95 seatspml – n = 80-90 seatsppp 35-40 seatsothers 47-72 seats  pulse consultants pti = 30 % or 82 seatspml-n = 27% or 73 seatsppp = 17 % or 46 seatsothers = 26% or 71 seats  gallup pakistanpti = 25% or 68 seatspml-n = 26% or 71 seatsppp = 16% or 44 seatsothers = 33% or 90 seats  herald magazinepti = 29% or 79 71 seatspml-n = 25% or 68 seatsppp = 20% or 54 seatsothers = 26% or 71 seats  credit suissepti = 92 seatspml-n = 73 seatsppp = 34 seatsothers = 73 seats  probability of error 3 ,8,0.9073336587644268,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
82942_kg,"there are 16 administrative districts in beijing.however,the  district  variable only ranges from 1 to 13.and we don t know how the number corresponds to districts    1东城区 2丰台区 3通州区 4大兴区 5房山区 6昌平区 7朝阳区 8海淀区 9石景山区 10西城区 11平谷区 12门头沟区 13顺义区没有延庆 怀柔 密云   three districts 延庆 怀柔 密云 not included",8,0.9073054972913002,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
5829_kg,"hi  to encourage use of r here is the r code to replicate mr dyakonov s example submission  let s r :  &nbsp  ###########################################################################&nbsp  labelsdf &lt;- read.csv  inputfiles/trainlabels.csv  header=t stringsasfactors = f y &lt;- labelsdf [,-1] y &lt;- as.matrix y  # d is basically the input matrix d &lt;- array 0 c55 198 510 for i in 1:510 { filename &lt;- paste inputfiles/ ,i .csv  sep=   data &lt;- read.csvfilename d[,,i] &lt;- as.matrixdata printfilename }  # t is basically the training matrix t &lt;- matrix0 200 198  for i in 1:200 { t[i,] &lt;- d[55,1:198,i] printi }  # s is basically the scoring matrix s &lt;- matrix 0 310 198 j &lt;- 1 for i in 201:510  { s[j,] &lt;- d[55,1:198,i] print i j &lt;- j+1 } s &lt;- as.data.frame s s$fileid &lt;- 1:310 s$seq &lt;- 55  t &lt;- as.data.frame t t$fileid &lt;- 1:200 t$seq &lt;- 55  colnamest [1:ncoldata] &lt;- colnames data colnames s [1:ncoldata] &lt;- colnames data  &nbsp   x &lt;- 1.014 * s   colnames x &lt;- paste &quot;o&quot c1:198 sep = &quot;&quot;    &nbsp   filedf &lt;- data.frame fileid = 201:510 x &lt;- as.data.frame x x &lt;- cbind filedf x  write.csv x file =  dyakonov.csv  row.names = f  &nbsp",19,0.9070159974262476,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
55674045_so,math statistics what is the difference between linear programming optimization and a gradient descent optimization in linear programming problem we formulate two linear functions and an optimization function where we find points where the two linear functions intersect and substitute these values in the optimization function to get the max or min  how is this different from a gradient decent optimization can anybody elaborate on this mathematically are both methods reaching the global maximum or minimum? which is better linear programming finds the weights that optimize that linear combination it is  guaranteed  to work but  only works  for functions that are linear combinations  gradient descent can work on  any function  as long as you know its derivative however it is only guaranteed to work if the function is convex otherwise it will get stuck at a local optimum   so there s really no choice if you have a linear combination linear programming is better in every other case gradient descent is your only option,3,0.9069413197943521,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
53480332_so,apache-flink bigdata distributed-computing parallel-processing flink how does the parallelism set in the jobmanager ui relate to task slots let s say i have 8 task managers with 16 task slots if i submit a job using the jobmanager ui and set the parallelism to 8 do i only utilise 8 task slots?  what if i have 8 task managers with 8 slots and submit the same job with a parallelism of 8? is it exactly the same thing? or is there a difference in the way the data is processed?  thank you the total number of task slots in a flink cluster defines the maximum parallelism but the number of slots used may exceed the actual parallelism consider for example this job       if run with parallelism of two in a cluster with 2 task managers each offering 3 slots the scheduler will use 5 task slots like this       however if the base parallelism is increased to six then the scheduler will do this note that the sink remains at a parallelism of one in this example       see  flink s distributed runtime environment  for more information,15,0.9066904419438588,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
59484643_so,cluster-analysis k-means machine-learning python find the top 10 centre most values from each clusters done by k-means using python i have a data frame and i have clustered it into 3 clusters using k-means clustering   now i want to find the top 10 centre most values from each clusters   how to do it using python  so after finding 3 clusters mean you have 3 centroids which are nothing but 3 datapoints or   vectors of size -> number of inputs right?  so you also have data points of dataset segregated to their cluster number for 10 closest points of cluster1 find the distance between points in cluster1 and centroid1.and sort them in decreasing order of distance and extract top 10 points  similarly for all 3 clusters  example   top2 points are   based on their distances,23,0.906435722817001,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
49370_kg,i am just keeping wondering how most winners achieved a so high validation accuracy? any hints what i have missed?   the batch size is 4 and input image size is 512x512  here is part of my training record   for training xception model even with 0 dropout    epoch 62/2001975/1975 [==============================] - 1227s 621ms/step - loss 0.2975 - acc 0.9416 - val_loss 0.9382 - val_acc 0.8661  epoch 63/2001975/1975 [==============================] - 1229s 622ms/step - loss 0.2690 - acc 0.9467 - val_loss 0.7668 - val_acc 0.8755  epoch 64/2001975/1975 [==============================] - 1228s 622ms/step - loss 0.2804 - acc 0.9430 - val_loss 0.9324 - val_acc 0.8620  epoch 65/2001975/1975 [==============================] - 1227s 621ms/step - loss 0.2798 - acc 0.9449 - val_loss 0.7955 - val_acc 0.8833  epoch 66/2001975/1975 [==============================] - 1227s 621ms/step - loss 0.2454 - acc 0.9492 - val_loss 0.8227 - val_acc 0.8703  epoch 67/2001975/1975 [==============================] - 1221s 618ms/step - loss 0.2855 - acc 0.9394 - val_loss 0.7439 - val_acc 0.8698  epoch 68/2001975/1975 [==============================] - 1222s 619ms/step - loss 0.2234 - acc 0.9522 - val_loss 0.8842 - val_acc 0.8719  epoch 69/2001975/1975 [==============================] - 1222s 619ms/step - loss 0.2362 - acc 0.9490 - val_loss 0.8605 - val_acc 0.8656  epoch 70/2001975/1975 [==============================] - 1223s 619ms/step - loss 0.2501 - acc 0.9501 - val_loss 0.7569 - val_acc 0.8745   with 0.3 dropout for inceptionresnet   epoch 129/2001895/1895 [==============================] - 1422s 751ms/step - loss 0.6473 - acc 0.8711 - val_loss 0.5347 - val_acc 0.8856  epoch 130/2001895/1895 [==============================] - 1421s 750ms/step - loss 0.6573 - acc 0.8701 - val_loss 0.7332 - val_acc 0.8728  epoch 131/2001895/1895 [==============================] - 1451s 766ms/step - loss 0.6721 - acc 0.8652 - val_loss 0.7261 - val_acc 0.8603  epoch 132/2001895/1895 [==============================] - 1460s 770ms/step - loss 0.6722 - acc 0.8636 - val_loss 0.6263 - val_acc 0.8634  epoch 133/2001895/1895 [==============================] - 1464s 773ms/step - loss 0.7025 - acc 0.8578 - val_loss 0.6221 - val_acc 0.8775  epoch 134/2001895/1895 [==============================] - 1461s 771ms/step - loss 0.6852 - acc 0.8617 - val_loss 0.6017 - val_acc 0.8762  epoch 135/2001895/1895 [==============================] - 1444s 762ms/step - loss 0.6174 - acc 0.8770 - val_loss 0.5433 - val_acc 0.8950  epoch 136/2001895/1895 [==============================] - 1440s 760ms/step - loss 0.5713 - acc 0.8868 - val_loss 0.6895 - val_acc 0.8731  epoch 137/2001895/1895 [==============================] - 1440s 760ms/step - loss 0.5565 - acc 0.8902 - val_loss 0.6082 - val_acc 0.8812  epoch 138/2001895/1895 [==============================] - 1441s 760ms/step - loss 0.5229 - acc 0.9001 - val_loss 0.6242 - val_acc 0.8859  epoch 139/2001895/1895 [==============================] - 1445s 763ms/step - loss 0.6404 - acc 0.8701 - val_loss 0.5816 - val_acc 0.8928  epoch 140/2001895/1895 [==============================] - 1442s 761ms/step - loss 0.6649 - acc 0.8679 - val_loss 0.6693 - val_acc 0.8784  epoch 141/2001895/1895 [==============================] - 1439s 759ms/step - loss 0.6482 - acc 0.8694 - val_loss 0.6046 - val_acc 0.8941  epoch 142/2001895/1895 [==============================] - 1423s 751ms/step - loss 0.6133 - acc 0.8772 - val_loss 0.6777 - val_acc 0.8728  epoch 143/2001895/1895 [==============================] - 1425s 752ms/step - loss 0.6591 - acc 0.8701 - val_loss 0.6410 - val_acc 0.8834  epoch 144/2001895/1895 [==============================] - 1432s 756ms/step - loss 0.6336 - acc 0.8686 - val_loss 0.7510 - val_acc 0.8741,13,0.9064263396836921,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
44566434_so,python tensorflow how to restore checkpoint directory in tensorflow i train model with method in    code is  here  at last i save the model in a checkpoint directory now i want to restore from the checkpoint directory   howerver i got error it look like you haven t defined your graph to restore from the checkpoint so when building the saver it complains that your graph is empty  could you try to build your graph again e.g redefining your variables before trying to restore it?  from the   method string doc     it requires a session in which the graph was launched,7,0.9063503345778254,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
36965269_so,machine-learning python scikit-learn how to predict more than one class with random forest in python how can i predict more than one class with random forest in python?  i am familiar with the get probability but how can i know to which class each probability belongs according to the  documentation    returns an array of predicted classes you can use to get the most likely class for each sample  if you want to use   to get the probability for all classes you need to look at the   attribute this lists the classes in the same order that   returned its probabilities,9,0.9062210596905708,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
29546_kg,now when private scores are available for all our submissions it would be interesting to know how good your choice of 2 final models turned out to be?  my chosen final models got private scores -0.0605160 and 0.0185464 which ended up in 177 place on private lb however my overall best private score is 0.0202835 would be about 80 place that best score was for huge ensamble which i didn t choose because of low public lb score  anyway this was very interesting competition only for me it seems to be quite a big factor of luck in the final results   when you say luck i just couldn t agree more : our overall best private sub was  private  0.0260733 public  0.0212636 -&gt not selected   i played safe and selected my kernel with best public score and a variation of it which had a lower public score but a much better local score i would have only won a few places if i had selected my best model   1st pick public lb score 0.0166048 - private lb score 0.0210565    2nd pick public lb score 0.0163776 - private lb score 0.0212860  best public lb score 0.0132476 - private lb score 0.0219973    the ones i submitted right before the ones i picked did better  it only made the difference between 51 and 20something though  .. and i flipped my best private sub to public  it was over a month ago and had a negative public lb score   my best private sub was  private  0.0272797  public  0.0132289 it used extratreesregressorn_estimators=10 max_depth=10 i thought it was too crazy thus did not select it   i know what you mean  increasing the depth helped with local cv but started failing on public lb  just tried depth 7 now and got 0.029+ on private lb  :   the scores of my model didn t change that much    my best private score is 0.0336284 while its public score is low i m not sure if there are any flaws in this competition either in evaluation set selection or metrics to rank the private leader board it seems to me that the evaluation set leads to people either over-fitting or under-fittitng    i ve seen more than one kernel not just mine that gained ~.002 from public to private r scores  i  suspect  that s what many reasonably fit models do but it s not good enough to hold place on the private lb   my best non selected submission was public lb 0.0134847 -&gt private lb 0.0219842? end it s only change max depth in public script  https://www.kaggle.com/dmitriic/two-sigma-financial-modeling/sub-115/run/889586 has somebody ideas about why increase of max_depth on private data lead to lb score rise?   i can comment 2 points about this matter  1 if your local score increase while giving your tree bigger values for max depth then it s only logical to remarque an increase of score when applied to another dataset  like the one in the private but not the one in the public  2 it was all about over fitting the train data as it seems there are some shared signals between the train data and the private databut not as much for the public data,14,0.9060666621532567,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
106912_kg,as title tried a dozen times over 3 hours.the notebooks do appear in my kernels profile page but when clicking on edit it will show the menus and such and:preparing your kernel.. that never finishesand on the right draft session | queued ...even after an hour they were still in that state  deleted all of these  broken  kernals but that didn t help either  if it helps its for this competition: https://www.kaggle.com/kernels/welcome?competitionid=14774   and a link to the last notebook attempt: https://www.kaggle.com/nozziel/kernel7addfd464c/edit    hey i have this issue as well it started happening about 1-2 weeks ago what i did to fix it is:1 create the kernel.2 wait a few seconds.3 go to all kernels.4 stop the newly created kernel.5 open the new kernel again  i hope this helps ,4,0.9058774644202782,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
56816648_so,deep-learning reinforcement-learning how to design a continuous reward function for deep reinforcement learning could you help me solve this problem  as far as we know a reward function is a crucial component of reinforcement learning but a  sparse reward such as r∈{+1 -1} could not get fast convergence.so i try to use continuous function as my reward function a soft-step reward function.the following is an  original reward function  that comes from a paper published by openai about  halfcheetah     p.s    means power  and i might give a negative reward when the agent did a very bad action so i  changed  the above soft-step function to   but in fact the performance from the above modified reward function was not very good which resulted in almost unchanged action for next step that sounds very bad on the other hand the original reward function seemingly did not do as the modified one   could you tell why the modified reward function got worse performance?   and how can i design a valid reward if i want to give a negative punishment to agent ,3,0.9054421388536484,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
49963829_so,apache-spark bigdata deployment sparkcore what is the exact difference between spark local and standalone mode can someone mention the difference regarding these factors   number of nodes / machines  memory  cores  setup  deployment  advantages of each mode  when they should be used  examples if possible   also if i am running spark locally on single laptop then is that local mode or standalone there is a huge difference between standalone and local   local  - means that it runs on your pc locally i.e not distributed   standalone  - means that spark will handle resource management   standalone for this i will give you some background so you can better understand what it means spark is a distributed application which consume resources i.e memory cpu and more...lets assume that you run 2 spark applications at the same time this can cause an error when allocating resources for example it may happen that the first job consumes all the memory and the second job would fail because he doesn t have memory  to resolve this issue you need to use some resource manager that will guarantee that your job can run without any problem with resources   standalone means that spark will handle the management of the resources on the cluster there are also other resource management tools like  yarn  or  mesos  overall you have 3 options for managing resources on the cluster: mesos   yarn    standalone   i would also mention that on a real hadoop cluster spark is not the only application that is running on your cluster which means it is not the only consumer of resources you can also run  hbase  tez   impala  yarn would help you to allocate resources to all of those applications,15,0.904662791577266,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
60214_kg,anyone else trying to add a data kernel external to a challenge and unable to add it? i click on `add data source  i find the data kernel in the list but i cannot click on the data kernel to add it nor can i cancel the popup window to add the data kernel to get back to the editor i have to refresh my page anyone else have experience with this?   i think this might have been due to a technical issue we were having around the time you made this comment it should be fixed now : do let us know if you run into any more trouble!   thank you for the reply! i ll try again and will let you know if i have any more issues   i am having an issue still - i can now add the dataset to my kernel through my notebook - i see the dataset under my  data  tab however i m not sure how i can access it through my r notebook for instance with     list.files ../input    i only see the datasets that were provided with the challenge but not the dataset i added does it take some time for the input folder to be properly synced? or should i look in another path for the data? thanks!   it does take a minute for your docker session to restart but you ll seen an indicator at the top of the kernel that tells you when it s done   if you add more than one dataset they are each in a separate folder in the input folder so it should be something like ../input/dataset-name/file.csv and ../input/notebook-name/file.csv,4,0.9045636039907977,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
55093279_so,"gradient gradient-descent machine-learning math python how to do a gradient descent problem machine learning could somebody please explain how to do a gradient descent problem without the context of the cost function? i have seen countless tutorials that explain gradient descent using the cost function but i really don t understand how it works in a more general sense  i am given a 3d function  z = 3*1-xx 2 * np.exp-xx 2 - yy+1 2 \- 10*xx/5 - xx 3 - yy 5 * np.exp-xx 2 - yy 2- 1/3* np.exp-xx+1**2 - yy 2  and i am asked to  code a simple gradient algorithm set the parameters as follows   learning rate = step size 0.1   max number of iterations 20   stopping criterion 0.0001 your iterations should stop when your gradient is smaller than the threshold   then start your algorithm at    x0 = 0.5 y0 = -0.5  x0 = -0.3 y0 = -0.3   i have seen this piece of code floating around wherever gradient descent is talked about   but i don t understand how to use it for my problem how does my function fit in there? what do i adjust instead of m and b? i m very very confused  thank you gradient descent is optimization algorithm for finding the minimum of a function   very simplified view  lets start with a 1d function y = fx  lets start at an arbitrary value of x and find the gradient slope of fx    if the slope is decreasing at x then it means we have to go further toward right of number line x for reaching the minimum   if the slope is increasing at x then it means we have to go away from left of number line x  we can get the slope by taking the derivative of the function the derivative is -ve if the slop is decreasing and +ve if the slope is increasing    so we can start at some arbitrary value of x and slowly move toward the minimum using the derivatives at that value of x how slowly we are moving is determined by the learning rate or step size so we have the update rule   we can see that if the slope is decreasing the derivative df_dx is -ve and x is increasing and so x is moving to further right on the other hand if slope is increasing the df_dx is +ve which decreases x and so we are moving toward left        we continue this either for some large number of times or until the derivative is very small  multivariate function z = fx,y  the same logic as above applies except now we take the partial derivatives instead of derivative.update rule is    where dpf_dx is the partial derivative of f with respect to x  the above algorithm is called the gradient decent algorithm in machine learning the fx,y is a cost/loss function whose minimum we are interested in   example   the min of z_func is at 1,2 this can be verified using the fmin function of scipy   now lets write our own gradient decent algorithm to find the min of z_func   we are starting at some arbitrary value x=10 and y=10 and a learning rate of 0.1 the above code prints   which is correct   so if you have a continuous differentiable convex function to find its optimal which is minimal for a convex all you have to do is find the partial derivatives of the function with respect to each variable and use the update rule mentioned above repeat the steps until the gradients are small which mean we have reached the minima for a convex function  if the function is not convex we might get stuck in a local optima",3,0.9042763355357339,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
45157593_so,cluster-analysis k-means boundaries is there any way to find boundaries coordinates for a x-y data in kmeans clustering i produced 8 clusters from the xy data which looks like below each color represent one cluster i need to get values of the boundaries for each cluster the  elki  tool that i usually use for clustering will generate the boundaries for you in the visualization i don t know if it will also output the coordinates to a file though  it s called a voronoi diagram and you need the dual the delaunay triangulation to build it you can easily find algorithms for that  beware that some edges will go to infinity just imagine two clusters how does their boundary look like? what are the coordinates of the boundary?  note that on your data set this clustering does not appear to be very good the boundaries between clusters look quite arbitrary to me,23,0.9041617226657426,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
8403139_so,cluster-analysis dendrogram matlab r extract cluster information from the generated dendrogram in the generated dendrogram graph the column marks the distance cutoff is there a way to get the cluster information for each of these distance cutoffs  in specific how to do that in matlab or in r if   is your dataset then in matlab the command   requires statistics toolbox will carry out hierarchical cluster analysis for you   is an m-1-by-3 matrix where m is the number of rows of   the first and second columns of   give you the indices of the data points or cluster centroids that have been merged together at each node of the dendrogram and the third column gives you the distance cutoff at that node  is that what you are asking for,23,0.9038703972236816,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
65780_kg,by accuracy you can t find out about overfitting.try your model on test data to find out also if you want to find out about underfitting you can use learning curve   you need to compare your accuracy on training data to your accuracy on test data if the model performs significantly better on training data than testing data you re likely overfitting if it performs similarly overfitting is less of a concern,1,0.9036489038556486,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
58152110_so,gradient-descent machine-learning minimization how does a gradient descent algorithm work when it is already in a local minimum in the context of gradient   not linear regression if the cost function is already at a local minimum what happens next? or how does it reach the global optimum later on?     in the case of linear regression there is only one minimum and hence  no problem of a local minimum but what about other algorithms that  might have a local minimum and a global minimum ,3,0.9035539119036206,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
122352_kg,hi there!i have to build a predictive model whose independent variables are a set of quantitative variables and polythomic factors i know for sure there will be some mid-to-high collinearity between some of the predictors 🔥 i m thinking about considering ridge or lasso regression or even a random forest but i am not sure how adequate are ridge or lasso regressions specially with factors as independent variables should in this situation consider a random forest or rigde and lasso can deal with polythomic factors?🤔 thanks a lot for your help!,2,0.9034664297816383,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
40220201_so,tensorflow what is the difference between tf.initialize_all_variables and tf.initialize_local_variables i am reviewing the code in this example  fully_connected_reader.py   i am confused with line 147 and 148   i don t know which variables are   and which are   any ideas a local variable in tf is any variable which was created with   for example      local_variables the subset of variable objects that are local to each  machine usually used for temporarily variables like counters note:  use tf.contrib.framework.local_variable to add to this collection   they are usually not saved/restored to checkpoint and used for temporary or intermediate values for a more detailed answer take a look  here   a global variable is mostly every other variable initialized by you   in a new version of tf you should use     because the previous functions were deprecated   global_variables   key to collect variable objects that are global shared across machines default collection for all variables except local ones   local_variables   key to collect local variables that are local to the machine and are not saved/restored    is a shortcut to     is a shortcut to   which initializes variables in   and   collections respectively  variables in   collection are variables that are added to the graph but not saved or restored  source       by default adds a new variable to   collection which can be controlled by collections= argument,7,0.9033854880607014,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
58396391_so,machine-learning python random-forest regression scikit-learn how to output the regression prediction from each tree in a random forest in python scikit-learn i m new to scikit-learn and random forest regression and was wondering if there is an easy way to get the predictions from  every tree  in a random forest in addition to the combined prediction  basically i want to have what in r you can do with the   option     i want to have every single prediction of every single tree not only the mean of them for each prediction  is it possible to do it in python use    this uses the  -attribute see  docs  which is a list of all the trained  decisiontreeregressors  we can then call the predict method on each one of them and save that to an array,9,0.9033613251295494,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
27004890_so,cluster-analysis hclust hierarchical-clustering r how to transform the following similarity matrix to distance matrix for performing hclust i am trying to cluster nodes c1 c2 c3... of a graph using hclust and my similarity metric is number of links between nodes   i have data like    basically this is a similarity matrix   this is an undirected graph where similarity between c1 and c3 is 3 links i need to transform this data to a suitable dist.matrix like    format based on my similarity metric #links between two nodes how do i do this take a look at the daisy function  http://www.inside-r.org/r-doc/cluster/daisy   it seems like you want to use hierarchical clustering based on edge-betweenness you can do this directly in,23,0.9033198628651682,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
123091_kg,in stadium type there are many duplicates though i have grouped all outdoor entries but i have confusion in creating the right grouping for the rest  should we make it outdoor open &amp closed indoor open &amp closed dome open &amp closed retractable open &amp closed others?any suggestion here ..  outdoor                   180972indoors                    22805dome                        9376retractable roof            8914indoor                      6892open                        4124domed closed               3076retr roof - closed         2235retr roof-closed           2015domed open                 1779dome closed                1059closed dome                 1011domed                        985domed open                  807outdoor retr roof-open       601indoor roof closed          547retr roof-open              486retr roof - open            486indoor open roof            479bowl                         465retr roof closed            414heinz field                  389cloudy                       178   thnks.gr8 work,8,0.9032142334099592,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
29606633_so,"opencv xcode xcode and opencv i am trying to compile a c++ project that uses opencv in xcode 6.2 i have downloaded opencv and the header and library files and setting as follow:header search path /usr/local/include/opencv2**library search path:/usr/local/liband opencv is truly in this path,but i get error   lexical or preprocessor issue/users/radio_lee/desktop/project/opencv/opencv/main.cpp:1:10  cv.h  file not found   when i change the header search path and library search path like that:header search path /usr/local/include/opencv2**  and /usr/local/include/opencvlibrary search path:/usr/local/lib  another error   lexical or preprocessor issue /usr/local/include/opencv/cv.h:63:10  opencv2/core/core_c.h  file not found  /users/radio_lee/desktop/project/opencv/opencv/main.cpp:1:10 in file included from /users/radio_lee/desktop/project/opencv/opencv/main.cpp:1 opencv is a private framework,since it is a private framework it must be copied to the frameworks/ directory of an application bundle which means it is useless for plain unix console applications.we can see the detail in this web site  http://docs.opencv.org/doc/tutorials/introduction/table_of_content_introduction/table_of_content_introduction.html#table-of-content-introduction   this folder contains toolchains and additional files that are needed for cross compilation.for more information see introduction tutorials for target platform in documentation",21,0.9030896006919803,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
88578_kg,there is thing that caught my attention once someone discovers the magic - he/she gets either  909-910  or  913-914  for example  felipe once he found the magic got 909  whereas  seth got 913 from scratch  if i remember correctly after magic was discovered chris got 909 and cpmp got 913   since i know the magic and it brought me to 909 score initially i was trying to achieve 913 score on pure magic last 24 hours with no success this observations brought me to conclusion about two ways of utilizing magic and i really wonder what can cause such differences no it s hpo of lgbm for sure   i started my discovery of the magic with 0.903 so i am not sure how exactly people are getting such a high score immediately after they break the 0.901 barrier i still have a lot to learn!   you are right! as uncle cpmp mentioned his progress as 0.900 &gt 0.901 &gt 0.913 &gt 0.922it confirms the fact that one magic boosts score by 0.009 and another by 0.013   might have to do with the parameters being used mine initially was 0.902 i tuned one thing and it got me to 0.909 i changed a few more things and it got me to 0.914....so theres a lot on parameter optimization i think that the second magic is to surpass the 0.920   for me parameter tuning with the magic only yields about 0.002 if compared to public kernel parameters.without any parameter tuning my magic gives about 0.917 cv/lb sadly i haven t found anything to increase that i am a running out of ideas   one magic and ended up getting .917.you might be using the second one....   i ve tuned about all possible hyperparameters now and it s still a large gap to the top so i doubt i have found all of the magic yet,14,0.9028895294068027,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
13882191_so,opencv titanium xcode4.5 trouble getting opencv framework symbols to link in xcode i m missing something minor here in my project using the opencv framework from a working demo  steps to reproduce    download the example app from  http://aptogo.co.uk/2011/09/opencv-framework-for-ios/     create a new titainum ios module with titanium create --platform=iphone --type=module --dir= --name=opencv --id=opencv    open the xcode project drag in the opencv framework from the facetracker app and the other required frameworks    add other_ldflags=$inherited -framework opencv to module.xcconfig    create new tiuiview and tiuiviewproxy classes named opencvview and opencvviewproxy    in the new opencvview class instantiate a uiviewcontroller that uses opencv    the build will build the titanium module but when i try to run the module test harness i get these errors for opencv objects  undefined symbols for architecture i386:  _cmsamplebuffergetimagebuffer referenced from:      -[videocaptureviewcontroller captureoutput:didoutputsamplebuffer:fromconnection:] in libopencv.avideocaptureviewcontroller.o  _cmsamplebuffergetoutputpresentationtimestamp referenced from:      -[videocaptureviewcontroller captureoutput:didoutputsamplebuffer:fromconnection:] in libopencv.avideocaptureviewcontroller.o  _cmtimemake referenced from:      -[videocaptureviewcontroller createcapturesessionforcamera:qualitypreset:grayscale:] in libopencv.avideocaptureviewcontroller.o  _cvpixelbuffergetbaseaddress referenced from:      -[videocaptureviewcontroller captureoutput:didoutputsamplebuffer:fromconnection:] in libopencv.avideocaptureviewcontroller.o  _cvpixelbuffergetbaseaddressofplane referenced from:      -[videocaptureviewcontroller captureoutput:didoutputsamplebuffer:fromconnection:] in libopencv.avideocaptureviewcontroller.o  _cvpixelbuffergetheight referenced from:      -[videocaptureviewcontroller captureoutput:didoutputsamplebuffer:fromconnection:] in libopencv.avideocaptureviewcontroller.o  _cvpixelbuffergetpixelformattype referenced from:      -[videocaptureviewcontroller captureoutput:didoutputsamplebuffer:fromconnection:] in libopencv.avideocaptureviewcontroller.o  _cvpixelbuffergetwidth referenced from:      -[videocaptureviewcontroller captureoutput:didoutputsamplebuffer:fromconnection:] in libopencv.avideocaptureviewcontroller.o  _cvpixelbufferlockbaseaddress referenced from:      -[videocaptureviewcontroller captureoutput:didoutputsamplebuffer:fromconnection:] in libopencv.avideocaptureviewcontroller.o  _cvpixelbufferunlockbaseaddress referenced from:      -[videocaptureviewcontroller captureoutput:didoutputsamplebuffer:fromconnection:] in libopencv.avideocaptureviewcontroller.o  cv::_inputarray::_inputarraycv::mat const&amp; referenced from:      -[demovideocaptureviewcontroller processframe:videorect:videoorientation:] in libopencv.ademovideocaptureviewcontroller.o  cv::_outputarray::_outputarraycv::mat&amp; referenced from:      -[demovideocaptureviewcontroller processframe:videorect:videoorientation:] in libopencv.ademovideocaptureviewcontroller.o  cv::cascadeclassifier::loadstd::string const&amp; referenced from:      -[demovideocaptureviewcontroller viewdidload] in libopencv.ademovideocaptureviewcontroller.o  cv::cascadeclassifier::cascadeclassifier referenced from:      -[demovideocaptureviewcontroller .cxx_construct] in libopencv.ademovideocaptureviewcontroller.o  cv::cascadeclassifier::~cascadeclassifier referenced from:      -[demovideocaptureviewcontroller .cxx_destruct] in libopencv.ademovideocaptureviewcontroller.o  cv::mat::deallocate referenced from:      -[videocaptureviewcontroller captureoutput:didoutputsamplebuffer:fromconnection:] in libopencv.avideocaptureviewcontroller.o      -[uiimageuiimage_opencv cvmat] in libopencv.auiimage+opencv.o      -[uiimageuiimage_opencv cvgrayscalemat] in libopencv.auiimage+opencv.o  cv::mat::createint int const* int referenced from:      -[uiimageuiimage_opencv cvmat] in libopencv.auiimage+opencv.o      -[uiimageuiimage_opencv cvgrayscalemat] in libopencv.auiimage+opencv.o  cv::flipcv::_inputarray const&amp cv::_outputarray const&amp int referenced from:      -[demovideocaptureviewcontroller processframe:videorect:videoorientation:] in libopencv.ademovideocaptureviewcontroller.o  cv::resizecv::_inputarray const&amp cv: outputarray const&amp cv::size  double double int referenced from:      -[demovideocaptureviewcontroller processframe:videorect:videoorientation:] in libopencv.ademovideocaptureviewcontroller.o  cv::fastfreevoid* referenced from:      -[videocaptureviewcontroller captureoutput:didoutputsamplebuffer:fromconnection:] in libopencv.avideocaptureviewcontroller.o      -[uiimageuiimage_opencv cvmat] in libopencv.auiimage+opencv.o      -[uiimageuiimage_opencv cvgrayscalemat] in libopencv.auiimage+opencv.o  cv::transposecv::_inputarray const&amp cv::_outputarray const&amp; referenced from:      -[demovideocaptureviewcontroller processframe:videorect:videoorientation:] in libopencv.ademovideocaptureviewcontroller.o  _kcvpixelbufferpixelformattypekey referenced from:      -[videocaptureviewcontroller createcapturesessionforcamera:qualitypreset:grayscale:] in libopencv.avideocaptureviewcontroller.old symbols not found for architecture i386clang error linker command failed with exit code 1 use -v to see invocation i have similar errors and just changing build setting does not help  finally i solved this problem by adding some framework like coremedia corevideo etc.these frameworks however are not used in my code  so i guess opencv needs these frameworks but i don t know why  hope this will help:  i had a similar problem with the default apple llvm compiler on xcode 4.5.1 try changing it to gcc from your build options and see if this works,21,0.902662940903043,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
135323_kg,hi can anyone please help in unzip file for emenddings.zip file i did just unzip files but it shows like flating google.text file.please help me out from this issue check out here   kernel link        neuro_stupid wrote       hi can anyone please help in unzip file for emenddings.zip file i did just unzip files but it shows like flating google.text file.  please help me out from this issue check out here   kernel link,4,0.90253743993754,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
91278_kg,i was trying to find the .csv dataset to download however i can only see the .json files can someone tell me if the .csv dataset is still available?    https://www.kaggle.com/yelp-dataset/yelp-dataset/version/6    there isn t a clear download button like on the main dataset page  goto  https://www.kaggle.com/yelp-dataset/yelp-dataset/version/6   click on yelp_review.csv under data sources then just below the .csv file list over to the right there is a grey download arrow the first of three little icons,4,0.9022793053870604,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
22336463_so,"matlab statistics how do i use the silhouette function in matlab i have a question on how to use silhouette function in matlab  if i have my correlation matrix x =  90x90 and my cluster membership numbers for my data say i have five clusters this is defined as cidx which is length 90x1 each value is assigned a number from 1 to 5  can i just pass the correlation matrix and cidx to the silhouette function and specify the measure as  correlation  or should i be passing in my returns matrix instead?  thanks for your help first of all you need to make your clusters for example  kmeans  function in matlab does this for you   according to matlab       idx = kmeansx,k  partitions the points in the  n-by-p  data matrix  x   into  k  clusters this iterative partitioning minimizes the sum over  all clusters of the within-cluster sums of point-to-cluster-centroid  distances rows of  x  correspond to points columns correspond to  variables  kmeans  returns an  n-by-1  vector  idx  containing the cluster  indices of each point   so here  cidx  is the  n-by-1  cluster indices.after finding the indices you can pass the  x  and the  cidx  to the  silhouette  function    s  is the silhouette values in the n-by-1 vector  silhouette is used to determine the quality of clustering the way this function works is illustrated below using a matrix of 100*3 size.example ",23,0.9021953598584264,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
55146700_so,deep-learning python tensorflow tf.get_collectiontf.graphkeys.global_variables of loaded .pb file is empy i m trying to look at variable list of loaded   file but for some reason it s empty  here is the code   also why is in v2 case i get    the     object serialized to the   file does not contain collections information if you want to store a graph along with its metadata including the collections you should save a     instead see     /      in your   code   is   because     does not return anything it just imports the nodes in the given graph definition into the current default graph  as a side comment note that  graph collections are being deprecated in tensorflow 2.x,7,0.9021665298405642,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
145319_kg,thanks for sharing this notebook!  i wanted to reach out and suggest that you save your notebook using the save and run all button instead of the quick save button  you should only click on quick save if you have already run your notebook from top to bottom or else your notebook will look blank if you have not already run your notebook from top to bottom then you will want to click on save and run all instead  you can read about the difference between quick save and save and run all here  https://www.kaggle.com/product-feedback/139884       and don t forget to make all of your data source public  thanks again for sharing this notebook,4,0.9017146107312701,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
11093735_so,cluster-analysis hierarchical-clustering hierarchical-data python how to select closest representative to the center in each cluster in scipy-cluster so basically i use the python module  scipy-cluster  to plot a lot of data points is there are way/function that give the representative of each cluster if given the threshold or the number of representatives i want? ideally each representative must has the closest distance to the center of the cluster it belongs to    edit i m looking for the data point closest to the centroid in each cluster i don t really know my way around scipy-cluster but it sounds like it gives you the centroid coordinates given that information and the knowledge of which points are in the cluster it should be trivial to calculate the distance from the centroid for each point in the cluster just make sure your calculation is based on the same distance metric you used for clustering probably euclidean distance  scipy-cluster provides coordinates for each centroid and identifies which points are in each cluster once you have that i believe     will give you the distance between observations and centroids,23,0.9014176873637992,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
14423854_so,c eye-detection opencv detect eye using hsv value in open cv i want to detect an eye i have some code where i can detect blue color object so if i made changeshow i can? then it would be possible for me to detect an eye as the below color has its own specific  range value so if i specify the eye color hsv value then can i detect eye with this method  in this below code i am going to detect blue color object please tell me that where i do changes in my code so that i could get eye using open cv such a simple method may work at extracting a blue object using some thresholding but even if it could be adapted using a different colour black? blue? green? everyone has different eye colours i don t see a non hacky method working for you using blob extraction like this based on a hsv threshold value this method works well on large blocks of the same colour i.e removing a blue background  look more at shape everyone has different coloured eyes but the shape is circular/ellipse ish there are varients of the  hough transform  for detecting circles     ...the hough transform has been extended to identifying positions of  arbitrary shapes most commonly circles or ellipses   eye detection is much easier with haar classifier. link here,20,0.9013150763773033,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
39244421_so,object-detection opencv how to detect and recognize a specific object in an image i want to detect or recognize a specific object in an image  first of all  say what i have done i tried to detect a logo  e.g  google logo i have the original image of the logo but in the images which i am going to process are taken with different cameras from different angle and from different distance and from different screens wide screen like cinema   i am using opencv 3 to check whether this logo is in these images i have tried the opencv surf sift etc functions and also tried norm_l2 algorithm which compares two images and template matching and also used svm it was so slow and not correct detection and some other opencv functions  but  no one was good to use  then  i did my own algorithm which is working better than the above functions but also cannot satisfy the requirements   now  my question is is there any better way to detect the specific object in an image? for example what should i do at the first and second.. steps ,20,0.9007365309208991,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
11272264_so,bigdata hadoop hdfs java mapreduce which machine does the reducer of the hadoop run on if i have a 4 node cluster where 1 machine is the namenode and the remaining 3 machines are datanodes and if i set the number of reducers to 1 which of the data nodes will run the reducer the namenode and datanode are hdfs processes not mapreduce i assume you have 3 task tracker nodes one of them will run it there is no guarantee which one hadoop generally moves computation to be near the data that it needs but for reducers they are pulling data from mappers not hdfs you can say hadoop will prefer a less loaded node with at least one reduce slot,15,0.9006786294247832,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
55562078_so,tensorflow2.0 tensorflow 2.0  frozen graph support will the support for frozen graph continue in tensorflow 2.0 or deprecated?i mean the scripts and apis to create/optimize frozen graph from saved_model also the apis to run the inference for the same   assuming it will be supported in future what is the recommended method to run the inference on frozen graph in tensorflow 2.0  the freeze graph apis -     and     - will not be supported in tensorflow 2.0  in 2.0 the primary export format is  savedmodels  so apis are built to directly support savedmodels. inference on existing frozen graphs can be run using the   path,7,0.9006753675238465,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
78233_kg,"since i only do this competition 5 days ago and i have 5 fold cv 3.648 ~ 3.646（i shuffle the random seed） and the lb score is 3.688i only submit twice so i have no idea how random seed influences the lb score.  but when i see this discussion  https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/73517  i see many kagglers  cv are similar to me    so i am a little confused about how much  can you gain  with post processing would you like to share your corresponding cv&amp;lb score before and after post-processing?   hi longyin  i would not say post processing but i did some ensemble and stacking that gave me boost of  .003 over my best single model   https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/77849    i try post processing https://www.kaggle.com/waitingli/combining-your-model-with-a-model-without-outlier  with my best single model but score   cv  3.652   before post-processing cv 3.655 lb 3.689  after post processing lb 3.685   thanks for sharing   thanks for sharing i will try that next time   thanks for sharing   actually post processing should get 4-6/1000 points imp   seems i should do more ensemble and stacking   may i ask what do you mean shuffle the random seed ?   i did different post processing approach   but i think that it is overfitting in the lb :d   like the example below     from sklearn.model_selection import stratifiedkfold,kfold  kf = kfoldn_splits=5,shuffle=true,random_state=1        @manoj -how many different model did u use?   got it   hi subikash,i have used 8 models all of them are lightgbm so far   thanks manoj all these are having different features ?   lb 3.695 cv  3.65498 -&gt 3.690   btw i tried to use the merchants.csv but it leads to bad results does anybody know how to use it?   top 80-90 features are common rest i am choosing and dropping randomly i still experimenting i have not yet build a proper pipeline    https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/77987#458060    you mean you can get nearly 3.658 without post processing this is amazing   yes，stacking really helps   single model lgb = lb 3.681 cv  3.6688 after post processing = lb 3.673   single lgb means one lgb model  or 5-fold lgb?   5 fold lgb   thanks   your cv score is impressive i think it shows a low risk of overfitting    for  outlier post-processing would anyone share that how you decide the threshold? 2207/201917?   sadly i got a huge gap between cv and lb.cv 3.64882 lb 3.693   this is reasonable now my cv is 3.6395 and lb is 3.679 the rest is from the kernel part by combining with binary classification   sadly i got a better  cv is 3.648 but lb is 3.687best lb is 3.683 and cv is3.6504i don t know how to deal with it   thanks for sharing   @longyin hi longyin! may u willing to have a talk with u ,then consider if team up with us    thanks for your kind invitation  i have formed a team  i am looking forward to having opportunities for future cooperation   okay thanks haha   both you guys are excellent!   without post processing.single model 9 fold cv score 3.648 lb score 3.680.break up of above score based on outliersscore only for non-outlier targets 1.826 score only for outlier targets 30.261",14,0.9004533928757951,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
39590729_so,bigdata hadoop hortonworks-data-platform raid hdp cluster with raid what is your experience with raid1 on hdp cluster?  i have in my mind two options   setup raid 1 for master and zoo nodes and don t use raid at all on slave nodes like kafka brokers hbase regionservers and yarn nodemanager s   even if i loose one slave node i will have two other replicas.in my opinion raid will only slow down my cluster   despite everything setup everything using raid 1   what do you think about it? what is you experience with hdp and raid?what do you think about using raid 0 for slave nodes i d recommend no raid at all on hadoop hosts there is one caveat in that if you are running services like oozie and the hive metastore that use a relational db behind the scenes raid may well make sense on the db host  on a master node assuming you have namenode zookeeper etc - generally the redundancy is built into the service for namenodes all the data is stored on both namenodes for zookeeper if you lose one node then the other two nodes have all the information  zookeeper likes fast disks - ideally dedicate a full disk to zookeeper if you have namenode ha give the namenode edits directory and each journal node a dedicated disk too  for the slave nodes the datanode will write across all disks effectively striping the data anyway each  write  is at most the hdfs block size so if you were writing a large file you could get 128mb on disk 1 then the next 128mb on disk 2 etc,15,0.9004118280811816,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
143003_kg,my notebook uses a datasource hosted on kaggle  https://www.kaggle.com/benhamner/jhucovid19   this dataset is updated on a daily basis  currently when i open my notebook i see in the datasource pane below the name of the dataset last updated 9 days ago version 30 of 48   what do i do to use a newer version of this dataset in my notebook,4,0.9001448581939898,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
46086401_so,cluster-analysis hierarchical-clustering matplotlib python scipy how to plot with label from scipy.cluster.hierarchy.linkage how can i plot a bunch of 2-d points x say using matplotlib with color labels from scipy.cluster.hierarchy.linkagex method=single say k = 3 fcluster from scipy.cluster.hierarchy will do,23,0.9000955410849452,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
58613825_so,computer-vision image image-processing opencv python get boundary from canny edges and remove the background of an image i m trying to remove the background of an image that im trying to train a neural network with i ve had little luck using the method described here  how do i remove the background from this kind of image?  but i have been able to use the canny edge detector to get a semi-good boundary of the object in my image heres my code i m running    and the resulting images we get are        so what i m looking for exactly is a way for me to get the boundaries of the canny edges and then from there crop the original image around these boundaries thanks if i understand correctly you want to remove the background and extract the object instead of using canny here s an alternative approach since you didn t provide an original image i screenshotted your image to use as input in general there are several ways to obtain a binary image for boundary extraction they include regular thresholding otsu s thresholding adaptive thresholding and canny edge detection in this case otsu s is probably the best since there is background noise      first we convert the image to grayscale then perform otsu s threshold to obtain a binary image     there are unwanted sections so to remove them we perform a morph open to separate the joints     now that the joints are separated we find contours and filter using contour area we extract the largest contour which represents the desired object then draw this contour onto a mask     we re almost there but there are imperfections so we morph close to fill the holes     next we bitwise-and with the original image     finally to get the desired result we color in all black pixels on the mask to white     from here you could use numpy slicing to extract the roi but i m not completely sure what you were trying to do i ll leave that up to you,20,0.9000852377746559,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
145112_kg,thanks for sharing this notebook!  i wanted to reach out and suggest that you save your notebook using the save and run all button instead of the quick save button  you should only click on quick save if you have already run your notebook from top to bottom or else your notebook will look blank if you have not already run your notebook from top to bottom then you will want to click on save and run all instead  you can read about the difference between quick save and save and run all here  https://www.kaggle.com/product-feedback/139884       and don t forget to make your datasets public!  thanks again for sharing this notebook,4,0.8995975470607429,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
53630654_so,caffe ubuntu-16.04 make *** [.build_release/src/caffe/solvers/sgd_solver.o] error 1 i m trying to install caffe on ubuntu but i m getting errors   root@c8f75a5e7268:/work/caffe# make all  protoc src/caffe/proto/caffe.proto  cxx .build_release/src/caffe/proto/caffe.pb.cc  cxx src/caffe/solvers/sgd_solver.cpp  in file included from ./include/caffe/common.hpp:19:0  from ./include/caffe/blob.hpp:8  from ./include/caffe/net.hpp:10  from ./include/caffe/solver.hpp:7  from ./include/caffe/sgd_solvers.hpp:7  from src/caffe/solvers/sgd_solver.cpp:4  ./include/caffe/util/device_alternate.hpp:34:23 fatal error cublas_v2.h no such file or directory  compilation terminated  makefile:591 recipe for target  .build_release/src/caffe/solvers/sgd_solver.o  failed  make *** [.build_release/src/caffe/solvers/sgd_solver.o] error 1 ,21,0.8995612762472189,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
6565_kg,recently i clicked an e-mail link to a forum and saw the message that i must be logged in to reply so i logged in and then was taken to kaggle home rather than back to the page i was looking at when i clicked the link to log in it took a while to find that page again and would be a better user experience to redirect after login including after any unsuccessful login or forgot password etc. back to where one came from on the site!   rather annoying indeed  here s a workaround log in press the back button until you reach the page you wanted and thenrefresh,4,0.8984383937093515,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
32697369_so,"matlab neural-network matlab neural network structure i m full newbie in neural networks i generated nn in matlab further i need to know exact structure of this nn because i need to implement it in javastatic connections and weights no learning can you explain how to connect neurons and what math operations perform in each element?  nn params are nexttaken from matlab   iw{1,1} - weight to layer 1 from intput 1     lw{2,1} - weight to layer     b{1} - bias to layer 1     b{2} - bias to layer 2    transfer function      greatly appreciate your help you have a nn that has 2 inputs then a hidden layer of 6 neurons and an output layer of 1 neuron  each of the neuron in each layer will take all the outputs from the previous one and multiply them by a number and offset the result by another  the numbers you show are the numbers i mentioned  for example the neuron 1 from hidden layer will output   then take whatever sigma function you are using and apply    as another example the output will be",11,0.8984134421089124,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
43432090_so,r regression stata statistics find variance in a logistical multilevel analysis i am trying to show the variance of different variables in a logistical multilevel analysis i just find the variance in the second level contextual  in a lineal multilevel regression i have the residual variance that i apply the next formula   variance = [σum0 - σum4] / σum0   σum0 is a null model  σum4 is a variable   but in a logistic multilevel regression i have not residual variance so   how can i know what variance explains the individual level and the contextual level?  note:i have a variance from level 2 but stata don t give me the level 1 variance this is a statistical question not a programming one but what you are looking for is the  intraclass correlation or icc   the way to get this measure is to run the empty model in stata and then type  .for example if you have a three level model you would do    the output of   tells you what percentage of the variance in the dependent variable is on the second level and the third level the difference to 100 is the first level variance usually if icc is lower than .1 that is 10% don t expect independent variables to explain much on the respective level,2,0.8983837033331092,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
57310804_so,"image-processing opencv svm how to find recognize certain shape in image so i want to find a certain shape in a videostream for example a certain starshape in a drawing when a camera is pointed to it i have extracted hog desciptorvalues of a single image of the shape i want to search i took the canny of the image how do i use these descriptorvalues with svm to find the shape on an other image or videostream and draw a boundary box around it? maybe an easier method than hog?  example with pictures: shape i want to search , example of wanted result ",20,0.8982918974465927,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
57797146_so,"computer-vision opencv python-3.x how to properly filter this image using opencv in python i have a computer vision project where i need to recognise digits on some totems which contain direction signages an example image is here :     so i tried many methods such as taking laplacian   after applying this i get a pretty good distinguish between background and the digits but since the output becomes 16sc1 i can not take the contours in the image i tried thresholding this but still can not get anything clear out of it  that s what i get after thresholding from range5000,8000 and converting it to uint8     in the end i try to take contours from it with this code here     result would be         how can i improve my solutions for this task and get all the digits? besides laplacian filter i tried darkening the image by lowering contrast and extracting white color regions it did kinda good but still couldn t get all the digits i tried gaussian blur and canny edge but at some places where the totem and the background are in the same pixel value contours merged ",20,0.8980923953128335,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
22614035_so,cluster-analysis k-means python k-mean clustering make centroids not overlap nodes i have done k-mean++ clustering and obtained the centroids of the clusters using python 2.7 following the method given in  http://datasciencelab.wordpress.com/2014/01/15/improved-seeding-for-clustering-with-k-means/   in my problem there is a further constraint that the distances between any centroid to any node should be larger than a constant what is the best way to achieve?  it is possible that one centroid is too close to several nodes  any suggestions on how to displace the centroids a bit?  many thanks  for example the nodes to be clustered are mynodes = [[469500 5802610] [468764 5803422] [467991 5804202] [470260 5799949] [469486 5800730] [468713 5801510] [467939 5802291] [467166 5803072] [467966 5800204] [467193 5800985] [466420 5801766] [466457 5799700] [465678 5800488] [464950 5799229] [470615 5796600] [469842 5797405] [470320 5794955] [469547 5795735] [468773 5796516] [467990 5797297] [470062 5793215] [469289 5793996] [468515 5794776] [467742 5795557] [466969 5796338] [466195 5797119] [469976 5791334] [469202 5792115] [468429 5792896] [467656 5793676] [466882 5794457] [466109 5795238] [465336 5796050] [464600 5796840] [470160 5789250] [469354 5789972] [468581 5790753] [467808 5791534] [467034 5792315] [466261 5793096] [465488 5793877] [464714 5794658] [463941 5795499] [463150 5796210] [469500 5787920] [468698 5788614] [467925 5789395] [467152 5790176]]  centroids = [[  467839.6  5793224.1] [  467617.22222222  5800489.94444444]]centroid[0] would be too close to node[29] centroid 1  would be too close to node[8 if i understand your question correctly and i am not at all sure whether i do then the solution is already apparent from your drawings  you want the point that is closest  to a given centroid point and has a minimum distance from a set of node points   draw a circle around each node point with your minimum distance as the radius    intersect each circle with each other circle note the intersection points  discard any intersection point that is closer than the minimum distance to a node point  from the remaining intersection points take the one closest to the centroid point that is your new displaced centroid   runtime for the naive implementation should be   though you can optimize that by using some fast nearest-neighbour lookup data structure such as a kd-tree when you intersect the circles and discard the intersection points that are too close  this should be the optimal solution no matter which algorithm you use you cannot find a point closer to the original centroid that fits the minimum distance constraint and this algorithm should always find that optimal point  though since the centroid is generally surrounded by node points the new point may be quite some distance away if the node points are densely packed,23,0.8979037469817828,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
57991573_so,python tensorflow tensorflow frozen graph and graph.get_collection trying to print   etc after loading frozen graph   output   why it return empty list of variables?   update   looks related   how do you list the variables in the graph in tensorflow?      that shows contents of variables collection which does not get  restored with import_graph_def however it does get restored when you  import meta graph ,7,0.8977553141628525,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
30717096_so,cluster-analysis r how to extract cluster centres from agnes for inputting into kmeans one recommended method  for getting a good cluster solution is to first use a hierarchical clustering method choose a number of clusters then extract the centroids and then rerun it as a k-means clustering algorithm with the centres pre-specified a toy example   this would give me two clusters how can i extract the cluster centres in a format that i can then put into the   algorithm and reapply it to the same data you can use the clustering to assign cluster membership and then calculate the center for all the observations in a cluster the   function allows you to specify initial centers via the   parameter if you pass in a matrix you can do that with,23,0.8975121481845167,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
40847889_so,tensorflow tensorflow-serving freezing tensorflow model saved by session_bundle.exporter i am currently following  train and export tensorflow model     which produces for each step   how do i take these files and create a  frozen model  for example by using    ?  it looks like   wants a   but all i have is a   file do i need to extract this first?  can the   file be used for the tensorflow variables file to load?  are there any other flags that i should pass when trying to freeze the model this seems to work for me,7,0.8974977589240264,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
55163846_so,python tensorboard tensorflow adding tf.identity ops to existing graph i have modified existing graph   https://github.com/tropcomplique/faceboxes-tensorflow/blob/master/src/detector.py#l70   adding   ops to get readable names to find out them in graph after   then having existing checkpoint i converted checkpoint to .pb using this modified graph like decribed here: https://github.com/tropcomplique/faceboxes-tensorflow/issues/6   but then when i try to convert .pb to tensorboard via  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/import_pb_to_tensorboard.py  and then try to view it via tensorboard   so is it possible to set readable names to some ops of existing graph ,7,0.8974711409714397,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
36715615_so,classification machine-learning python-2.7 scikit-learn using onevsrestclassifier from sklearn to tune a customized binary classification into a multi-class classification i have binary classification method name  fmclassifier  i need to apply it on a multi-class classification problem so far i know it is possible to use some estimators to turn a binary classifier or a regressor into a multiclass classifier.i was wondering if this goal can be reached using  onevsrestclassifier  in  sklearn  ? if so i need to know how can i apply it in my code? is something like the following code a right way in sklearn onevsoneclassifier and outputcodeclassifier are also available other than onevsrestclassifier.fyr  http://scikit-learn.org/stable/modules/multiclass.html   yes it would be something like   you just need to ensure that your classifier implements  fit and one of decision_function or predict_proba methods more info on it here: http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.onevsrestclassifier.html   in your example you use onevsoneclassifier this is a different meta-classifier with different approach,9,0.8973513879601501,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
58197749_so,python tensorflow tensorflow.js which version of tensorflow.js is compatible with models trained in tensorflow 1.12.0 python i need to convert models trained in tensorflow 1.12.0 python into that of tensorflow.js what version of tf.js and tf.js converter is compatible with it you have not mentioned in which format you are saving your model in tensorflow 1.12 i would recommend to make use of saved model format to save your model if you use saved models you can use the latest versions of tf.js and tf.js converters same is the case for keras h5 model as well  however if you save it in form of   files you will have to use tf.js version of 0.15 and tf.js converter of 0.8.6,7,0.8973314225288984,"0.123*""tensorflow"" + 0.035*""model"" + 0.026*""tf"" + 0.026*""graph"" + 0.024*""python"" + 0.023*""variable"" + 0.015*""code"" + 0.014*""tensor"" + 0.014*""create"" + 0.013*""function"""
39854101_so,c++ image-processing opencv erase shadow of an image in opencv 3.0 i m working with license plate segmentation and i have some images with shadows in the part of the plate that difficult the recognition processing some idea of erase the shadow in the part of the plate for leave the letters clear thanks and appreciate any helps!   here two images    image with shadow2   i want use mser for detect the letters in the plate and after do a segmentation of it firstly i do a preprocess of the imageblur and clahe after  apply a morphological blackhat transformation and after apply the mser but the recognition isn t good i think that removing the shadow of the plate the result will be better i don t know what to do thanks for your response and help!! my code and result is    the final result is   mser i also don t see any problems with the shadow that would affect the image recognition of the plate what you will need to do is isolate the letters and numbers on the license plate on each image file by using an image segmentation algorithm of your choice the shadow and all the other parts of the images should be treated as noise and interference you could also use thresholding and the hough transform algorithm in order to assist with the optical character recognition,20,0.8972282113837382,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
142722_kg,i created the coronawhy plus dataset as a quick way to unblock folks wrestling with the kaggle vs pickle issue on the coronawhy dataset as that dataset has moved to gcp i do not plan to update it further and plan to remove the v6_text folder soon please let me know when you have repointed your kernel    https://console.cloud.google.com/storage/browser/coronawhy/nlpdatasets/v7_preprocessed?pli=1,4,0.897114111457559,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
93606_kg,"so i noticed these are the possible values for the participant type  { arrested ,  injured ,  injured arrested ,  injured unharmed ,  injured unharmed arrested ,  killed ,  killed arrested ,  killed injured ,  killed unharmed ,  killed unharmed arrested ,  unharmed ,  unharmed arrested }  some of these don t make sense such as  killed injured     killed unharmed",8,0.8966983442537517,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
10279_kg,hello  it would be really useful if one could use curl or wget or some other non-interactive cli tool to download competition data files on remote servers to do that it would be very convenient if kaggle supports http basic authentication i wouldn t know if it does since using my google account to login i do not have a kaggle password  so does kaggle support http ba and if so is there a way to use it with an account setup to login with oauth?  thanx!  edit apparently i  suck at googling,4,0.8966497419512666,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
1768994_so,cluster-analysis fuzzy c means in matlab i am clustering some data in matlab using the builtin fuzzy c means algorithm which returns c the cluster centers u fuzzy partition matrix so i know what the cluster centers are from c but how can i figure out which cluster center each data point belongs to? using the fuzzy partition matrix or some other way i know it is a very old question but someone else might find helpful if i give the answer  the following example is from the matlab help there are 2 clusters in the example   index1 is the indices of the data point that belong to the cluster 1 and index2 is similar so using this info what you need is easily obtained,23,0.8959299583129298,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
103328_kg,"please i need help with this this is just a dummy data the actual data has over 9,000 rows the goal is to remove all the rows with   in desc columns and also remove the row that   matches those with   in desc columns the index of the desired result will be          i can t really understand your question you want to remove the rows with duplicate  ref_id  but only the ones with different  desc  value?   you can get refid of all rows where desc is  witrev  and then can filter those rows  refid = dfa.loc[dfa.desc ==  wit rev ][ ref_id ].values  output = dfa.loc[dfa.desc!=  wit rev  &amp ~dfa.ref_id.isinrefid",19,0.8957147754553103,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
17298257_so,image image-recognition image-segmentation opencv texture based image segmentation i ve got photo of room with carpet on the floor i ve got texture sample of carpet i want to detect carpet borders on photo  could you please describe how to perform texture based image segmentation using opencv you can apply an edge detecting filter like canny to extract the edges as a feature then you can apply a similarity function between the distance-points of the carpet in your template and try to find a scaling parameter for the lines you have extracted in your edge detection phase   you can also use some deep learning algorithms which are more complicated,20,0.8953445196868532,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
58350510_so,cluster-analysis k-means r distance matrix in k-prototypes clustmixtype hi everyone i am trying to obtain a distance matrix when using clustmixtype r package specifically when using the function kprotox ... the output gives me a column called cluster which is the vector of cluster memberships and other columns called dists.i [matrix with distances of observations to all cluster prototypes] where i is the number of resulting clusters like the following data frame    but in my knowledge this is not a distance matrix like   i want to know if it is possible to derive the distance matrix from the r output  thank you use the function   to compute a pairwise distance matrix    performs prototype clustering it probably does not use pairwise distances only to prototypes,23,0.8951537312698336,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
21696444_so,boost g++ opencv visual-c++ how to compile g++ on windows using visual studio 2010 i have successfully installed opencv and boost library and config in my visual studio i want to run a project  here  how can i compile this project with g++ on windows?     g++ -o detecttext textdetection.cpp featuresmain.cpp -lopencv_core  -lopencv_highgui -lopencv_imgproc -i/path/to/current/directory where /path/to/current/directory is replaced with the absolute path to the  current directory   i am very new and please help me step by step to run this  project using vc++  thank you so much you cannot mix g++ and msvs without a lot of pain use a different ide like qt creator with cmake eclipse or code::blocks  you seem to know how to compile from the commandline so why not just do that,21,0.8951208977649772,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
25639996_so,"cluster-analysis dendrogram matlab grouping using dendrogram matlab i have a matrix a composed by 4 vectors columns of 12 elements each   i also have a similarity matrix that states how much a vector is similar to the others   reading the rows of this matrix   i would like to create a dendrogram graph that shows me how many different groups there are in a considering a threshold of 0.95 for similarity i.e if 2 groups have a similarity >0.7 connect them  i didn t really understand how to use this function with my data. not sure i understood correctly you question but for what i ve understood i will do that   it gives the result   after compute the linkage   you can plot the dendrogram with   however you want to split the groups according to a threshold so   this is the dissimilarity at which to cut here it means that two groups will be connected if they have a similarity higher than 0.9   the result of t in that case is   this means that at this level your vectors 1 2 3 4 call them a b c d are organized in 3 groups   a  b,d  c    also with c = 0.3 or 0.7 similarity   so there is just one group here  to have that on the dendrogram you can calculate the number of groups   after   in that case the dendrogram won t display all groups because you set the maximum of nodes equal to the number of groups",23,0.8946533176441487,"0.077*""cluster"" + 0.027*""point"" + 0.021*""distance"" + 0.020*""datum"" + 0.019*""matrix"" + 0.018*""algorithm"" + 0.013*""pca"" + 0.013*""analysis"" + 0.011*""number"" + 0.011*""vector"""
21949921_so,c++ face-detection opencv how we can avoid unwanted detection currently i am doing face detection from video images i am able to detect faces from videos i am using haar cascade classifier for that  but it shows some unwanted detection  that is it detect some region that is not a face   what should i do to avoid this unwanted detection in my program i am using   function is there any wrong with that thanks in advance you can setup the corresponding parameters for     to suit your purpose i.e filter out unwanted faces  during these parameters you need to pay more attention to four of them     scalefactor  – parameter specifying how much the image size is reduced at each image scale     minneighbors  – parameter specifying how many neighbors each candidate rectangle should have to retain it     minsize  – minimum possible object size objects smaller than that are ignored     maxsize  – maximum possible object size objects bigger than that are ignored,20,0.8944698432168947,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
10354_kg,congratulations everyone this is the best competition in terms of sharing benchmarks ideas and tools and hope all of these help physicists : &nbsp  i have a question about blending/ensemble methods in the contest i tried two things to ensemble my xgb rf and linear models  1 voting to get final labels  2 simple averaging of ranks and then take top 15% or whatever threshold to be final  s   but neither of them improves  what s your ensemble method? many many thanks!   hi  i had 700 features and i used xgboost here is one of my cv with ensemble  i trained 4 models with same parameters except colsample_bytree i set colsample_bytree = 1.0 0.5 0.25 and 0.1 and then average their result with same weight output ams s are listed below as you see it improved ams 0.04 compared to the highest ams among 4 models have  param3[ bst:eta ] = 0.1  param3[ bst:max_depth ] = 8  param3[ bst:min_child_weight ] = 250  param3[ bst:colsample_bytree ] = xx    num_round =450 # number of boosted trees  model 1 with 1.0 -------------------------------------------- thresh0 = 0.1300 ams = 3.6440 std = 0.1098 thresh0 = 0.1325 ams = 3.6551 std = 0.1085 thresh0 = 0.1350 ams = 3.6707 std = 0.1201 thresh0 = 0.1375 ams = 3.6762 std = 0.1257 thresh0 = 0.1400 ams = 3.6938 std = 0.1068 thresh0 = 0.1425 ams = 3.7048 std = 0.1029 thresh0 = 0.1450 ams = 3.6991 std = 0.0933 thresh0 = 0.1475 ams = 3.6973 std = 0.0949 thresh0 = 0.1500 ams = 3.6840 std = 0.1111 thresh0 = 0.1525 ams = 3.6947 std = 0.1055 thresh0 = 0.1550 ams = 3.6850 std = 0.0911 thresh0 = 0.1575 ams = 3.6791 std = 0.1043 thresh0 = 0.1600 ams = 3.6685 std = 0.0945 thresh0 = 0.1625 ams = 3.6629 std = 0.1054 thresh0 = 0.1650 ams = 3.6655 std = 0.1164 thresh0 = 0.1675 ams = 3.6576 std = 0.1108 thresh0 = 0.1700 ams = 3.6434 std = 0.0962 ------------------------------------------------------  model 2 with 0.5--------------------------------------------- thresh1 = 0.1300 ams = 3.6842 std = 0.1680 thresh1 = 0.1325 ams = 3.7027 std = 0.1614 thresh1 = 0.1350 ams = 3.7128 std = 0.1781 thresh1 = 0.1375 ams = 3.7233 std = 0.1579 thresh1 = 0.1400 ams = 3.7238 std = 0.1343 thresh1 = 0.1425 ams = 3.7331 std = 0.1288 thresh1 = 0.1450 ams = 3.7524 std = 0.1311 thresh1 = 0.1475 ams = 3.7394 std = 0.1214 thresh1 = 0.1500 ams = 3.7453 std = 0.0942 thresh1 = 0.1525 ams = 3.7354 std = 0.0991 thresh1 = 0.1550 ams = 3.7295 std = 0.0983 thresh1 = 0.1575 ams = 3.7125 std = 0.1056 thresh1 = 0.1600 ams = 3.7140 std = 0.1100 thresh1 = 0.1625 ams = 3.6945 std = 0.0909 thresh1 = 0.1650 ams = 3.6802 std = 0.0871 thresh1 = 0.1675 ams = 3.6717 std = 0.0743 thresh1 = 0.1700 ams = 3.6605 std = 0.0860 ------------------------------------------------------  model 3 with 0.25------------------------------------------ thresh2 = 0.1300 ams = 3.6790 std = 0.1354 thresh2 = 0.1325 ams = 3.7132 std = 0.1299 thresh2 = 0.1350 ams = 3.7229 std = 0.1238 thresh2 = 0.1375 ams = 3.7351 std = 0.1322 thresh2 = 0.1400 ams = 3.7320 std = 0.1350 thresh2 = 0.1425 ams = 3.7437 std = 0.1306 thresh2 = 0.1450 ams = 3.7625 std = 0.1389 thresh2 = 0.1475 ams = 3.7510 std = 0.1414 thresh2 = 0.1500 ams = 3.7507 std = 0.1214 thresh2 = 0.1525 ams = 3.7447 std = 0.1164 thresh2 = 0.1550 ams = 3.7475 std = 0.1154 thresh2 = 0.1575 ams = 3.7404 std = 0.1009 thresh2 = 0.1600 ams = 3.7426 std = 0.1047 thresh2 = 0.1625 ams = 3.7392 std = 0.0928 thresh2 = 0.1650 ams = 3.7429 std = 0.1022 thresh2 = 0.1675 ams = 3.7384 std = 0.0808 thresh2 = 0.1700 ams = 3.7230 std = 0.0730 ------------------------------------------------------  model 4 with 0.1-------------------------------------------- thresh3 = 0.1300 ams = 3.7109 std = 0.1737 thresh3 = 0.1325 ams = 3.6996 std = 0.1408 thresh3 = 0.1350 ams = 3.7116 std = 0.1188 thresh3 = 0.1375 ams = 3.7117 std = 0.1148 thresh3 = 0.1400 ams = 3.7168 std = 0.1111 thresh3 = 0.1425 ams = 3.7142 std = 0.1100 thresh3 = 0.1450 ams = 3.7327 std = 0.1037 thresh3 = 0.1475 ams = 3.7327 std = 0.0858 thresh3 = 0.1500 ams = 3.7343 std = 0.0906 thresh3 = 0.1525 ams = 3.7337 std = 0.0864 thresh3 = 0.1550 ams = 3.7381 std = 0.0906 thresh3 = 0.1575 ams = 3.7347 std = 0.0961 thresh3 = 0.1600 ams = 3.7387 std = 0.1132 thresh3 = 0.1625 ams = 3.7306 std = 0.1091 thresh3 = 0.1650 ams = 3.7404 std = 0.0986 thresh3 = 0.1675 ams = 3.7300 std = 0.0993 thresh3 = 0.1700 ams = 3.7224 std = 0.0892 ------------------------------------------------------  average model --------------------------------------------------- threshcom = 0.1300 ams = 3.7567 std = 0.1653 threshcom = 0.1325 ams = 3.7612 std = 0.1696 threshcom = 0.1350 ams = 3.7561 std = 0.1407 threshcom = 0.1375 ams = 3.7538 std = 0.1383 threshcom = 0.1400 ams = 3.7612 std = 0.1293 threshcom = 0.1425 ams = 3.7718 std = 0.1160 threshcom = 0.1450 ams = 3.7861 std = 0.1230 threshcom = 0.1475 ams = 3.7897 std = 0.1143 threshcom = 0.1500 ams = 3.7861 std = 0.1094 threshcom = 0.1525 ams = 3.7901 std = 0.1085 threshcom = 0.1550 ams = 3.7997 std = 0.0996 threshcom = 0.1575 ams = 3.7998 std = 0.0976 threshcom = 0.1600 ams = 3.7869 std = 0.0901 threshcom = 0.1625 ams = 3.7806 std = 0.0895 threshcom = 0.1650 ams = 3.7742 std = 0.0906 threshcom = 0.1675 ams = 3.7636 std = 0.0906 threshcom = 0.1700 ams = 3.7599 std = 0.0828 ------------------------------------------------------   btw i ran 5 fold cv   thank you very much davut,14,0.8939723784104128,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
31397902_so,c++ cascade-classifier image-processing opencv how can i resize an image where the face should be cropped and scaled to fit the size my webcam takes images but opencv gender classification needs the images to be of the same size of that of the images used to train so i need my webcam images to be 300x300 where the face in the webcam images would fit the resolution 300x300 i have identified the face in the webcam image using opencv face cascade classifiers but how can i crop that face to fit in the size of 300x300? please help with some code lines as i am new to opencv here a small sample that will help you to crop and resize your  faces        detected face     cropped face      resized face,20,0.8936588301197524,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
8108_kg,"it is seen in the transactions records that most customers ids had so many transactions per day i m curious about what kind of&nbsp;customers they are?&nbsp   i think it s just supermarkets with food and so because many of transactions are per count and other are per weight   yes,they must be retailers   the transactions are per item purchased which means if some customer&nbsp;go to supermarket and buy 10 items like milk bread butter etc in a single trip then you will see 10 transactions in a single day for that customer so transactions table is per item transactions although muat be buying many items in a single trip   sorry typo in the last line -&nbsp so transactions table is per item &nbsp transactions although customer must be buying many items in a single trip",8,0.8935701131433391,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
93047_kg,seismic waves   seismic waves are the waves of energy caused by the sudden breaking of rock within the earth or an explosion they are the energy that travels through the earth and is recorded on seismographs   types   there are several different kinds of seismic waves and they all move in different ways the two main types of waves are body waves and surface waves body waves can travel through the earth s inner layers but surface waves can only move along the surface of the planet like ripples on water earthquakes radiate seismic energy as both body and surface waves   body waves   traveling through the interior of the earth body waves arrive before the surface waves emitted by an earthquake these waves are of a higher frequency than surface waves   p wave   the first kind of body wave is the p wave or primary wave this is the fastest kind of seismic wave and consequently the first to  arrive  at a seismic station.    s wave   the second type of body wave is the s wave or secondary wave which is the second wave you feel in an earthquake an s wave is slower than a p wave.    surface waves   travelling only through the crust surface waves are of a lower frequency than body waves and are easily distinguished on a seismogram as a result though they arrive after body waves it is surface waves that are almost enitrely responsible for the damage and destruction associated with earthquakes this damage and the strength of the surface waves are reduced in deeper earthquakes   love waves   it s the fastest surface wave and moves the ground from side-to-side confined to the surface of the crust love waves produce entirely horizontal motion.    rayleigh waves   a rayleigh wave rolls along the ground just like a wave rolls across a lake or an ocean because it rolls it moves the ground up and down and side-to-side in the same direction that the wave is moving most of the shaking felt from an earthquake is due to the rayleigh wave which can be much larger than the other waves.   source   http://www.geo.mtu.edu/upseis/waves.html   edit 1 when the seismic waves reach a piezoelectric sensor shown below a sensitive material present in the sensor gets deformed which generates voltage     awesome graphics so for real earthquakes do people experience a combination of a love wave + rayleigh wave?   nice visuals wish i didn t drop geology 201 back in the day thank you for recapping p and s waves hardly remember p and s waves other than the fact that one is faster than the other   now i wonder if there is a way to extract these waves from acoustic readings if i m not mistaken   is measured in voltage..      the seismic data is recorded using a piezoceramic sensor which outputs a voltage upon deformation by incoming seismic waves the seismic data of the input is this recorded voltage in integers   quoting bertrand from the discussion   so the piezoelectric sensors are vertically oriented? i am very confused   as far as i rememberhaven t work on the competition for a while we do not deal with seismic waves here the graphs generated from the data  are not seismograms they do not represent ground movements they represent the acoustic emission recorded during the experiment  something like- how noisy are the particles when move or/and break   i think edit 1 should be  when the  acoustic  waves reach the sensor..   that part was unclear to me too i  googled information about the sensor and as i remember the sensor record the acoustic signal emitted when the grains in the experiment rearrange i interpret that as how noisy is around there  if nothing moves it will be quiet when a force is applied and the grains start to rearrange it will be noisy the data represents time periods before the failure with that in mind we can not extract  p or s waves because they do not exist yet they start to radiate after the earthquake occurs,10,0.8934104661157471,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
14652_kg,can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline   can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline   can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline   can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline   can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline   can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline   can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline   can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline   can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline   can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline   can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline   can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline   can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline   can you tell me whyxtrain[i][0] = gen_snowlinextrain[i][1] = gen_tavglinextrain[i][2] = gen_tmaxlinextrain[i][3] = gen_tminlinextrain[i][4] = gen_weekline  can it be restructured randomly?just like that xtrain[i][0] = gen_tavglinextrain[i][1] = gen_snowline,19,0.8932047431728446,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
57999284_so,computer-vision image-processing image-stitching opencv python in opencv warpperspective how do i transform the left image and stitch it to the image on the right i m trying to do an image stitch using opencv by doing sift->knn->warpperspective there are whole lot of resource on how to warp the image on the right to be stitched on to the destination on the left i ve tried calculating the homography matrix for warping left image to be stitched to the right and that seems to work problem is i can t stitch the image together with cv2.warpperspective since it seems to put the image in where it should be if the right side image is warped  my code is basically   but this creates image offset shifted to the right how could i stitch the images correctly first you should resize the images and place them in a bigger image each with   and,20,0.8931851935635668,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
108911_kg,there is a way to download data to a headless server - you start download with your browser and the copy the url of the download it will be a long url now you can cancel download in the browser and start download on the headless server with wget   this works but put the url in quotes when using wget   i m missing a step how do i get the download url? if i right-click on the download button i just get this link  https://www.kaggle.com/c/15768/download-all  which isn t the download link?   this is a redirect link if you go to that link then copy the new link from your download manager in chrome start the download first then go to downloads and copy the link from there   thank you sir! the key for me was to look at the chrome download manager grab the url from there and then use wget with the url in quotes thanks again ,4,0.8931563221620707,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
138771_kg,i thought it would be better to build a model by increasing the train set using the test set.is this allowed?   can you? yes its just a data.should you? no.i am assuming the question is related to kaggle competition data even in general i suggest don t use test data for training your model test data is used to test the variances accuracy in unseen data besides train data is taken in larger portion than test data 😊    if you do so your test set will not be a test set anymore it will become a part of your training set you should not use test set as training set i think because the meaning of test set is to see if your model is accurate if you train your model on the test set the   accuracy   on the test set will have no meaning,1,0.8931317483359785,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
44531_kg,what is your best single model performance?  mine:lightgbm 0.284 - 0.285nn 0.284 - 0.285xgboost 0.283-0.284  my xgboost really doesn t like this dataset :   xgboost 0.285 lgb 0.284 nn 0.282 rgf 0.283   how come you are not in 0.288 army    i don t know :  i ve been debugging my ensembling for last few days something wrong somewhere     or or maybe you are actually at the top of private lb :   @cpmp if you have a submission or three to burn   this   may be something to try   @tilii i ve played with power averaging too  how do you know i have 3 subs left today? ;      how do you know i have 3 subs left today?   female intuition?   xgboost 0.286 lgb 0.285 nn 0.280   are these cv scores or lb? my best 5 fold cv score is 0.2868967 via lightgbm this is non-bagged lb is 0.283 i didn t even bother looking at the lb for this contest we ll see how that turns out    xgboost 0.284 lgb 0.286 catboost 0.286 0.283 out of the boxand i have used knn to filling nas   i think they are public lb  mine are for sure   how did you make nn achieve this performance? how to deal with the missing values?    lb scores cv scores vary a lot even with different seeds.. public lb sometimes doesn t align with public lb but for my weighted average stacking they are perfectly aligned   i had similar issues kim stacking gave me 0.298 cvwith different lightgbm and xgboost models but only 0.283 on lb :   wow i hope you will publish your solutions sounds very interesting   a lot of i mean a lot of feature engineering :   xgb 0.285  nn 0.242    lgb 0.280   how many layers on your nn? what optimizer did you use? i had bad time with my nn always 0.242 or lower   congrats ~ looking forward to your solution   single roughly optimized 10-fold averaged lightgbm with features merged from the andy_xgb olivier s selected features cross-fold target encoding and froza_pascal one-hot encoding a couple of engineered features median&amp;mean features  public 0.28701 private 0.28329  i had some more features and stacking worked out in the last day but didn t bother updating the submissions this likely cost me the top 50   lightgbm 0.284 - 0.285 nn 0.280  xgboost 0.283-0.284   amazing single model can do so well?  hope to see your solutions    my best model was a xgb with 0.28705 on the private leaderboard,14,0.8930448772682141,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
54421025_so,"gradient-descent machine-learning will gradient descent be stuck in non-minima point? how can we prove its correctness for stuck example let our cost function be jx,y = x * y and we are currently at point 0,0  then the gradient vector will be 0,0 that means we will not move to any other point with the gradient descent algorithm  for the later question let s consider another example the derivative by x of function fx,y let s call it fxx,y is negative and the derivative by y of function fx,y let s call it fyx,y is also negative then what we will do with gradient descent is moving along the vector alpha * fxx,y fyx,y how can we guaranteed that fx + alpha * fxx,y,y + alpha * fyx,y &lt fx,y for any sufficiently small alpha? there is  no guarantee  for gradient descent algorithms to find the global minimum or even a local minimum yes the algorithm would be stuck at   as you described however you will most likely never be  exactly  at  .also there are a lot of techniques that prevent this from happening",3,0.8926455785282372,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
38376529_so,bigdata hadoop hortonworks-data-platform hortonworks-sandbox virtual-machine error in reducing ram size in hortonworks hadoop i have to reduce ram size of virtual box from 4 gb to 1 gb .i had tried for reducing it but it is unchangable so please suggest ways to do it in right manner  i am attaching screenshot the same error had occured when i had tried for hadoop  now you can use these things .configuring yarnin a hadoop cluster it’s vital to balance the usage of ram cpu and disk so that processing is not constrained by any one of these cluster resources as a general recommendation we’ve found that allowing for 1-2 containers per disk and per core gives the best balance for cluster utilization so with our example cluster node with 12 disks and 12 cores we will allow for 20 maximum containers to be allocated to each node.each machine in our cluster has 48 gb of ram some of this ram should be reserved for operating system usage on each node we’ll assign 40 gb ram for yarn to use and keep 8 gb for the operating system the following property sets the maximum memory yarn can utilize on the node:in yarn-site.xml   the next step is to provide yarn guidance on how to break up the total resources available into containers you do this by specifying the minimum unit of ram to allocate for a container we want to allow for a maximum of 20 containers and thus need 40 gb total ram / 20 # of containers = 2 gb minimum per container:in yarn-site.xml   yarn will allocate containers with ram amounts greater than the yarn.scheduler.minimum-allocation-mb.for more information you can visit  hortonworks.com/blog/how-to-plan-and-configure-yarn-in-hdp-2-0,15,0.8925326944943442,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
37711695_so,caffe conv-neural-network deep-learning mnist neural-network how do i locate/specify the size of pooling layers in caffe my team has been going through caffe s mnist example and has been able to locate/specify the number of neurons/filters in some of the neural network s layers like the convolution layer which is referred to by a parameter called num_output.however the pooling layers don t seem to specify the number of outputs they have/we can adjust.is there any way to locate this information so that i can be able to know how many neurons exist in each layer of the mnist example neural network?  in addition the 1st convolution layer has num_output = 20 and the 2nd convolution layer has num_output = 50 how is this jump in layer depth made? i would assume it s because of the pooling layers between convolution layers 1 and 2 but again i do not understand how many filters the pooling layers have you have to understand that pooling layer is a special kind of layer which main purpose is to decrease a dimensionality of output from convolutional layer   the output of pooling layers is a function of its parameters - kernel size pad and stride as well as size of the output from a convolutional layer with width   and height   of kernel pads   and strides   it produces an output from a convolutional layer of a size   which has              you can read a detailed explaination of parameters  here  and details of pooling operation  here,11,0.8925070055867196,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
46966_kg,"how much does your  score on the lightgbm  or xgboost and what are your parameters?      my best score with xgboost is 0.484 on public lb and the best attempt with lightgbm scores at  0.485 you can see some other scores in those algorithms at  https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion/46179    thanks  for your reply,my best score with lightgbm is 0.481 on lb but xgboost is 0.484 and we are merge the  two model  is only 0.477 should i get more model  go to merge or some other approach?  sorry for my english。   sure you can try to add more models into your ensemble   thanks for your advices ， i  need try",14,0.8922146692792758,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
20921636_so,feed-forward matlab neural-network the number of outputs in feed forward ann the number of outputs number of neurons in output layer in feed forward neural network can be more than 2 such as 3 neural network can have  arbitrary  number of output neurons 2 3 or even 2131,11,0.8910970087614569,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
120750_kg,i have a dataset which is  imbalanced and it is a multi text classification problem and i have to predict 300 labels how can i predict    for imbalance data following approach can be used1 smote2 class weight3 one-class classification  moreover  for multi label classification1 chain classification2 onevsrest  hope this helps,9,0.891019852658516,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
56004530_so,"caffe macos mac install caffe error    ld library not found for -lleveldb   clang error linker command failed mac install caffe,there is a error      ld -o .build_release/lib/libcaffe.so.1.0.0  ld library not found for -lleveldb  clang error linker command failed with exit code 1 use -v to see invocation  make *** [.build_release/lib/libcaffe.so.1.0.0] error 1      ar -o .build_release/lib/libcaffe.a  /library/developer/commandlinetools/usr/bin/ranlib file .build_release/lib/libcaffe.acudnn_pooling_layer.o has no symbols  /library/developer/commandlinetools/usr/bin/ranlib file .build_release/lib/libcaffe.acudnn_lcn_layer.o has no symbols  /library/developer/commandlinetools/usr/bin/ranlib file .build_release/lib/libcaffe.acudnn_conv_layer.o has no symbols  /library/developer/commandlinetools/usr/bin/ranlib file .build_release/lib/libcaffe.acudnn_tanh_layer.o has no symbols  /library/developer/commandlinetools/usr/bin/ranlib file .build_release/lib/libcaffe.acudnn_deconv_layer.o has no symbols  /library/developer/commandlinetools/usr/bin/ranlib file .build_release/lib/libcaffe.acudnn_softmax_layer.o has no symbols  /library/developer/commandlinetools/usr/bin/ranlib file .build_release/lib/libcaffe.acudnn_relu_layer.o has no symbols  /library/developer/commandlinetools/usr/bin/ranlib file .build_release/lib/libcaffe.acudnn_lrn_layer.o has no symbols  /library/developer/commandlinetools/usr/bin/ranlib file .build_release/lib/libcaffe.acudnn_sigmoid_layer.o has no symbols  /library/developer/commandlinetools/usr/bin/ranlib file .build_release/lib/libcaffe.aparallel.o has no symbols  /library/developer/commandlinetools/usr/bin/ranlib file .build_release/lib/libcaffe.acudnn.o has no symbols  ld -o .build_release/lib/libcaffe.so.1.0.0  ld library not found for -lleveldb  clang error linker command failed with exit code 1 use -v to see invocation  make *** [.build_release/lib/libcaffe.so.1.0.0] error 1 ",21,0.8908996218348794,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
115092_kg,q:**where are the upcoming olympics to be held**p    this is a list of host cities of the olympic games  both summer and winter  since the modern olympics began in 1896  since then  summer games have usually -- but not always -- celebrated a four - year period known as an olympiad  there have been 28 summer olympic games held in 24 cities  and 23 winter olympic games held in 20 cities  in addition  three summer and two winter editions of the games were scheduled to take place but later cancelled due to war  berlin  summer  in 1916  tokyo / helsinki  summer  and sapporo / garmisch - partenkirchen  winter  in 1940  and london  summer  and cortina d ampezzo  italy  winter  in 1944  the 1906 summer olympics were officially sanctioned and held in athens  however  in 1949  the international olympic committee  ioc   decided to unrecognize the 1906 games  four cities have been chosen by the ioc to host upcoming olympic games  tokyo for the 2020 summer olympics  beijing for the 2022 winter olympics  paris for the 2024 summer olympics  and los angeles for the 2028 summ   a [ tokyo for the 2020 summer olympics   beijing for the 2022 winter olympics   paris for the 2024 summer olympics   los angeles for the 2028 summer olympics ,8,0.8904250984713072,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
65308_kg,what to do if you can t view the kernel that someone else sent you?   if you want to view someone else s private kernel then you will need to ask them to add you as a collaborator  you can add collaborators to kernels that you have authored by clicking on the options tab within the kernel viewer or by clicking on the sharing button within the kernel editor  alternatively the kernel author can make the kernel public by clicking on the make public button  did it work?  hopefully that helps,4,0.8903767674050496,"0.040*""kaggle"" + 0.040*""kernel"" + 0.038*""https"" + 0.036*""dataset"" + 0.025*""file"" + 0.021*""notebook"" + 0.020*""www"" + 0.017*""download"" + 0.011*""link"" + 0.010*""github"""
22009871_so,classification libsvm r svm how to perform multi-class classification using  svm  of e1071 package in r i want to perform multi-class classification using the   function of   package but from what i came to know from the documentation of   it can only perform binary classification the vignettes document tells this for multi-class classification  to allow for multi-class classification   uses the one-against-one technique by fitting all binary subclassifiers and finding the correct class by a voting mechanism  what i still don t understand is if we can perform the multi-class classification with   of   in r? if yes please explain how we can do it over   dataset r document says that for multiclass-classification with k levels k>2 libsvm uses the ‘one-against-one’-approach in which kk-1/2 binary classifiers are trained the appropriate class is found by a voting scheme  the iris dataset contains three class labels iris setosa iris virginica and iris versicolor to employ a balanced one-against-one classification strategy with svm you could train three binary classifiers  the first classifier s training set only contains the iris setosa and iris virginica instances the second classifier s training set only contains the iris setosa and the iris versicolor instances the third classifier s training set--i guess by now you ll know already--contains only the iris virginica and the iris versicolor instances  to classify an unknown instance you apply all three classifiers a simple voting strategy could then select the most frequently assigned class label a more sophisticated may also consider the svm confidence scores for each assigned class label  edit this principle works out of the box with,9,0.8903706718009058,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
121087_kg,"i tried hard to find a stable validation scheme but failed...sometimes even a significant improvement 0.01 + in local cv can result in a significant drop in public lb...i made sure that all random seeds were fixed and the result can be reproduced so it s not due to the randomness..  just wondering what and how is your validation scheme? is it consistent with lb?   some said the private set is always changing.....if you submit the same kernel in different days you ll get different scores....i am not sure about that as i haven t test it but if it s true,it could be a reason why your lb score is not stable    i managed to improve my local cv from 0.52 to 0.59 but lb dropped from 0.44 to -0.009 :d   the public leaderboard score is always calculated with the same 1000 installation ids: https://www.kaggle.com/c/data-science-bowl-2019/discussion/120840#latest-692132    same story here.i had a submit where average cv of 5 folds was .541 and lb was the same.with adding new features cv improved to .565 but lb dropped to .51  the cv variance between folds is also huge - typically over 0.03 and in some settings even ~0.1 between best and worst fold   i just split by installation_id but it doesn t work well spending a lot of time to improve validation score may be useless",14,0.8903341107235632,"0.041*""score"" + 0.032*""lb"" + 0.031*""model"" + 0.021*""cv"" + 0.018*""good"" + 0.016*""feature"" + 0.015*""public"" + 0.013*""competition"" + 0.012*""share"" + 0.012*""fold"""
29097353_so,computer-vision opencv mirroring a haar cascade in opencv i have a haar cascade for an open hand which detects right hands easily but doesn t always work on left hands is there a way to mirror the cascade in opencv? this way i could detect both hands more robustly i guess  i don t like mirroring the image since i would have to do it very often i m not sure it is possible but why don t you mirror the image instead of the classifier i.e    ,20,0.8902040334881616,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
56121939_so,amazon-web-services azure bigdata google-cloud-platform hadoop a single computation engine to connect to cloud and on-prem supporting acl i m trying to find a big data solution as a computation engine like sql engine or machine learning to support simultaneous connections to aws gcp and azure storages and their managed sql services as well as on-prem clusters like hadoop which supports data security fine grained acl lineage graph and data governance  having known that cloud services don t support connections to other clouds i know there is a hadoop solution to address this problem using hive and ranger but hive has performance drawbacks especially compared to spark and presto  any idea ,15,0.8893104049806557,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
61681_kg,in  trackml-participant-document-particle-v1.0.pdf  it is stated     a small fraction of the particles come from short-lived unstable heavy  particles flying a few millimeter   does a short-lived particle leave a track? will we find a short track splitting at the end to a few tracks?  i did found few tracks starting far from the origin and having the same starting point   answering to my self  yes they do .look at particles 671044041076379649 671044041076383746 671044041059598336 in event 00001000.seems like particle 671044041059598336 leave a very short trace 2 hits and then splits to particles  671044041076379649 671044041076383746 which originate adjacent to the place  671044041059598336 was last seen   there are two different things  mentioned here are particles traveling and decaying on their own if they decay after a few millimeters they have not crossed any detector so the particle is unseen only its children  but there are also particles interacting with the detector itself it is destroyed and there are children particles emitted the interaction can take place in the middle of the detector so there is a chance one can see the original particle   thanks this might be a hint on how to find particles starting far from the origin,10,0.8884418575807168,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
116747_kg,"학습 데이터 준비    함수 은 opencv를 이용하여 경로 에 저장된 이미지를 불러와 1d vector로 변환하는 함수이다  를 이용하여 경로  에 저장된 이미지를 열고 rgb 3차원으로 저장된 이미지를 흑백 1차원으로 변환한다  를 이용하여 1024x1인 1d vector로 변환한다.     os.listdir를 이용하여 이미지가 저장되어 있는 폴더의 하위 디렉토리를 검색하여 이미지 파일의 이름을 저장한다.plt.subplots를 이용하여 데이터의 이미지를 시각화하고 데이터의 라벨을 그림의 라벨로 지정한다.파일명은 dog.560.jpg와 같이 저장되어 있으므로 split  를 이용하여 ‘.’을 기준으로 분리하여 라벨을 얻어낸다 얻어낸 라벨이 ‘cat’이면 0 ‘dog’이면 1으로 라벨링한다.이미지 데이터는 함수 를 이용하여 1d vector로 변환한다    ```dataset_train = ../input/2019-fall-pr-project/train/train/  y=[]x=[]data=os.listdirdataset_trainfig,ax=plt.subplots3,3for i,axi in enumerateax.flat:    img= cv2.imreaddataset_train+data[i]    axi.imshowcv2.cvtcolorimg cv2.color_bgr2rgb    axi.setxticks=[] yticks=[],xlabel=data[i].split  [0]  for i in range10000:    y.append0 if data[i].split  [0]== cat  else 1    image=resize32dataset_train+data[i]    x.appendimage  x=np.arrayx```* train set과 validation set은 0.75  0.25로 나누어 학습을 진행하였다     kneighborsclassifier과 gridsearchcv를 이용한 학습기반 모델 설계   kneighborsclassifier를 이용하여 모델을 설계하였다  는 결과 예측시 몇개의 이웃 데이터를 가지고 투표할 것인가에 대한 파라미터이다 gridsearchcv를 이용하여 가장 정확도가 높은   파라미터를 구하고  를 통해 모델을 저장한다.```from sklearn.model_selection import gridsearchcv   knn = kneighborsclassifierparam_grid = { n_neighbors  np.arange1 10}grid = gridsearchcvknn param_grid cv=5grid.fitx_train,y_trainmodel=grid.best_estimator_yfit=model.predictx_val```   테스트 데이터 가공   테스트 데이터가 저장된 폴더의 하위 파일을  에 저장하고 이를 함수 를 이용해 1d vector로 변환해준다.```dataset_test = ../input/2019-fall-pr-project/test1/test1/   x=[]files=os.listdirdataset_testfor i in range5000:    image=resize32dataset_test+files[i]    x.appendimagetest_x=np.arrayx```  학습한 모델을 이용하여 결과 예측   학습된 모델을 이용하여 테스트 데이터를 라벨링한다.    결과 파일 저장   캐글 제출 형식을 맞추기 위해 0번째 행의 index 이름을  로 바꾸고 데이터는  label `로 바꿔준다 마지막으로 data frame을 csv파일로 변환하여 저장한다.```import pandas as pdresult=np.append[ label ],resultdf = pd.dataframeresult,columns=[   ]df=df.renameindex={0:id}   df.to_csv results.csv ,index=true header=false``",19,0.8880733546184566,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
56403292_so,binning feature-engineering machine-learning what to do after binning numerical feature i want to know what to do after i did the binning for example one of the feature is age so my data is [11 12 35 26]   then i apply binning with size of 10  bin      name  [0 10 --> 1  [10 20 --> 2  [20 30 -->3  [30 40 --> 4  then my data becomes [2 2 4 3] now assume i want to put this data to a linear regression mode should i treat the [2 2 4 3] as numerical feature? or should i treat them as categorical feature like do one-hot encoding first and then feed it to the model if you are building a linear model then one hot encoding of those bins might be a better option so that if there is any linear relationship with the target the ohe will preserve it  if you are building tree based models like random forests then you could use the [2 2 4 3] as numerical feature because these models are non-linear  if building a regression model and not wanting to expand the feature space with ohe you could treat the bins as a categorical variable and encode that variable using mean / target encoding or encoding with digits by following the target mean per bin  more details about the last 2 procedures in  this article   disclaimer i wrote the article,2,0.8880067955281103,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
120414_kg,the igarapé institute released today through the eva evidence on violence and alternatives for women and girls platform a survey that shows that 1.23 million women reported having suffered some kind of violence in brazil since 2010  according to the survey black women are the biggest victims of all types of violence they account for 57% for sexual violence and 51% for physical violence while violence against white women increased by 297% between 2010 and 2017 against black women the growth was 409% the research was based on the eva platform which according to the institute allows the online crossing of a large volume of data that gathers information related to physical patrimonial psychological moral and sexual violence  https://www.uol.com.br/universa/noticias/redacao/2019/11/25/mais-de-1-milhao-de-brasileiras-foram-vitimas-de-violencia-em-9-anos.htm,8,0.8877678406215366,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
12535536_so,c++ image-segmentation object-recognition opencv extracting an object from a low contrast background i need to extract an object from an image where the background is almost flat..  consider for example a book over a big white desktop. i need to get the coordinates of the 4 corners of the book to extract a roi  which technique using opencv would you suggest?  i was thinking to use k means but i can t know the color of the background a priori also the colors inside the object can be vary if your background is really low contrast why not try a flood fill from the image borders then you can obtain bounding box or bounding rect afterwards  another option is to apply hough transform and take intersection of most outer lines as corners this is if your object is rectangular,20,0.8875088753356231,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
27955604_so,neural-network pybrain python cascade-forward neural network i understand that we can create a  feed forward neural network  in pybrain     however can we also create a  cascade forward neural network  in pybrain if i understand correctly you want to connect your input layer to both hidden layer and directly to the output layer  what if you simply create an additional fullconnection from input layer to output layer?    this seems to be working,11,0.8874198802868434,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
142925_kg,can we predict stress levels with other lifestyle attributes?   yes it should be possible to predict stress levels with lifestyle attributes stress can be caused by factors such as individual e.g physical health mental health financial aspects etc.  interpersonal conflict with family friends coworkers etc. or societal e.g crime pandemic recession etc. situations each of those factors have known attributes e.g exercise weight blood pressure etc for health crime rate unemployment rate for societal etc the correlation between those factors and stress levels should be a strong indicator of the predictive power of those factors,8,0.8870733395241258,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
382_kg,"hi  daysinhospital do not add up example     memberid =&nbsp;929358906     claim_count = 24     sumlengthofstay = 18     daysinhospital = 15  another issue what if somebody has 5 claims each 1-2 weeks what is the predicted length of stay? 5 weeks? 10 weeks? 4-8 weeks? 8-12 weeks?  thanks  hi bacg,1 daysinhospital refers to y2 the second year while the claims refer to y1 the first year.2 not everything that has a length of stay counts as a hospitalization in fact you don t have enough detail in the claims table to calculate daysinhospital the detail has been suppressed for privacy reasons.anthony",8,0.8866588866234816,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
42685880_so,color-depth infrared opencv realsense coordinate mapping from left or right ir image to depth - r200 intelrealsense the community has already helped me to guide me in this project  i am working with the r200 camera visual studio 2015 c ++ windows 10 and opencv 3.1  i currently do the image preprocessing separately in the left and right infrared cameras to identify objects i need the coordinates x y z of the object s geometric center so i have to do a coordinate mapping but the sdk only allow to do it between depth and rgb   does anyone know how to perform the mapping between left or right ir and depth? or in its default ir left or right rgb for me to do the mapping in depth?  thank you very much at the beginning i needed to find out how to map a specific point detected on one of the infrared cameras to the depth image so my final solution was to subtract the sector of interest detected in the ir left camera which is the nearest to the color camera from the rgb image and from the result doing the mapping to depth  the gap exists but is not too much   https://i.stack.imgur.com/hjcjd.png,20,0.88659062307665,"0.132*""image"" + 0.019*""opencv"" + 0.014*""pixel"" + 0.013*""object"" + 0.012*""detect"" + 0.010*""detection"" + 0.010*""find"" + 0.010*""face"" + 0.009*""video"" + 0.008*""feature"""
41779707_so,gradient-descent machine-learning gradient descent - step value let       in the course by andrew he said that alpha is the learning rate if the derivative is positive we subtract   and if negative we add it why do we need to subtract this   instead of  ?  what is the need of the multiplication there? thanks we need to decrease the value of k - the step value while we get to the minimum as we know when we reach the minimum the derivative also gets to zero so we multiply alpha and the derivative to generate a stepping value that tends to zero while we reach the minimum,3,0.8864205326355468,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
38853370_so,gradient-descent logistic-regression machine-learning matlab octave matlab regularized logistic regression - how to compute gradient i am currently taking machine learning on the coursera platform and i am trying to implement logistic regression  to implement logistic regression i am using gradient descent to minimize the cost function and i am to write a function called   that returns both the cost and the gradient of each parameter evaluated at the current set of parameters    the problem is better described below         my cost function is working but the gradient function is not  please note that i would prefer to implement this using looping rather than element-by-element operations  i am computing   in matlab   separately as it is not being regularized i.e we do not use the first term with     what am i doing wrong the way you are applying regularization is incorrect  you add regularization  after  you sum over all training examples but instead you are adding regularization  after each example   if you left your code as it was before the correction you are inadvertently making the gradient step larger and will eventually overshoot the solution  this overshooting will accumulate and will inevitably give you a gradient vector of   or   for all components except for the bias term    simply put place your   statement after the second   loop terminates,3,0.8855088679920928,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
59842_kg,"the dataset its nyc data but in cities we can see other than new york too are those covered under nyc or those must be excluded?      good question maybe we are talking about the state new york?   data[city].unique yields the following cities   [ new york   roosevelt island   bronx   brooklyn   elmhurst ,        woodside   corona   middle village   maspeth   ridgewood ,        glendale   long island city   flushing   college point ,        whitestone   bayside   queens village   little neck ,        douglaston   floral park   bellerose   jamaica   arverne ,        far rockaway   south ozone park   broad channel ,        richmond hill   woodhaven   south richmond hill   ozone park ,        rockaway park   howard beach   rockaway beach   kew gardens ,        forest hills   rego park   springfield gardens   hollis ,        saint albans   rosedale   cambria heights   jackson heights ,        astoria   east elmhurst   staten island ] dtype=object  i ve been in nyc for about a month in my life and based on what i ve seen there these sound like neighboorhoods of nyc my guess would be that new york in this list is actually what everybody refers to as manhattan since manhattan doesn t appear on the list.in any case i would definitely not exclude the bronx or brooklyn from the analysis ;   yeah but it is still more than the 5 boroughs of new york which i think should make up the entire city just did a quick search on south ozone park and that s actually in queens it now seems as if 3 boroughs are in there as a whole and queens and manhattan could be broken down further   it s a misleading field name if you re not familiar with the geography of nyc manhattan maps to new york and roosevelt island the bronx brooklyn and staten island have a single city each and the rest is queens zip codes are going to be much more useful in terms of grouping things to a more limited area i think the city open data website offers a variety of shapefiles that you can use to map latitude/longitude onto different types of geographies   all the entries in the  city  column are neighborhoods in the borough of queens  except  the following brooklyn,bronx,new york,staten island roosevelt island  roosevelt island is actually part of new york which is actually the borough of manhattan  nyc is comprised of 5 boroughs manhattan queens brooklyn bronx staten island",8,0.8854919085304298,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
28773153_so,r regression statistics how to do regression model selection if dummy variables are involved i am trying to do a logistic regression analysis in r with two continuous explanatory variables and six other explanatory categorical variables and find a regression model to do predictions when i do step-wise model selections there are always some levels of certain categorical variables identified as insignificant i am just wondering how should i deal with this situation should i simply drop these levels or i should force the program to keep all levels of the categorical variables and try to drop the relatively insignificant variables?  thanks a lot ,2,0.8849393861212183,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
46382362_so,"python random-forest random forest-the number of classifier i have a question about the randomforest classifier.i wonder if the number of decision trees is equal to the number of the classifier?if not,what does the classifier really mean then one   object is a single classifier within that classifier you have a number of decision trees referred to as estimators you can find those in the   attribute of the   you re being asked to train 10 different   each one with a different number of decision trees for example   that code would create but not train a list with three classifiers containing different numbers of estimators decision trees specifically it would create classifiers with 8 16 and 32 decision trees",9,0.8848374733729786,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
54790775_so,machine-learning python scikit-learn svm svc classifier support vector classes in python sklearn how can i find out which support vectors belong to which class in  sklearn svc ?   which vector belongs to which decision boundary you can use the     attribute the   attribute provides the index of the training data for each of the support vectors in   you can retrieve the classes for each support vector as follows given your example   a more complete example,9,0.8847347116448345,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
26656640_so,gradient-descent machine-learning octave vectorization octave code for gradient descent using vectorization not updating cost function correctly i have implemented following code for gradient descent using vectorization but it seems the cost function is not decrementing correctly.instead the cost function is increasing with each iteration  assuming theta to be an n+1 vector y to be a m vector and x to be design matrix m*n+1   the compute cost function is you can vectorise it even further    you can vectorize it better as follows   the computecost function can be written as,3,0.8844871176578093,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
13649449_so,machine-learning neural-network in 3 layer mlp why should the input to hidden weights be random for example for 3-1-1 layer if the weights are initialized equally the mlp might not learn well but why does this happen it looks like you have a typo in your question title i m guessing that you mean why should the  weights  of hidden layer be random  for the example network you indicate 3-1-1 it won t matter because you only have a single unit in the hidden layer however if you had multiple units in the hidden layer of a fully connected network e.g 3-2-1 you should randomize the weights because otherwise all of the weights to the hidden layer will be updated  identically   that is not what you want because each hidden layer unit would be producing the same hyperplane which is no different than just having a single unit in that layer  if you only have one neuron in the hidden layer it doesn t matter but imagine a network with two neurons in the hidden layer if they have the same weights for their input than both neurons would always have the exact same activation there is no additional information by having a second neuron and in the backpropagation step those weights would change by an equal amount hence in every iteration those hidden neurons have the same activation,11,0.8840658384275251,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
24371255_so,arm c++ opencv static-libraries opencv static libraries linker error for arm hi guys i have a problem with the static libraires linking i am doing a c++ aplication in ubuntu 12.0.4 and i have to create an execute of this .cpp file for an arm this file contain opencv libraries  so the first what i did was download the opencv source from the git repository  git clone  https://github.com/itseez/opencv.git   once that finish without problem i create a new directory and i executed the cmake  cmake -dsoftfp=on  -dbuild_shared_libs=0 -dcmake_toolchain_file=../opencv/platforms/linux/arm-gnueabi.toolchain.cmake ../opencv  then i execute make and start to build the static opencv libraries for arm everything finish ok and i can see the static libraries just created  so i try to compile like this  arm-linux-g++ -static -o camera  ipcampthread.cpp -i/usr/local/include -l/home/jesus/opencv/build/lib -lopencv_core -lopencv_imgproc -lopencv_highgui  and then appear this error   i was looking for something bu t i cannot get anything someone could help??thank you so mucheven i was investigate and i find that for to be sure that all of dependencies are included i should compile with the pkgconfig like this   and it creates an executable but when i make file on the executable this is the result:    example elf 32-bit lsb executable arm version 1 sysv dynamically linked  uses      shared libs for gnu/linux 2.6.26 not strippedso is an arm file but is dynamically linked then it does not work in my arm i do not undestand why make a dynamically linked when in my opencv.pc file there are this      name opencv      description open source computer vision library      version 2.4.9      libs  ${exec_prefix}/lib/libopencv_contrib.a ${exec_prefix}/lib/libopencv_stitching.a  ${exec_prefix}/lib/libopencv_nonfree.a  ${exec_prefix}/lib/libopencv_superres.a  ${exec_prefix}/lib/libopencv_ocl.a ${exec_prefix}/lib/libopencv_ts.a  ${exec_prefix}/lib/libopencv_videostab.a  ${exec_prefix}/lib/libopencv_gpu.a  ${exec_prefix}/lib/libopencv_photo.a  ${exec_prefix}/lib/libopencv_objdetect.a  ${exec_prefix}/lib/libopencv_legacy.a  ${exec_prefix}/lib/libopencv_video.a ${exec_prefix}/lib/libopencv_ml.a  ${exec_prefix}/lib/libopencv_calib3d.a  ${exec_prefix}/lib/libopencv_features2d.a  ${exec_prefix}/lib/libopencv_highgui.a  ${exec_prefix}/share/opencv/3rdparty/lib/libilmimf.a  ${exec_prefix}/share/opencv/3rdparty/lib/liblibjasper.a  ${exec_prefix}/share/opencv/3rdparty/lib/liblibtiff.a  ${exec_prefix}/share/opencv/3rdparty/lib/liblibpng.a  ${exec_prefix}/share/opencv/3rdparty/lib/liblibjpeg.a  ${exec_prefix}/lib/libopencv_imgproc.a  ${exec_prefix}/lib/libopencv_flann.a  ${exec_prefix}/lib/libopencv_core.a  ${exec_prefix}/share/opencv/3rdparty/lib/libzlib.a -lrt -lpthread -lm  -ldl -lstdc++      cflags -i${includedir_old} -i${includedir_new}   all the libraries which use the open.pc are static so i do not know why compile and build a dinamic executable  someone? hi guys thanks idinev i was looking for how add the libraries and how to make sure that every libraries which i need are linked propertly  so i try with pkgconfig how i said above but i could not get the static executable and finally that was for a sintaxis error i use this  arm-linux-g++ -static -o example ipcamera.cpp    and it works it created a executable and when i execute file executable the output is  example elf 32-bit lsb executable arm version 1 sysv statically linked for gnu/linux 2.6.26 not stripped  statically linked!  a classic case of missing a few -lsomelib statements to the linker.pthread and gzip seem to be missing among others to manually find which libs you need grep your lib folder for the symbol-name,21,0.883787181097174,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
1413_kg,the data page says that trade size is &quot;the dollar amount of the trade&quot; in the first row of the training file we have trade price = 128.596 trade size = 120000 and current coupon = 5.95 how many bonds have the customer bought? for what notional amount? are coupons paid on a monthly basis a quarterly basis a half-yearly basis or a yearly basis?   trade_size refers to the notional amount of the trade &nbsp;notional amount is what the bond is issued at what the coupons are paid in reference to and what is paid out at maturity &nbsp;for instance a bond will be issued at $100 with a coupon of 5.5% &nbsp;this bond will pay $5.50 a year whether the price rises to $110 or falls to $90 when the bond matures the holder will receive $100 &nbsp;whenever this bond is traded it s trade_size is in reference to this $100 notional amount  the payment types of the bonds varies monthy quarterly yearly etc but the coupon amounts we have provided are standardized to a yearly amount  -dan,8,0.8835851414015847,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
58175571_so,"android tensorflow unable to deploy ssd mobilenet v1 fpn on android i am using default ssd mobilenet v1 fpn model for object detection it s running perfectly fine on my laptop but when i try to deploy the tflite file on android it gives me the error     rejecting re-init on previously-failed class java.lang.class java.lang.noclassdeffounderror failed resolution of landroid/view/view$onunhandledkeyeventlistener;          at void androidx.core.view.viewcompat.setonapplywindowinsetslistenerandroid.view.view androidx.core.view.onapplywindowinsetslistener viewcompat.java:2203          at android.view.viewgroup androidx.appcompat.app.appcompatdelegateimpl.createsubdecor appcompatdelegateimpl.java:637          at void androidx.appcompat.app.appcompatdelegateimpl.ensuresubdecor appcompatdelegateimpl.java:518          at void androidx.appcompat.app.appcompatdelegateimpl.setcontentviewint appcompatdelegateimpl.java:466          at void androidx.appcompat.app.appcompatactivity.setcontentviewint appcompatactivity.java:140          at void org.tensorflow.lite.examples.detection.cameraactivity.oncreateandroid.os.bundle cameraactivity.java:95          at void android.app.activity.performcreateandroid.os.bundle activity.java:6984          at void android.app.instrumentation.callactivityoncreateandroid.app.activity android.os.bundle instrumentation.java:1235          at android.app.activity android.app.activitythread.performlaunchactivityandroid.app.activitythread$activityclientrecord android.content.intent activitythread.java:2783          at void android.app.activitythread.handlelaunchactivityandroid.app.activitythread$activityclientrecord android.content.intent java.lang.string activitythread.java:2909          at void android.app.activitythread.-wrap11android.app.activitythread android.app.activitythread$activityclientrecord android.content.intent java.lang.string activitythread.java:-1          at void android.app.activitythread$h.handlemessageandroid.os.message activitythread.java:1606          at void android.os.handler.dispatchmessageandroid.os.message handler.java:105          at void android.os.looper.loop looper.java:164          at void android.app.activitythread.mainjava.lang.string[] activitythread.java:6592          at java.lang.object java.lang.reflect.method.invokejava.lang.object java.lang.object[] method.java:-2          at void com.android.internal.os.zygote$methodandargscaller.run zygote.java:240          at void com.android.internal.os.zygoteinit.mainjava.lang.string[] zygoteinit.java:769      caused by java.lang.classnotfoundexception didn t find class android.view.view$onunhandledkeyeventlistener on path dexpathlist[[zip file /data/app/org.tensorflow.lite.examples.detection-4snpfse9sc16tbhi7elm9g==/base.apk],nativelibrarydirectories=[/data/app/org.tensorflow.lite.examples.detection-4snpfse9sc16tbhi7elm9g==/lib/arm /system/fake-libs /data/app/org.tensorflow.lite.examples.detection-4snpfse9sc16tbhi7elm9g==/base.apk!/lib/armeabi-v7a /system/lib /system/vendor/lib]]          at java.lang.class dalvik.system.basedexclassloader.findclassjava.lang.string basedexclassloader.java:93          at java.lang.class java.lang.classloader.loadclassjava.lang.string boolean classloader.java:379          at java.lang.class java.lang.classloader.loadclassjava.lang.string classloader.java:312          at void androidx.core.view.viewcompat.setonapplywindowinsetslistenerandroid.view.view androidx.core.view.onapplywindowinsetslistener viewcompat.java:2203          at android.view.viewgroup androidx.appcompat.app.appcompatdelegateimpl.createsubdecor appcompatdelegateimpl.java:637          at void androidx.appcompat.app.appcompatdelegateimpl.ensuresubdecor appcompatdelegateimpl.java:518          at void androidx.appcompat.app.appcompatdelegateimpl.setcontentviewint appcompatdelegateimpl.java:466          at void androidx.appcompat.app.appcompatactivity.setcontentviewint appcompatactivity.java:140          at void org.tensorflow.lite.examples.detection.cameraactivity.oncreateandroid.os.bundle cameraactivity.java:95          at void android.app.activity.performcreateandroid.os.bundle activity.java:6984          at void android.app.instrumentation.callactivityoncreateandroid.app.activity android.os.bundle instrumentation.java:1235          at android.app.activity android.app.activitythread.performlaunchactivityandroid.app.activitythread$activityclientrecord android.content.intent activitythread.java:2783          at void android.app.activitythread.handlelaunchactivityandroid.app.activitythread$activityclientrecord android.content.intent java.lang.string activitythread.java:2909          at void android.app.activitythread.-wrap11android.app.activitythread android.app.activitythread$activityclientrecord android.content.intent java.lang.string activitythread.java:-1          at void android.app.activitythread$h.handlemessageandroid.os.message activitythread.java:1606          at void android.os.handler.dispatchmessageandroid.os.message handler.java:105          at void android.os.looper.loop looper.java:164          at void android.app.activitythread.mainjava.lang.string[] activitythread.java:6592          at java.lang.object java.lang.reflect.method.invokejava.lang.object java.lang.object[] method.java:-2          at void com.android.internal.os.zygote$methodandargscaller.run zygote.java:240          at void com.android.internal.os.zygoteinit.mainjava.lang.string[] zygoteinit.java:769   a/libc fatal signal 6 sigabrt code -6 in tid 25346 inference  but the app runs perfectly fine when i use ssd mobilenet v1  could anyone guide me what to do? any help would be greatful there are some issues with deployment of ssd mobilenet v1 fpn on android  please refer to open issue in tf api  https://github.com/tensorflow/models/issues/5298",21,0.8833982102973005,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
101041_kg,hello!   tl;dr best variable selection method suggestion - continuous target variable   i have a data set with 35 independent variables and a continuous target variable  15/35 are categorical variables   i have filtered these 35 variables from a larger set of 200+ variables based on their relevance business importance % of null/missing values etc i believe that the 35 variables i have are in some way useful in explaining/predicting my target variable  i am looking at a good variable selection method to use in building my model and my first choice was stepwise selection along with including any non-significant control variables however i came a couple of articles that advice against using stepwise and noticed that several kernels that i have seen so far do not use stepwise selection method   my question is - what is the recommended way to go about with variable selection in building a model? please share your thoughts on the same!  thank you!   proper variable selection method depends a lot on the purpose of the model.if you build a model for prediction purposes then you can use pca or plsfor multiple targets and choose the high variance components for prediction.you can also go for ensemble methods where you fit multiple models and combine them for prediction  but if you go for interpretability you can use regularization methods like lasso using all the variables.another recommendation is when you have enough domain knowledge about the features use it directly for feature selection based on hypothesis testing,2,0.8830815815949733,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
50891873_so,convolutional-neural-network dataset image tensorflow how many images are needed per class to retrain cnn model such as inceptionv3 from scratch i have to retrain the inceptionv3 model from scratch on skin lesion images how many images per class should i use well the inceptionv3 has a model based on imagenet so about 1000 should do are you sure you need to train it from scratch though,13,0.8829658057693801,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
29930147_so,autosuggest lucene machine-learning solr is there a way we can use lucene to discover the relevancy of word based on search query all  i wonder if there is any way that we can use lucene to do search keyword relevancy discovering based on search history?   for example  the code can read in user search string parse it extract the keyword and find out which words have most possibility to come together when search   when i try solr i found that the lucene has a lot of text analysis feature that is why i am wondering if there is any way we can use it and combine with other machine learning libsif necessary to achieve my goal   thanks yes and no   yes  it should work simply treat every keyword as a document and then use  morelikethis  feature of lucene which constructs a lucene query on the fly based on terms within the raw query the lucenue query is then used to find other similar documents keywords in the index   suppose in your indexed keywords you have such keywords as   when you launch a query with iphone i am sure you will find the first three keywords above as most similar due to the full term match of iphone  no  the  default  similarity function in lucene never understands that iphone is relevant to apple inc thus iphone is relevant to apple store if your raw query is just apple store an ideal search result within your current keywords would be as follows ordered by relevancy from high to low   unfortunately you will get below results   the first one is great however the other two are totally unrelated to  get the  real  relevancy discovery using the  semantic   you need more work to do  topic modeling  if you happen to have a great way e.g a pre-trained  lda  model or  wordvec   to pre-process each keyword and produce a list of topic ids you can store those topic ids in a separate field with each keyword document something like below   where each keyword is also mapped to a few topic ids with weight value   at query time you should run the same topic modeling tool to generate topic ids for the raw query together with its terms for example    now you should combine the two fields keyword and topic to compute the overall similarity,12,0.8827873725917781,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
23819949_so,"bigdata hadoop java memory is the hadoop cluster configuration possible? what are minimum disk space requirements my hadoop clusters are based on virtual machine following is the configuration   1 master and 9 slaves    master   disk space 20gb  memory 16g  cpu cores 8   slave1 ~ slave9   disk space 5gb  memory 16g  cpu cores 8  i know the disk space is too slow but my data is not very largeabout 10gb so i think it s enough also my mapperno reducer is very simple the output is not larger than 5gb  when i test it using 2gb datashave uploaded hdfs it is always the following error     container  [pid=17619,containerid=container_1400594068017_0014_01_000009] is  running beyond physical memory limits current usage 1.0 gb of 1 gb  physical memory used  11.8 gb of 2.1 gb virtual memory used  killing  container   yes i need to increase the jvm but what i m wondering is  how the virtual memory computes why does it need 11.8gblarger than slaves disk space?is it the reason that my slaves  disk space too low? or is there other reason? configuration problem? thanks in advance ",15,0.88204373972062,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
119746_kg,"논문에서 나타난 spm을 구현하는 과정에서 spm kernel을 놓칠 수도 있고 이를 놓치면 성능향상에 있어서 한계가 있어서 이를 공유하고자 합니다   정확한 이론적인 내용은 저도 부족하기에 총괄조교님께서 설명해주실거라고 믿고 제가 얻은 소스의 주소와 실제구현한 결과에 대해서 말씀드리고자 합니다   histogram intersection히스토그램 유사도와 관련된 구현코드는  image-recognition 에서 확인하실 수 있습니다   이를 이용해 제가 사용한 코드는 다음과 같습니다   ```def histogramintersectionm n:    m = m.shape[0]    n = n.shape[0]    result = np.zerosm,n    for i in rangem:        for j in rangen:            temp = np.sumnp.minimumm[i] n[j]            result[i][j] = temp    return result  히스토그램 유사도를 측정하는 함수위에 링크에서 가져옴 spm 커널 적용하는부분  grammatrix = histogramintersectiontotal_train_feature total_train_feature  spm을 통해서 만든 feature의 유사도를 구해서 grammatrix를 정의  clf = svm.svckernel= precomputed   svc 진행시 precomputed를 통해서 위에서 정의한 spm 커널을 기준으로 svc 진행  clf.fitgrammatrix train_labels  svc 진행시 preconputed를 통해서 위에서 정의한 spm 커널을 기준으로 svc 진행  predictmatrix = histogramintersectiontotal_test_feature total_train_feature  test셋과 train셋에 대한 유사도를 구한 predictmatrix를 구함  svmresults = clf.predictpredictmatrix  이를통해서 최종 결과인 svmresults를 구함결과값 클래스 라벨  ```  해당 방법을 통해서   40퍼센트 후반 ~ 50퍼센트 초반에서 60퍼센트의 성능까지  끌어올릴 수 있었습니다",19,0.8819422510264391,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
52003277_so,activation conv-neural-network machine-learning why we use activation function after convolution layer in convolution neural network i m new to machine learning and one of the things that i don t understand about convolution neural networks is that why we perform activation after convolution layer cnn is one of the neural network the basic idea behind neural network is that when you have enough inputs then the neuron is triggered based on the computing of activation function the basic neural network known as multi later perceptron mlp in which you have have x - dimensional input that you pass to 1st mlp layer and the process goes on to the further layer and eventually there is one neuron at the end where in the output is computed which might be classification or regression based on the problem  in the similar way after you apply filter/kernel on the input image after that you need to apply element wise activation function like relu or sigmoid on that convolved image activation function produces an output if you have enough inputs which gets as input to other layers  because a convolution followed by a convolution is a convolution  therefore a convolutional neural network of arbitrary depth without intervening non-convolutional layers of some sort such as a relu layer is fundamentally equivalent to a convolutional neural network with only one layer  this is because composing linear transformations is linear   which is just a linear function..  why learn two when you can learn just one and it is exactly the same?  this logic applies even to locally linear functions convolutions are locally linear  thus for either convolutional nns but also vanilla nns we must do something anything non-linear in-between the linear layers  one incredibly simple non-linear function is the  relu  which is a basic bend,11,0.8818346081166539,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
46204331_so,logistic-regression python-3.x scikit-learn how to set sample weight in sklearn logistic regression i have a problem when i do the logistic regression in   python package  when the data it has a different number of samples for 1 or 0 i want to do logistic regression with concerning sample weight but i have a few data so i can t get the same number of samples for each as the  documentation  of sklearn s logisticregression says there are two options to assign weights to samples   the classifier accepts a   parameter which can be used to set the weight of all samples belonging to a certain class one can also apply   to automatically adjust the class weights based on the number of samples in each class  the   method of the classifier also accepts a   array which assigns weights to individual samples,9,0.8817965659311958,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
114456_kg,"i want to use csv data by pandas but there is a problem.it is that data header shift right three columns.therefore correct data cannot be used.i think this is probably because the last three headers are empty.please tell me how to get correct csv data by pandas   fig.1 code and incorrect output   fig.2 csv data   ```  this will allow you to specifc exactly what each header column will be but it will be a bit tedious since you have a lot of columns  csv_df = pd.read_csvfilepath names=[ sample_time   frame   nose   l_hand_cog_x   1   2   3   4   5   6   7   8   9   10   11   12   13   14   15   16   17 ..... 97 ] skiprows=1  ```let me know if this helps!   try using this  import pandas as pdcsv_df=pd,read_csvfile_path/file_name.csv  printcsv_dforcsv_df   p.s don t use header= while reading the file it will work   regardsforidur   thank you for your returns! i try it now   i use this code and fix it  import pandas as pdcsv_df = pd.read_csv /content/drive/my drive/data/data_estimated/box1analize.csv ,header=1,        names= [ frame   nose_x   nose_y   nose_score   neck_x   neck_y ,        neck_score   rshoulder_x   rshoulder_y   rshoulder_score ,        relbow_x   relbow_y   relbow_score   rwrist_x   rwrist_y ,        rwrist_score   lshoulder_x   lshoulder_y   lshoulder_score ,        lelbow_x   lelbow_y   lelbow_score   lwrist_x   lwrist_y ,        lwrist_score   rhip_x   rhip_y   rhip_score   rknee_x   rknee_y ,        rknee_score   rankle_x   rankle_y   rankle_score   lhip_x ,        lhip_y   lhip_score   lknee_x   lknee_y   lknee_score   lankle_x ,        lankle_y   lankle_score   reye_x   reye_y   reye_score   leye_x ,        leye_y   leye_score   rear_x   rear_y   rear_score   lear_x ,        lear_y   lear_score   head_cog_x   head_cog_y   head_cog_score ,        torso_cog_x   torso_cog_y   torso_cog_score   r_thigh_cog_x ,        r_thigh_cog_y   r_thigh_cog_score   l_thigh_cog_x   l_thigh_cog_y ,        l_thigh_cog_score   r_leg_cog_x   r_leg_cog_y   r_leg_cog_score ,        l_leg_cog_x   l_leg_cog_y   l_leg_cog_score   r_foot_cog_x ,        r_foot_cog_y   r_foot_cog_score   l_foot_cog_x   l_foot_cog_y ,        l_foot_cog_score   r_arm_cog_x   r_arm_cog_y   r_arm_cog_score ,        l_arm_cog_x   l_arm_cog_y   l_arm_cog_score   r_forearm_cog_x ,        r_forearm_cog_y   r_forearm_cog_score   l_forearm_cog_x ,        l_forearm_cog_y   l_forearm_cog_score   r_hand_cog_x ,        r_hand_cog_y   r_hand_cog_score   l_hand_cog_x   l_hand_cog_y ,        l_hand_cog_score  undif_1  undif_2  undif_3 ]  printcsv_df",19,0.8813762424741383,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
40121550_so,conv-neural-network deep-learning keras machine-learning training loss and validation loss in convolutional auto encoder is not decreasing much why the training loss and validation loss in convolutional auto encoder is not decreasing the training data is of dimension   and   is trained with   size image patches in   i have already tried   but did not help much i am trainig for 20 epochs what could be the other alternatives ?  the output      epoch 1/20 10496/10496 [========] - 52s - loss 0.4029 - val_loss:  0.3821      epoch 2/20 10496/10496 [========] - 52s - loss 0.3825 - val_loss:  0.3784      epoch 3/20 10496/10496 [=======] - 52s - loss 0.3802 - val_loss:  0.3772      epoch 4/20 10496/10496 [=======] - 51s - loss 0.3789 - val_loss:  0.3757      epoch 5/20 10496/10496 [=======] - 52s - loss 0.3778 - val_loss:  0.3752      epoch 6/20 10496/10496 [=======] - 51s - loss 0.3770 - val_loss:  0.3743      epoch 7/20 10496/10496 [=======] - 54s - loss 0.3763 - val_loss:  0.3744      epoch 8/20 10496/10496 [=======] - 51s - loss 0.3758 - val_loss:  0.3735      epoch 9/20 10496/10496 [=======] - 51s - loss 0.3754 - val_loss:  0.3731      epoch 10/20 10496/10496 [=======] - 51s - loss 0.3748 - val_loss:  0.3739      epoch 11/20 10496/10496 [=======] - 51s - loss 0.3745 - val_loss:  0.3729      epoch 12/20 10496/10496 [=======] - 54s - loss 0.3741 - val_loss:  0.3723      epoch 13/20 10496/10496 [=======] - 51s - loss 0.3736 - val_loss:  0.3718      epoch 14/20 10496/10496 [=======] - 52s - loss 0.3733 - val_loss:  0.3716      epoch 15/20 10496/10496 [=======] - 52s - loss 0.3731 - val_loss:  0.3717      epoch 16/20 10496/10496 [=======] - 51s - loss 0.3728 - val_loss:  0.3712      epoch 17/20 10496/10496 [=======] - 49s - loss 0.3725 - val_loss:  0.3709      epoch 18/20 10496/10496 [=======] - 36s - loss 0.3723 - val_loss:  0.3710      epoch 19/20 10496/10496 [=======] - 37s - loss 0.3721 - val_loss:  0.3708      epoch 20/20 10496/10496 ========] - 37s - loss 0.3720 - val_loss:  0.3704 your network is still learning and is not slowing down so much at epoch 20 you can try a higher learning rate and more epochs with an early stopping method if you have enough data.this approach can be applied also with regularization methods and k-fold cross validation,13,0.8812732871578907,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
44828101_so,non-linear-regression regression statistics polynomial regression with one non-linear and other linear independent variables in a hypothetical situation where i have 3 independent variables and one of those variables has a non-linear relationshipexponential with the dependent variable and the other two independent variables are linearly related to the dependent variable in such a case what would be the best approach for running a regression analysis?considering i tried transforming the one non-linear independent variable ,2,0.8806880179831781,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
53008780_so,"machine-learning q-learning reinforcement-learning q-learning convergence and local optima problem i am a newbie to reinforcement learning rl and q-learning in particular i have a set of 20 states and 9 actions my goal is to start from some random state and reach the final 20th state with shortest number of steps by performing actions i am trying to solve this problem using q-learning   states  [20,22 24 ....,40,44...,50....60] 20 states  actions  [-,+ -,0 - -......] 9 actions  rewards  tried both binary reward function as well as continuous goal biased reward shaping function  initial q-values  tried both uniform q-values as well goal biased initial q-values  optimization function          i ran this problem for 10,000-20,000 episodes and still could see that the learnt q-values are resulting in reaching some in-between state like 40 local optima most of the time but not the final state 60 all time i am using epsilon-greedy as well for exploration    any suggestions on how to solve this local optima problem? or is this always the problem with rl slow convergence and local optima?increase the number of episodes further ? also does learnt q-values underfit or overfit the given problem in q-learning ",3,0.8803478412906838,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
49428210_so,apache apache-storm apache-zookeeper bigdata java apache storm supervisor stops automatically i have used two systems to configure apache strom cluster  system1   zookeeper server  nimbus  ui   system2   zookeeper client     storm supervisor   when i start storm supervisor by   .\storm supervisor   in power shell command line it started but after few seconds it automatically stopped  is anyone faced same issue when setting storm cluster in multiple system ?  am i missing any configuration ? or any command line argument should i pass when starting storm supervisor ?  how to resolve this issue ?  following is the latest config i have used   storm.yaml nimbus config  storm.zookeeper.servers: - localhost  storm.local.dir g:\software\apache-storm\apache-storm-1.1.2\datadir  nimbus.host localhost  storm.yaml supervisor config  storm.zookeeper.servers: - 192.168.1.10  storm.local.dir f:\software\apache-storm-1.1.2\datadir  nimbus.host  192.168.1.10  supervisor.slots.ports:- 6700- 6701- 6702- 6703  zookeeper server config  ticktime=2000  initlimit=10   synclimit=5   datadir=g:\software\zookeeper\zookeeper-3.4.6\data   clientport=2181   maxclientcnxns=60   server.1=192.168.1.10:2888:3888  zookeeper client config  ticktime=2000   initlimit=10   synclimit=5   datadir=f:\software\zookeeper-3.4.6\data   clientport=2181   server.1=192.168.1.10:2181  cnxtimeout=60 you should go check your supervisor log in storm-home/logs/supervisor.log it ll likely tell you what s wrong   since you re on windows i d bet that you re not running the supervisor as administrator try doing that and see if that solves it,15,0.8801290356659047,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
140916_kg,the datasets hold information about the cases and deaths from covid-19 for multiple countries between january 22th 2020 to march 30 2020 there is a separate excel sheet for every country the following is the information that the dataset holds  the dataset is available at the following link -  dataset    the date for which the observation was made for the country/state  information regarding the state of the country where the case is reported  the country where the case is reported  cumulative confirmed cases and cumulative deaths  daily cases reported and daily deaths  latitude and longitude for the country  average temperature for that day  minimum and maximum temperature for that day  wind speed reported for that day  precipitation and fog 1 denotes the presence  population population density and median population for that country  the sex ratio for that country  %of population above 65 years of age  hospital beds and available hospital beds/1000 people  confirmed covid-19 cases/1000 people  no of males and females/1000 people suffering from a lung / copd disease  life expectancy males and females  total covid-19 tests conducted for that country  outbound | inbound | domestic travels for that country  separate csv sheets are made for the country    the datasets would surely be updated on a certain basis to fit with the current covid-19 values  special thanks to -  https://www.kaggle.com/koryto/countryinfo  for providing the much essential information for building the dataset   an informative indicator would be the total covid-19 tests conducted by the country population    @cesarboucas  i ll make sure that to update the data with the same thanks 👍    well presented dataset   thanks...,8,0.8790696082279835,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
32051951_so,knn multilabel-classification scikit-learn sklearn-knearestneighbors with multilabels i have a dataset with features and their labels   it looks like this    i want to train a kneighborsclassifier on this dataset it seems like sklearn does not take multilabels i have been trying this   it is giving me    is there a way that i can run multilabel classifier in sklearn according to sklearn  documentation  the classifiers that support multioutput-multiclass classification tasks are     decision trees random forests nearest neighbors   since you have a binary matrix for your labels you can use   to make your   handle multilabel predictions code should now look like   you can use the   with any of the sklearn models to do multilabel classification  here s an explanation   http://scikit-learn.org/stable/modules/multiclass.html#one-vs-the-rest   and here are the docs    http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.onevsrestclassifier.html,9,0.8790304880448546,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
48757573_so,imagenet slim tensorflow tensorflow slim validation accuracy is around 0 for modelsmobilenet inceptionv2 trained from scratch on imagenet i trained tensorflow slim default models like mobilenetv1 and inceptionv2 on imagenet from scratch.the loss is decreasing from ~7 to ~2 training seems to be good.but the validation accuracy using eval_image_classifier.py shows around 0.checkpoints trained from scratch is used for validation accuracy check  while i use tensorflow provided pretrained checkpoints of mobilenetv1 to check validation accuracy accuracy is about 70% as claimed in the site  i also trained darknet-19 from scratch and the validation accuracy is around 60% and i added batch normalization to vgg16 and trained on imagenet the validation accuracy is also above 50%  could anyone tell me why default models on slim like mobilenetv1 and inceptionv2 trained from scratch shows around 0 accuracy on validation ,13,0.8786706062261872,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
41103120_so,android android-assets java-native-interface opencv3.0 jni get asset filepath i am trying to add two .xml files with initialisation data to the apk of my android app in the jni c++ code i want to get the path to the files so i can open and read the files  i realy need the path because the files are opened with an opencv function that accesses the files  i already have this  java file   cpp file   now how do i extract the two paths to the files? the files are called classifications.xml and images.xml and are locaed in the /src/assets folder now how do i extract the two paths to the files?    there is no path to the files assets are files on your development machine they are not files on the filesystem of the android device instead they are entries in the apk file  your choices are    figure out how to adapt opencv to work with a java     or something else so your java code can still work with assets normally or    use java to make a copy of those files on the local filesystem e.g   so opencv can work with those copies,21,0.878429433109008,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
103844_kg,"hello,thank you for this code but can you tell why there are 103 classes in last dense layer  `model=sequentialfor layer in vgg.layers[:-1]:    model.addlayer  for layer in model.layers[:]:    layer.trainable=falsemodel.adddense103,activation= softmax model.compileloss= categorical_crossentropy ,optimizer= adam ,metrics=[ accuracy ]model.summary",13,0.8780886542618586,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
126872_kg,how do economic characteristics such as income and employment differ by neighborhood  how do housing characteristics such as occupancy and rent paid differ by neighborhood?  how do demographic characteristics such as age race and sex differ by neighborhood?  how do social characteristics such as marital status and education differ by neighborhood,8,0.8779781709649156,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
143685_kg,the use of training validation and test datasets is common but not easily understood i will try to clarify this concept!  1training dataset  the sample of data used to fit the model  2validation dataset  the sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters the evaluation becomes more biased as a skill on the validation dataset is incorporated into the model configuration  3test dataset  the sample of data used to provide an unbiased evaluation of a final model fit on the training dataset     dividing the data set into two sets is a good idea but not quite reasonable you can greatly reduce your chances of overfitting by partitioning the data set into the three subsets use the validation set to evaluate results from the training set then use the test set to double-check your evaluation after the model has passed the validation set the following figure shows this workflow     putting it all together  the overall steps are  1 divide the available data into training validation and test set 2 select an algorithm and training parameters 3 train the model using the training set 4 evaluate the model using the validation set 5 repeat steps 2 through 4 using different algorithms and training parameters6 select the best model and train it using data from the training and validation set7 assess this final model using the test set     good explanation 💯    thanks to remind me:   👍 ,1,0.8777337634592122,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
22412429_so,machine-learning matlab neural-network how to use the custom neural network function in the matlab neural network toolbox i m trying to create the neural network shown below it has 3 inputs 2 outputs and 2 hidden layers so 4 layers altogether or 3 layers of weight matrices in the first hidden layer there are 4 neurons and in the second hidden layer there are 3 there is a bias neuron going to the first and second hidden layer and the output layer     i have tried using the  create custom neural network  function in matlab but i can t get it to work how i want it to  this is how i used the function   and it gives me the neural network shown below     as you can see this isn t what i want there are only 3 weights in the first layer 1 in the second 1 in the output layer and only one output how would i fix this?  thanks!   just to clarify how i want this network to work   the user will input 3 numbers into the network  each one of the 3 inputs is multiplied by 4 different weights and then these numbers are sent to the 4 neurons in the first hidden layer  the bias node acts the same as one of the inputs but it always has a value of 1 it is multiplied by 4 different weights and then sent to the 4 neurons in the first hidden layer  each neuron in the first hidden layer sums the 4 numbers going into it and then passes this number through the sigmoid activation function  the neurons in the first hidden layer then output 4 numbers that are each multiplied by 3 different weights and sent to the 3 neurons in the second hidden layer  the bias node going to the second hidden layer works the same as the first bias node  each neurons in the second hidden layer sums up the 5 numbers going into it and passes it through the sigmoid activation function  the neurons in the second layer then output two numbers that are again multiplied by weights and go to each of the outputs   the output layer also sums all of its inputs including its bias input and then passes this through the sigmoid activation function to get the final two values after some time playing around i ve figured out how to do it the code i needed to use is   this creates the network i was looking for     i was originally mistaken about the matlab representation of neural networks the green arrows show the path of all of the numbers not just a single number,11,0.877711630730903,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
36267212_so,c++ compilation opencv adding opencv lib to custom lib errors with ipp i m bundling opencv into an sdk for people developing in c++ in linux i m linking a test executable with my built library and its giving me a huge dump of errors one of which is   what is this error referencing? should i be building without ipp? i compiled the opencv libs   and standalone i m actually getting thousands of errors which have some mention of   and this is just an example i had the same error you need to link the executable to the library     this is a 3rd party library used by opencv an you can find it in    you can also find in   all the dependencies used by opencv e.g      /usr/local/lib/pkgconfig/opencv.pc      # package information for pkg-config      prefix=/usr/local exec_prefix=${prefix} libdir=${exec_prefix}/lib  includedir_old=${prefix}/include/opencv  includedir_new=${prefix}/include      name opencv   description open source computer vision library   version 3.2.0       libs -l${exec_prefix}/lib -lopencv_shape -lopencv_stitching  -lopencv_objdetect -lopencv_superres -lopencv_videostab -lopencv_calib3d -lopencv_features2d -lopencv_highgui -lopencv_videoio -lopencv_imgcodecs -lopencv_video -lopencv_photo -lopencv_ml -lopencv_imgproc -lopencv_flann -lopencv_core      libs.private -l${exec_prefix}/share/opencv/3rdparty/lib -llibwebp  -lippicv -l/usr/lib/x86_64-linux-gnu -lpng -lz -ltiff -ljasper -ljpeg -limath -lilmimf -liex -lhalf -lilmthread -lgtk-x11-2.0 -lgdk-x11-2.0 -lpangocairo-1.0 -latk-1.0 -lcairo -lgdk_pixbuf-2.0 -lgio-2.0 -lpangoft2-1.0 -lpango-1.0 -lgobject-2.0 -lglib-2.0 -lfontconfig -lfreetype -lgthread-2.0 -ldc1394 -lavcodec-ffmpeg -lavformat-ffmpeg -lavutil-ffmpeg -lswscale-ffmpeg -lstdc++ -ldl -lm -lpthread -lrt cflags -i${includedir_old} -i${includedir_new,21,0.8773604837319972,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
93779_kg,"i have generated multiple dataframes with same columns and formats and i want to iterate over all those dataframes how can i do that in python?    if you want to iterate over the dataframes you can put them into a list and iterate over them like below it assumes df1,df2,df3 are 3 dataframes   if you want to iterate the rows of each dataframe one after another then you can probably merge them into  temporary dataframe and iterate rows as you would normally do",19,0.8772024794564778,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
42043056_so,neural-network sigmoid architecture of the neural network i was reading a paper and the authors described their network as follows   to train the corresponding deep network a fully connected network with onehidden layer is used the network has nine binary input nodes the hidden layer contains one sigmoid node and in the output layer there is one inner productfunction thus the network has 10 variables  the network is used to predict a continuous number y my problem is i do not understand the structure of the network after the sigmoid node what does the output layer do? what is the inner product used for usually the pre-activation functions per neuron are a combination of an inner product or dot product in vector-vector multiplication and one addition to introduce a bias a single neuron can be described as   where   is an additive term the neuron s bias and each   is the output of one layer and corresponds to the input of the following layer in the case of the output layer it is that   a layer might also consist of multiple neurons or - like in your example - only of single neurons  in the described case it seems like no bias is used i understand it as follows  for each input neuron   to   a single weight is used nothing fancy here since there are nine inputs this makes 9 weights resulting in something like   in order to connect the hidden layer to the output the same rule applies the output layer s input is weighted and then summed over all inputs since there is only one input only one weight is to be summed such that   keep in mind that the sigmoid function squashes its input onto an output range of 0..1 so multiplying it with a weight re-scales it to your required output range,11,0.876899049567087,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
29703182_so,c++ caffe ios xcode how to build caffe framework xcode 6.2 ios 8.3 environment i am working on build caffe framework for ios i used the caffe master source and make files to build the framework for ios   i changed the os target in cmake gui config as /applications/xcode.app/contents/developer/platforms/iphoneos.platform/developer/sdks/iphoneos.sdk  while run xcode to build project i got the below error messages/users/macpro_ios_v2/caffe_ios/src/caffe/common.cpp:1:10  glog/logging.h  file not foundboost/thread.h file not foundi included usr/local/include and opt/local/include to search paths in the build phase    while run the same xcode project for osx it works fine and generates the libs perfectly  if i change the target for iphone os i got above error  please help me to fix the above issuse please help how to configure  the make list in caffe master for iphone  i have caffe dylip lib-a for osx is it possible to link mac osx libaries in ios project cloudvision  you should install opencv2 from here before you compile the caffe-ios-sample: http://docs.opencv.org/doc/tutorials/introduction/ios_install/ios_install.html,21,0.8768428802733129,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
89565_kg,i had a quick question about the variable suicides_no - is this the number of suicides in total for a given year in a country? or does it represent suicides in each age group for a given year? just wanted to clarify before going further   is the number of suicides per country year sex and age group for example the first row is  albania 1987    male    15-24 years 21  with suicides_no=21 therefore in albania in 1987 21 men with ages between 15 and 24 committed suicide,8,0.8766522055356528,"0.029*""datum"" + 0.016*""user"" + 0.015*""day"" + 0.012*""year"" + 0.011*""data"" + 0.009*""product"" + 0.009*""date"" + 0.008*""month"" + 0.008*""dataset"" + 0.007*""predict"""
51718792_so,"kubernetes nvidia-docker tensorflow running an example pod on kubernetes with nvidia gpu nodes i m trying to setup kubernetes with nvidia gpu nodes/slaves.i followed the guide at  https://docs.nvidia.com/datacenter/kubernetes-install-guide/index.html  and i was able to get the node join the cluster i tried the below kubeadm example pod   the pod fails scheduling &amp the kubectl events shows   i m using aws ec2 instances m5.large for the master node &amp g2.8xlarge for the slave node describing the node also gives  nvidia.com/gpu  4 .can anybody help me out if i m missing any steps/configurations according to the aws g2  documentation    servers have the following resources   four nvidia grid gpus each with 1,536 cuda cores and 4 gb of videomemory and the ability to encode either four real-time hd videostreams at 1080p or eight real-time hd video streams at 720p   32 vcpus   60 gib of memory  240 gb 2 x 120 of ssd storage   looking at the comments 60 gb is standard ram and it is used for regular calculations   servers have 4 gpus with 4 gb of gpu memory each and this memory is used for calculations in   containers   in your case it is requested 8 gb of gpu memory per gpu but your server has only 4 gb therefore the cluster experiences a lack of resources for scheduling the pod so try to reduce the memory usage in the pod settings or try to use a server with a larger amount of gpu memory",15,0.8766052229839698,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
49816015_so,caching caffeine distributed-system google-guava-cache spring-boot evicting in-memory cache across multiple instances how do we evict in-memory caches at different instances?  we have a scale-out architecture multiple instances service requests simultaneously each one of them has in-memory cache attached to it  we need eviction accross all instance at once   why not memcache/redis or other provider? calls to redis/memcache creates network latency apart from its speed our data size is much smaller that can easily fit within an instance [max 100mb]   temporary solution as a temporary solution we have time based eviction time being relatively lower 2.5minute but for 2.5 minute it can each instance can serve own copy of data that can lead to inconsistency how do we keys of cache at multiple instances at once ,15,0.876476524171704,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
57448794_so,deep-learning neural-network perceptron can anyone prove that how many hidden nodes can solve a boolean function with n-dimension input if use only one hidden layer i have a boolean function with n-dimension input if use single layer perceptron how many nodes at least can solve that and why and if use multi layers how many nodes and layers at least can solve it ,11,0.8763920132747997,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
50726363_so,math regression statistics clarification on squaring residuals i understand we take squares of residuals because it penalizes large deviations from actuals more than smaller ones but how does that help? we try to minimize sum of squared residuals anyways so why does it matter if one of the predictions is more penalized vs others ,18,0.8763445236016292,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
59115757_so,"ensemble-learning imbalanced-data logistic-regression machine-learning svm is it possible to use voting classifier as base classifier in ensemble voting classifier i design model like bagging classifier.but in every level instead of training individual classifier,i training voting classifier as base classifier.voting classifier contains svm and logisticregression classifer.after training voting classifier i save them in list and pass list to ensemblevotingclassifer from mlxtend package.i use ensemblevotingclassifer because sklearn votingclassifier can not process prefitted classifier.i want to know can i do this or this model is wrong?if this method is true what is the name of this method in general?  i train voting classifier during bagging process by passing bootstrap samples to voting classifier like that   and then i get prediction from it by this code ",9,0.8761958472774307,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
55189944_so,deep-learning keras machine-learning neural-network i want to converge the keras model with just fc-layer i have a keras model with just fc-layerdense i got train image size   and   class each class having 1 train image i would like to overfit and get 100% training accuracy  isuue:i tried to babysit model hyperparameters but it s not converging to 100% train accuracy although it s just fc-layer even  here s my code   here s plot for above code       i have ran different hyper-params experiment with 10k to 20k epochs loss after some epochs not decreasing and no improvement in train-accuracy  i tried to play with different optimizers&amp hyper-params regularization as well there s not much hyperparams to play with except optimizer &amp regularizers here right?  if anyone can help me for converging the model that would be great.thank you i am able to overfit hyper-params i have used for over-fitting this experiment   i got 99% train-accuracy @around 12k epochs and continued decreasing loss till around 25k epochs,13,0.87609665240697,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
147912_kg,i want to pass the created xlsx file as a stream or in-memory to called called process/function?  right now i am getting file object type info in the called process as  pandas.io.excel._openpyxl._openpyxlwriter object at 0x0000017ee9a76808 but as actually i want to pass file name along with its contents  import sys csv;import pandas as pd  class custompythonscript:    pd.set_option display.max_rows  none    pd.set_option display.max_columns  none    pd.set_option display.width  none    pd.set_option display.max_colwidth  -1    df = pd.read_csvsys.stdin sep= \t     data = df.groupby[ x   y_dt   z ].sumnumeric_only=true.reindexcolumns=setdf.columns - { x   y_dt   z }\        .reset_index    df1 = pd.dataframedata    writerexcel = pd.excelwriter report_groupby.xlsx  engine= openpyxl     df1.to_excelwriterexcel sheet_name= report_groupby  index=false    writerexcel.save    printwriterexcelhow to change my code so that i will get expected outcome ,19,0.8757820086654162,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
35667330_so,classification machine-learning neural-network python theano log-likelihood cost function mean or sum in  this code  for computing the negative log-likelihood they say     note we use the mean instead of the sum so that the learning rate is  less dependent on the batch size   and this is how they get the negative log-likelihood   this is true in many textbooks e.g  pattern recognition and machine learning  by bishop the negative log-likelihood is calculated by using the  sum  of each individual sample error rather than the  mean  i still don t understand the note from the author every time when we calculate cost function should we use the mean rather than the sum? even when we are not using batch consider the two situations when you want to change the batch size of your algorithm lets say from 10 to 100    if you are using the sum of the log-likelihood cost function the average step that you re taking will be multiplied by 10 because the sum will have 10x more terms and then you will have to readjust the learning rate    if you are using the mean then that result will be divided by 100 instead of 10 and your steps will be naturally of the same order of magnitude    so if you re not using mini-batches or adjusting the batch size don t worry about this  the difference between the mean and the sum is just the multiplication by 1/n   the problem with using the sum is that the batch size n will influence your gradients the learning rate indicates how much in the direction of the gradient you want to adjust your parameters   if your gradient is larger for larger batch sizes n it means that you will need to adjust the learning rate as you increase the batch size n  in practice in order to keep these two learning rate and batch size independent it is common to use the mean instead of the sum this makes the gradient magnitude independent of n  if you are not using a batch then n=1 and the mean is the same as the sum,3,0.8755659501601026,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
42178437_so,bigdata java oozie yarn run single application master for oozie workflow according to  why does the oozie luncher consume 2 yarn containers?   i have cluster with 1900 core and 11tb ram.and i have next structure of workflow for my oozie wf   approximately 300-400 subworkflows with same structure that will runin parallel by fork control node   in these subflows one-by-one runseveral tasks java actions spark tasks shell actions   some ofsubflows can execute in 3-5 minutes some of them - 2-3 hours longterm spark tasks   the question is - is it possible to run these subworkflows in a   single   container application master? by default for each subworkflow oozie/yarn uses two cores one for am and one for map-reduce task controller and this is the bottleneck - 1/3 of all cores of my cluster used only for controlling but not for computing i guess you can use the uber mode of the oozie to save the container which launches the oozie action job the am will launch the action instead of doing it from a separate container  add the following property into,15,0.8752193283150353,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
44976308_so,"c++ caffe makefile protobuf-c add protbuf 3.3.0 to make file i use ubuntu 16.04 vith protobufer 2.6.1 but i want to build  caffe required for  faster_rcnn_cplusplus  via protobuffer 3.3.0 which i build from github sources.as i want to install it locally to some folder and use it folder only for 1 program i folowed the instruction till make install command  and finally my question could you,please advice me how can i add my protobuf 3.3.0 to makefile and what path should it be proto 3.3.0 local directory is /home/adzhus/workspace/faster-rcnn-cpp-1/protobuf-3.3.0/protobuf-master ",21,0.8749549686053549,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
41229340_so,"artificial-intelligence machine-learning mnist neural-network tensorflow dimensions of this neural network i.e 4 inputs 2 hidden layer with x neurons each etc i was looking at tensorflow examples by aymeric damien  https://github.com/aymericdamien/tensorflow-examples/blob/master/examples/3_neuralnetworks/multilayer_perceptron.py  and in   he uses a neural net to classify mnist digits i think he is using a neural network with  784inputs with 2 hidden layers with 256 neurons each and 10 outputs  am i correct?   how do matrix dimensions in   and   in multilayer_perceptron.py correspond with ann dimensions #inputs #hidden layers #output #neurons in each hidden layer etc   thank you this is a 3-layer neural network 2 hidden layers and an output layer  the connection between the inputs to the first hidden layer has 784 x 256 weights with 256 biases this configuration is due to the fact that each of the 784 inputs is fully connected to the 256 hidden layer nodes and each hidden layer node has 1 bias  the connection between that first hidden layer to the second hidden layer has 256 x 256 weights due to full connectivity between the layers the second layer s 256 nodes each has 1 bias  the connection between the second hidden layer and the output layer is similar there are 256 x 10 weights for the second hidden layer s 256 nodes and the output layer s 10 nodes and each output node has 1 bias  there are thus 785*256 + 256*256 + 256*10 = 269,056 weights and 256 + 256 + 10 = 522 biases  the figure below should explain it fully",11,0.8748900531920626,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
42981049_so,apache-crunch bigdata distributed-computing mapreduce oozie scaling oozie map reduce job does splitting into smaller jobs reduce overall runtime and memory usage i have a oozie workflow that runs a map-reduce job within a particular queue on the cluster  i have to add more input sources/clients to this job so this job will be processing n times more data than what it does today  my question is if instead of have one big job processing all the data if i break it down into multiple jobs one per source will i reduce the total amount of time the jobs will take to complete?  i know mapreduce anyhow breaks down a job into smaller jobs and spreads them across the grid so one big job should be the same as multiple small jobs  also the capacity allocation within the queue is done on a  per user  basis[1] so no matter how many jobs are submitted under one user the capacity allocated to the user will be the same or is there something i am missing?  so will my jobs really run any faster if broken down into smaller jobs?  thanks  [1]  https://hadoop.apache.org/docs/r1.2.1/capacity_scheduler.html#resource+allocation ,15,0.8742825469170086,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
37216501_so,gradient-descent statistics theano taking the gradient of huber loss in theano i have two functions that are suppose to produce equal results    given input   i need to find the parameters   that makes this equality hold as well as possible  initially i was thinking of using squared loss and minimizing   and solving via sgd  however i was thinking of making the loss more precise and using huber or absolute loss of the difference.huber loss is a piecewise function ie initially it is quadratic and then it changes into a linear function  how can i take the gradient of my huber loss in theano a pretty simple implementation of huber loss in theano can be found  here   here is a code snippet   the function   will return a symbolic representation of the loss which you can then plug in   to get the gradient and use it to minimize using sgd,3,0.8740792410320075,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
55923246_so,gradient-descent optimization python pytorch how can i supply custom gradient to torch.optim.lbfgs i have some research task for logistic-like regression   it converges but near optimum gradient becomes nan i can calculate gradient more effectively with my function gradw it gives same results as pytorch derivative calculator except it doesn t go to nan near optimum how can i supply it to torch.optim.lbfgs  ,3,0.8736535475916926,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
50677597_so,bigdata cloud what does big data have to do with cloud computing what does big data have to do with cloud computing? i have try to explain the relation between big data and cloud computing they overlap one is not dependent on the other cloud computing enables companies to rent infrastructure over time rather than pay up-front for computers and maintain it over time   in general cloud vendors allow you to rent out large amounts of server pools and build networks of servers clusters   you can pay for servers with large storage drives and install software like hadoop filesystem hdfs ceph glusterfs etc these softwares will make a single shared filesystem the more servers you combine together into this filesystem the more data you can store   now that s just storage hopefully these servers also have some reasonable amount of memory and cpu processing other technology such as yarn with hadoop apache mesos kubernetes/docker allow you to create resource pools to deploy distributed applications that spread over all those servers and read data that s stored in all those other machines    the above is mostly  block storage  though the alternative cheaper alternative is  object storage  such as amazon s3 which is a hadoop compatible filesystem there are other object storage solutions but people use this as it s more highly available via replication and can be secured easier with access keys and policies,15,0.8735896418411683,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
18502093_so,classification machine-learning how to calculate f-measure based on tpr fpr and accuracy can anyone help me on this!  i have given tpr true positive rate and false positive rate and the accuracy as well based on the given numbers is there anyway to calculate the f-measure precision and recall  let say that the tpr=.93 fpr=0.17 and the accuracy=0.93 what would be the value of f-measure  thanks f needs to compute precision and recall true positive rate   in the confusion matrix you have four variables tp fp fn tn and since you only need the rates so you have tp + fp + fn + tn = 1 which essentially makes there only 3 unknown variables and now you have tpr fpr accuracy you can have 3 independent equation   then you can figure out how to compute precision and then f,18,0.8733212517835881,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
48928_kg,can anyone tell me comae i never get this error in jupiter  convert_to_binary  is not defined and how do i solve it? thank you  determine primary deviceimport numpy as np printdeterming primary device... sessions_device = sessions.loc[: [ user_id   device_type   secs_elapsed ]] aggregated_lvl1 = sessions_device.groupby[ user_id   device_type ] as_index=false sort=false.aggregatenp.sum idx = aggregated_lvl1.groupby[ user_id ] sort=false[ secs_elapsed ].transformmax == aggregated_lvl1[ secs_elapsed ] df_primary = pd.dataframeaggregated_lvl1.loc[idx  [ user_id   device_type   secs_elapsed ]] df_primary.renamecolumns = { device_type  primary_device   secs_elapsed  primary_secs } inplace=true df_primary = convert_to_binarydf=df_primary column_to_convert= primary_device  df_primary.drop primary_device  axis=1 inplace=true  nameerror traceback most recent call last in  7 df_primary = pd.dataframeaggregated_lvl1.loc[idx  [ user_id   device_type   secs_elapsed ]] 8 df_primary.renamecolumns = { device_type  primary_device   secs_elapsed  primary_secs } inplace=true ----&gt 9 df_primary = convert_to_binarydf=df_primary column_to_convert= primary_device  10 df_primary.drop primary_device  axis=1 inplace=true 11  nameerror name  convert_to_binary  is not defined   there are at least two problems   python doesn t have a function named   you probably want  bin   you re using the wrong syntax for applying functions to pandas dataframe columns it should be something like   see  the pandas docs on apply  for details,19,0.8731738851063326,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
48600813_so,artificial-intelligence machine-learning neural-network which layers in a neural network use activation functions does the input layer of a neural network use activation functions or is it just the hidden and output layers here s a figure of a 3-layer neural network from stanford s class on nn for visual recognition       the two hidden layers will always have an activation function the output layer may or may not have an activation function for binary classification you might have a sigmoid function to squash your output but for regression you typically will not have an activation function  for clarity the hidden layers compute   as you probably know the   may be a       or other  hidden and output layer neurons possess activation functions but input layer neurons do not input layer just gets input and multiply it with unique weights activation functions perform a transformation on the input received,11,0.8729475754200463,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
28113_kg,hi how do i convert h5 file to csv   its a dataframe  in pandas you can directly read using pd.read_hdf pd -&gt pandas  in r u need library gdalutils  if you want to write to csv read using r or python code and do dataframe.to_csv    when you read data block0_values rows and and columns will get transposed try to correct it   use pandas in python   then,19,0.8725115867481933,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
39054513_so,"machine-learning mathematical-optimization in the regularization,why we use θ^2 rather than θ the regularization is lambda*sumθ^2 i ve  already answered  this in your previous question see last paragraph but i ll try again   the problem regularizing with   is that you may have θ parameters that cancel each other  example   the   here is +1000000 -1000001 = -1 which is small  the   is 1000000² + -1000001² which is very big  if you use   you may end up without regularization which was the goal because of large θ values that escaped the regularization because the terms cancel each other out  you may use   depending on your search/optimisation algorithm but i know θ² l2 norm to be popular and works well with gradient descent",3,0.8719059322951911,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
5125770_so,"c++ configuration opencv visual-studio opencv and visual studio configuration in  learning opencv  it mentions the following regarding configuring opencv and visual studio     in visual studio it is necessary to  create a project and to configure the  setup so that  a the libraries  highgui.lib cxcore.lib ml.lib and  cv.lib are linked and b the  preprocessor will search the opencv …  /opencv/*/include directories for  header files these  “include”  directories will typically be named  something like c:/program  files/opencv/cv/include,  …/opencv/cxcore/include …  /opencv/ml/include and …  /opencv/otherlibs/ highgui   how would i go about creating and configuring the project this way it is necessary to set environment variables first you just need to add the location of the bin class to the directory path.just add a semicolon and paste the path  then after creating a visual c++ console project you have to include needed include directories path to specific location.if you need more explanation on that just add a comment  you need to set the environment variables and then set the projects properties c++ and linker according to your opencv version and directories see my step-bystep guide with instructions and a video   http://devel-open.blogspot.com.ar/2012/12/opencv-visual-studio-2008.html",21,0.8713600344433471,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
4895485_so,neural-network delta rule vs gradient descent what s the difference between gradient descent and the delta rule without math the delta rule uses gradient descent to minimize the error from a perceptron network s weights  gradient descent is a general algorithm that gradually changes a vector of parameters in order to minimize an objective function it does this by moving in the direction of least resistance i.e the direction that has the largest negative gradient  you find this direction by taking the derivative of the objective function it s like dropping a marble in a smooth hilly landscape it guaranties a local minimum only so the short answer is that the delta rule is a specific algorithm using the general algorithm gradient descent,3,0.8710149741706249,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
53557621_so,machine-learning mlp random-forest svm xgboost how to set multi classes with machine learning algorithm i m using xgboost randomforestsklearn svmsklearn and mlpclassifiersklearn as classifier.and i want to set these models for multi label class.how can i set i think you don t need to do anything extra for xgboost random forest and and mlp  for svc you can use onevsrestclassifierlinearsvc.then you just have to train with the algorithms you mentioned and tune it based on predictors to get the best results  none of these algorithms you ve mentioned are restricted to binary classification problems they can be used for multiclassification problems the same way as you would do for binary classification by calling,9,0.8706073175620688,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
46884841_so,machine-learning scikit-learn svm how to draw equal number of examples from each class in scikit learn svm during training i used scikit learn to implement a  support vector machine  since i am dealing with class imbalance 96% to 4% i would like the svm to draw an equal number of samples from each class during training how can i achieve this with scikit learn an alternative approach is to adjust the class weights with the   argument from the  svc docs  similar argument exists for other svm models too      class_weight   {dict ‘balanced’} optional      set the parameter c of class i to class_weight[i]*c for svc if not given all classes are supposed to have weight one the “balanced”  mode uses the values of y to automatically adjust weights inversely  proportional to class frequencies in the input data as     you might be interested in  imbalanced-learn  package which has a number of implementations such as oversampling and undersampling to tackle the class imbalance problem,9,0.8705130731574685,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
52452281_so,cross-validation machine-learning svm training-data the correct way to tune the c parameter of svm i have a dataset which has three splits training-validation-testing what is the best way to tune the c parameter? do i train on the training and evaluate on the validation partition? is it correct to perform k-fold validation when you have an already partiotioned data?  any explanation will be truly appreciated.thank you i generally dont split my data into 3 parts i use 20% of my train data randomly for validation in 5-10 iterations and check accuracy with different c  suppose i take 5 iterations and 4 different c to check   similarly i do this for 5 more iterations each iteration provides a new validation set randomly from train data and the c value with the highest mean accuracy along different iterations is chosen as the best parameter  alternatively you can use gridsearchcv or randomizedsearchcv to achieve the same,1,0.8704478788402297,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
56669190_so,correlation machine-learning regression relationship between independent and dependent variables i have a dataset in which there are multiple independent variables which might have some relation with the dependent variable i am trying to find the relation between each independent variable at first visually plotting scatterplots between each independent and dependent variable and correlation but it seems not helping me  what i am able to think is that it might happen that when i am looking at the relationship of feature1 with label and not able to find a good relation the other variable feature2 or feature3 might have affected the relationship how can i keep one variable unaffected by the other variable and see the relationship  i have actually checked the multicollinearity between different features using vif and correlation  p.s  i am actually trying to fit a regression model ,2,0.870275781750497,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
3693_kg,"i would be doing my data manipulation in postgresql and have created the following code to load data into a database feel free to use it  [code]  -- database &quot;bulldozer&quot  -- drop database &quot;bulldozer&quot;  create database &quot;bulldozer&quot &nbsp with owner = postgres &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp encoding =  utf8  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp tablespace = pg_default &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp lc_collate =  english_united kingdom.1252  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp lc_ctype =  english_united kingdom.1252  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp connection limit = -1  show datestyle --datestyle=postgres dmy --since dates in the training set provided are in mdy format temporarily change the datestyle to be mdy set datestyle to postgres mdy --now datestyle=postgres mdy  /* create raw_train table to hold the training data provided*/ --drop table raw_train;&nbsp;&nbsp &nbsp create table raw_train  salesid&nbsp;&nbsp &nbsp;int primary key ,saleprice&nbsp int ,machineid&nbsp int ,modelid&nbsp int ,datasource&nbsp int ,auctioneerid&nbsp int ,yearmade&nbsp int ,machinehourscurrentmeter&nbsp int ,usageband&nbsp varchar6 ,saledate&nbsp date ,fimodeldesc&nbsp varchar19 ,fibasemodel&nbsp varchar13 ,fisecondarydesc&nbsp varchar19 ,fimodelseries&nbsp varchar11 ,fimodeldescriptor&nbsp varchar14 ,productsize&nbsp varchar14 ,fiproductclassdesc&nbsp varchar64 ,state&nbsp varchar14 ,productgroup&nbsp varchar3 ,productgroupdesc&nbsp varchar19 ,drive_system&nbsp varchar16 ,enclosure&nbsp varchar19 ,forks&nbsp varchar19 ,pad_type&nbsp varchar19 ,ride_control&nbsp varchar19 ,stick&nbsp varchar8 ,transmission&nbsp varchar19 ,turbocharged&nbsp varchar19 ,blade_extension&nbsp varchar19 ,blade_width&nbsp varchar19 ,enclosure_type&nbsp varchar19 ,engine_horsepower&nbsp varchar8 ,hydraulics&nbsp varchar19 ,pushblock&nbsp varchar19 ,ripper&nbsp varchar19 ,scarifier&nbsp varchar19 ,tip_control&nbsp varchar19 ,tire_size&nbsp varchar19 ,coupler&nbsp varchar19 ,coupler_system&nbsp varchar19 ,grouser_tracks&nbsp varchar19 ,hydraulics_flow&nbsp varchar19 ,track_type&nbsp varchar6 ,undercarriage_pad_width&nbsp varchar19 ,stick_length&nbsp varchar19 ,thumb&nbsp varchar19 ,pattern_changer&nbsp varchar19 ,grouser_type&nbsp varchar6 ,backhoe_mounting&nbsp varchar19 ,blade_type&nbsp varchar19 ,travel_controls&nbsp varchar19 ,differential_type&nbsp varchar12 ,steering_controls&nbsp varchar19   create index machineid_idx on raw_train using btreemachineid asc  /*read from csv file*/ copy raw_train from  e:/bulldozer/train.csv  delimiters    csv header quote  &quot   /*create a table with the same table definition as train to hold validation data*/ --drop table raw_valid  create table raw_valid like raw_train alter table raw_valid drop saleprice;/*droping salesprice column since leaderboard validation sample does not have this column*/ create index machineid_vidx on raw_valid using btreemachineid asc /*read from csv file*/ copy raw_valid from  e:/bulldozer/valid.csv  delimiters    csv header quote  &quot   --set datestyle back to uk style set datestyle to postgres dmy  /*create table to hold machineid_appendix*/ --drop table machineid_appendix create table machineid_appendix  &nbsp;&nbsp &nbsp;machineid&nbsp;&nbsp &nbsp;int primary key ,&nbsp;&nbsp &nbsp;modelid&nbsp;&nbsp &nbsp;int ,&nbsp;&nbsp &nbsp;fimodeldesc&nbsp;&nbsp &nbsp;varchar25 ,&nbsp;&nbsp &nbsp;fibasemodel&nbsp;&nbsp &nbsp;varchar13 ,&nbsp;&nbsp &nbsp;fisecondarydesc&nbsp;&nbsp &nbsp;varchar20 ,&nbsp;&nbsp &nbsp;fimodelseries&nbsp;&nbsp &nbsp;varchar11 ,&nbsp;&nbsp &nbsp;fimodeldescriptor&nbsp;&nbsp &nbsp;varchar14 ,&nbsp;&nbsp &nbsp;fiproductclassdesc&nbsp;&nbsp &nbsp;varchar70 ,&nbsp;&nbsp &nbsp;productgroup&nbsp;&nbsp &nbsp;varchar4 ,&nbsp;&nbsp &nbsp;productgroupdesc&nbsp;&nbsp &nbsp;varchar29 ,&nbsp;&nbsp &nbsp;mfgyear&nbsp;&nbsp &nbsp;int ,&nbsp;&nbsp &nbsp;fimanufacturerid&nbsp;&nbsp &nbsp;int ,&nbsp;&nbsp &nbsp;fimanufacturerdesc&nbsp;&nbsp &nbsp;varchar27 ,&nbsp;&nbsp &nbsp;primarysizebasis&nbsp;&nbsp &nbsp;varchar27 ,&nbsp;&nbsp &nbsp;primarylower&nbsp;&nbsp &nbsp;float ,&nbsp;&nbsp &nbsp;primaryupper&nbsp;&nbsp &nbsp;float  copy machineid_appendix from  e:/bulldozer/machine_appendix.csv  delimiters    csv header quote  &quot   [/code]   this is awesome - thank you so much! i adapted it for mysql and it saved me tons of futsing around",19,0.8700726738929467,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
38159788_so,algorithm classification naivebayes svm one class classification alternative algorithms are there any other algorithms except from svm and positivenaivebayesclassifier that i can use to do one class classification? the positive naive bayes is only for text classification and i want to use except from svm and another two.any suggestions ,9,0.8699906892926104,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
18875896_so,cvblobslib opencv visual-c++ cvblobslib external link error..please help me today i ve compiled cvblobslib for windows with opencv in my visual studio c++ 2010  compilation goes ok and i obtain cvblobslib.lib  i ve follow the istruction on library to set visual c++ in my project to use this library c++ additional directories and other like in the instructions that i quote here  1 - open the project of the library and build it ok done2 - in the project where the library should be used add  2.1 in project/settings/c++/preprocessor/additional includedirectories add the directory where the blob library is stored done  2.2 in project/settings/link/input/additional library path addthe directory where the blob library is stored and in object/librarymodules add the cvblobslib.lib file where? in the visual studio folder or in my project folder?  3- include the file blobresult.h where you want to use blob variables ok done  note verify that in the project where the cvblobslib.lib is used the mfc runtime libraries are not mixed   check in project->settings->c/c++->code generation->use run-time library of your project and set it todebug multithreaded dll debug version  or to multithreaded dll  release version .2 check in project->settings->general how it uses the mfc it should be use mfc in a shared dll done   can anyones help me because with this code   i obtain this errors   why i obtain external link error ??  please help me...i don t know what to do. you need to correctly set the path to the  64-bit  cvblobslib.lib  go to project settings configuration properties and find the settings   linker -> general -> additional library directories  linker -> input -> additional dependencies   although this is easier if the cvblobslib project is in the same solution as prova64 in which case you can add a project reference right click prova64 project references.. add the cvblobslib project,21,0.8699744278412153,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
52402693_so,chainer gensim nlp tensorflow word-embedding non english word embedding from english word embedding how can i generate non-english french  spanish  italian  word embedding from english word embedding ?  what are the best ways to generate high quality word embedding for non - english words   words may include samsung-galaxy-s9 for non-english words you can try to use a bilingual dictionary to translate english words with embedding vectors  you need a large corpus to generate high-quality word embeddings for non-english you need to add the bilingual constraints into the original w2v loss with the input of bilingual corpora  you can regard the compound word as a whole word or split it according to your applications       how can i generate non-english french  spanish  italian  word embedding from english word embedding ?   you can t really unless you have words which mean exactly the same if you have know the french word for king queen woman and man you can give those words the embedding of the exact same word in english they will show the same syntactic and semantic properties that the english words do but you can t really use the english embeddings to make embeddings for different languages     what are the best ways to generate high quality word embedding for non - english words    english words and non-english words can be treated the same way represent your non english words as strings/tokens and train a w2v model use gensim for this you ll have to find a huge corpus for the language you want then you will have to train your model with this huge corpus for a few epochs done alternatively look for pre existing models in your required language     words may include samsung-galaxy-s9   unless your corpus has words like samsung-galaxy-s9 your model won t know what it means use a corpus which might have more words in the domain you re hoping to use the embeddings for,12,0.8695839410450755,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
42923851_so,"machine-learning multilabel-classification nonlinear-functions scikit-learn svm an svm implementation supporting non-linear kernels and multi-label on a one-vs.-rest i m looking for a svm implementation with support for non-linear kernels and one-vs-rest scenario to perform a multi-label classification preferably written in python or that i can call from python with wrappers  i was looking into sklearn and there are two implementations to use svm for classification   sklearn.svm.linearsvc - supports multi-label classification with a one-vs.-rest scenario but it s based on liblinear and therefore only supports linear kernels   sklearn.svm.svc - based on libsvm supports non-linear kernels but multi-label classification is done under a one-vs.-one reduction it trains k k − 1 / 2 binary classifiers for a k-way multiclass problem  more info also here: http://scikit-learn.org/stable/modules/multiclass.html   does anyone knows any other svm implementations directly supporting multi-label classification and non-linear kernels ?   one possible solution could also be to adapt the code based on sklearn.svm.svc to perform one-vs-rest was this already attempted before binary relevance problem transformation method  uses one-vs-rest approach for doing multi-label classification one could easily implement svm with non-linear kernels using  scikit-multilearn  library the following is the sample python code to do the same where each row of train_y is a one-hot vector representing multiple labels for instance [0,0,1,0,1,0",9,0.8695573468045574,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
52436128_so,data-cleaning machine-learning normalization training-data if i am performing data preprocessing on training data is it necessary to perform the same on test data for example if i find the   and   of the training data and   it should i use the same   and   for testing data or should i find the   and   of testing data you should use the mean and variance used on the  training data  this ensures that the processing methodology on both sets of data is the same the unseen test set data mean/variance should not be used,1,0.8695364536779658,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
53133930_so,grid-search machine-learning scikit-learn how to use the best parameter as parameter of a classifier in gridsearchcv i have a function called   which returns  .now i want to use the best_params returned as the parameter of a classifier like:    it seems parameters is not a grid here you can use gridsearchcv to do this there is a example here   but for   of   you should pass a dictionary of parameter name and value for you classifier for example a classifier like this   then after finding best parameters by   you apply them on you model,9,0.8695343050775562,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
101017_kg,"hi all,i have small doubt.please help me to come out from this.suppose we have simple linear regression like this hx = w0+w1x1and the sum of sqared error is given as  1/nsumactual-w0+w1x1**2so,this sum of squared error is a function of w0 and w1 means we have to choose w0 and w1 in such a way that our sum of squared error is minimum so by differentiating this sum of squared error function with respect to w0 and w1  we get the slope and we also know that slope=0 means either we have minima or maxima.then why in gradient descent we are not equating this slope =0  i saw many places they are doing like this w0 = w0 - learning_rate*slope same this way for w1 after that they are repeating this step till our cost is minimize.but my question is if we directly equate the slope=0 then at this places either we have minima or maxima.please help me to come out from this thanks in advance     there are certain cost functions which cannot be solved using the derivative method.some functions do not have derivative everywhere and for some functions even if you find the derivative you cannot find a solution after equating it to zero.so we use numerical methods like gradient descent to optimize these functions.for example in linear regression we can find a derivative and equate it to zero to find a minima but for logistic regression even if you find the derivative you cannot find an analytical solution to the equations easily   thanks  @shreyanchak     really clear explanation  @shreyanchak  :   thank you  @rtatman",3,0.8695156422115572,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
36786899_so,"android android-ndk tensorflow how to build the project for intel x86 emulator instead of armeabi v7 i am beginner in android  i have successfully built the android demo with bazel now i am trying to work with it in android studio  i found this repository  here   it currently works well with  armeabiv7  but  crashes with intel x86 emulator   but i want to build it for  intel x86 and x86_64  and i want to build it in android studio using gradle what should i do? please help me  i am using ndk 10re,android studio 2.0,ubuntu 14.04 as you see in this location of repo  https://github.com/miyosuda/tensorflowandroiddemo/tree/master/app/src/main/jnilibs there are only libraries for armeabi-v7a thus it will not work on x86 emulator   from what is available on this repo i see there is also jni code code for that libraries unfortunately there are dependencies and are also available here only for armv7 platform to make this work it will require a lot of work mainly searching for proper working x86 libraries/dependecies or building them by yourself",21,0.8694035886482238,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
45018147_so,android android-studio java opencv make a stand alone library jar that also uses opencv lib using android studio one can make a library using android studio by following  https://developer.android.com/studio/projects/android-library.html   i want to make a computer vision library that can be used by people easily into their projects but this library also uses opencv is there any way i can make a library that also contains opencv in it ?i tried to include opencv-2.4.1.jar in libs forlder of the target library but while running the application i get following error   java.lang.unsatisfiedlinkerror native method not found org.opencv.core.mat.n_mat:  please guide me how to include opencv in another library is it possible ?or i will have to import opencv and the other library individually in all the project  you have to add a link to opencv as a gradle or maven dependency for your project when you will add it to maven repo.like this   opencv is not just a jar it has native libraries as well  if you distribute your library as an artifact e.g on maven central or jcenter and you set up your dependencies properly using gradle   directives the consumers of your library will pull in opencv automatically you would not directly include the opencv jar in your library,21,0.8691557324701508,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
48611634_so,linear-regression multilevel-analysis regression statistics multilevel model - 2 levels i got my data from a questionanire where i had group1 30 individuals vs group2 30 individuals they answered on 6 questions from those 6 questions i got weights on advice my dv that range from 0 to 1 continuous data to analyze it i though it would be good idea to do a multilevel model so then level 1 is individuals level 2 - group 1 and 2 but when i did a multilevel model glm with level 2 - group 2 groups the icc equals 0 does it mean that i cannot use a multilevel model or am i doing smth wrong?   if i cannot on which regression should i focus then ,2,0.8691226803444017,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
46840353_so,"missing-data r random-forest random forest for a mixture of categorical,numeric and unwanted variables which include missing values i am trying to use random forest package in r for my data set which includes categorical and numerical variables as well as some unwanted coloumns coloumns which i do not want to include as my predictor variables moreover some of my desirable variables which are supposed to be used as predictor are missing.how can i handle that i assumed your dataset looks like something like this      to use only desired columns   a you can either specify in your formula which columns you want to use in your random forest    b else you can subset your dataset by keeping only desired columns       to handle na values   a you may try to impute them  b or you can you another library that may handle them such as      finally i suggest you have a look at this thread    how to build random forests in r with missing na values",2,0.8688928255670538,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
55448330_so,convolution cross-validation data-science keras machine-learning can i predict and evaluated model with the whole dataset i split the dataset into train and test of 80-20 ration respectively i predicted and evaluated with test dataset and my question is can we evaluate and predict model with the whole dataset before that i shuffle entire dataset can we do that? if not why should not we do that? what is wrongdoing like that if you use the whole dataset for training the model will fit to all the variances in data overfitting as a result the performance of your model on similar data will be high however the model will exhibit low performance on unseen data with a different distribution compared to your training dataset one way to prevent this is to a split your data into training validation and testing datasets see the note below b apply k-fold cross-validation on training and validation splits c verify the performance of your models from step b on the third split test dataset note there is no consensus on the naming of the splits some sources name them training-validation-testing while others use training-testing-validation   data snooping is the quick answer what you are looking for in other words your model would seem outperforming on your test data if it was trained on 100% data first model would become an overfitted model that basically would predict seen data with higher accuracy however would fail to do so with any sort of unseen test data   you can do it however it would result in overfitted model you can try k fold cross validation method in stead,1,0.8686184672765531,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
54394011_so,classification ensemble-learning knn matlab random-forest applying classification ensemble methods i want to apply classification ensemble on a matrix of data by using fitcensemble methode if i want to combine some classifiers for example random forest &amp knn classifiers should i use fitcensemble?is there more methods for classification ensemble ,9,0.8682188003211286,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
30850206_so,c++ opencv visual-c++ visual-studio visual-studio-2013 visual studio 2013 link  fatal error lnk1181 cannot open input file i am using visual studio 2013  i m trying to build some code given to me from my professor and i keep getting this error      link  fatal error lnk1181 cannot open input file   c:\users\manduchi\documents\eyegaze\eyegazedemo..\libraries\opencv\lib\opencv_core249.lib    however on my computer opencv_core249.lib is located somewhere else i ve tried updating the linker directories to the address on my computer but i continue getting the error  here was my attempt    under configuration properties-> vc++ directories i added the address of the folder enclosing the .lib file in include directories and in library directories   linker-> general and added an additional library directory there as well   linker-> input and added opencv_core249.lib to additional dependencies   i m new to visual studio and c++ so i might have done it incorrectly?   more info   i m doing this on my windows 7 bootcamp  the code is on a usb stick because i don t have enough space on mybootcamp partition   any help would be appreciated! thanks  update  updated error message     link  fatal error lnk1181 cannot open input file   opencv_calib3d300.lib    i think  opencv_calib3d300.lib  is on the linker->input->additional dependencies under inherited values  linker command line  /out:debug\eyegazedemo.exe /manifest /nxcompat /pdb:debug\eyegazedemo.pdb /dynamicbase glu32.lib opengl32.lib gdi32.lib user32.lib opencv_ts300.lib opencv_ts300d.lib opencv_world300.lib opencv_world300d.lib e:\qt\5.0.2\msvc2012_64\lib\qtmaind.lib e:\qt\5.0.2\msvc2012_64\lib\qt5cored.lib e:\qt\5.0.2\msvc2012_64\lib\qt5widgetsd.lib e:\qt\5.0.2\msvc2012_64\lib\qt5guid.lib opencv_calib3d300.lib opencv_contrib300.lib opencv_core300.lib opencv_features2d300.lib opencv_flann300.lib opencv_gpu300.lib opencv_highgui300.lib opencv_imgproc300.lib opencv_legacy300.lib opencv_ml300d.lib opencv_nonfree300d.lib opencv_objdetect300d.lib opencv_ocl300d.lib opencv_photo300d.lib opencv_stitching300d.lib opencv_superres300d.lib opencv_video300d.lib opencv_videostab300d.lib kernel32.lib winspool.lib comdlg32.lib advapi32.lib shell32.lib ole32.lib oleaut32.lib uuid.lib odbc32.lib odbccp32.lib opencvconfig.cmake opencvmodules.cmake opencvmodules-debug.cmake opencvmodules-release.cmake e:\eyegaze\eyegaze\libraries\opencv\lib\opencv_core249d.lib e:\eyegaze\eyegaze\libraries\opencv\lib\opencv_imgproc249d.lib e:\eyegaze\eyegaze\libraries\opencv\lib\opencv_highgui249d.lib e:\eyegaze\eyegaze\libraries\opencv\lib\opencv_objdetect249d.lib e:\eyegaze\eyegaze\libraries\opencv\lib\opencv_ml249d.lib e:\eyegaze\eyegaze\libraries\intraface\lib\intrafacedll-x86d.lib /debug /machine:x86 /safeseh /incremental:no /pgd:debug\eyegazedemo.pgd /subsystem:windows /manifestuac:level= asinvoker  uiaccess= false  /manifestfile:win32\debug\eyegazedemo.exe.intermediate.manifest /errorreport:prompt /nologo /libpath:c:\opencv\build\x64\vc12\x64\vc11\lib /libpath:e:\qt\5.0.2\msvc2012_64\lib /libpath:e:\eyegaze\eyegaze\libraries\opencv\lib /libpath:e:\eyegaze\eyegaze\libraries\intraface\lib /libpath:e:\eyegaze\eyegaze\eyegazedemo /libpath:c:\opencv\build\x64\vc12\lib /tlbid:1 you will need to know the location of the .lib file and then you will need to add it into your project configurations it will be very similar to if you were adding a directx library reference boost etc i found the following post which shows  how to add additional libraries   you will also want to make sure you  apply  the changes to all builds so that you are covered for release debug etc  remove all references to the library somewhere that project is pointing at the path you give above and you need to remove that   then add the library into the executable project right click->add->existing item change the type to all files then browse to the file location,21,0.8675928638011612,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
32324499_so,.net azure bigdata hadoop hdinsight storage using hdinsight hadoop i am pretty much curious to know one information about hadoop hdinsight  this article from microsoft   https://azure.microsoft.com/en-us/documentation/articles/hdinsight-hadoop-use-blob-storage/   explains that hadoop internally uses storage account for storing the data  assuming the above information to be the approach  then whats the difference between hadoop and storage account.if i want to just store the information like files etc i can just make use of storage account only instead of creating hdinsight hadoop?also if hadoop   hadoopcluster   uses storage account   stgaccount   does that mean that storage account   stgaccount   space and   hadoopcluster   space are same  basically in a hdinsight deployment you have two parts   the hdinsight cluster which is made of multiple head and worker nodes virtual machines where the software is running  the azure blob storage where you store data   the azure blob storage is a safe distributed storage for you data you can use it whether you use hdinsight or not this is just a cloud storage with its own pricing so if yo just want to store files in the cloud you definitely do not need hdinsight  the hdinsight cluster is not actually you will see that whatever you store for example on the disks of the head node directly will disappear once in a while  the hdinsight cluster has access to the storage you ve specified when creating the cluster and can read/write data to this storage  just to add to benohead s response you can either use  azure blob store  as the storage or the newly released  azure data lake store  adls - which is a highly scalable and performant store for big data workloads since hdinsight separates compute from storage it is possible to use the vms for compute and either azure blog or adls for storage you can use azure blob or adls without using the compute provided by hdinsight,15,0.8673867267742784,"0.033*""gpu"" + 0.030*""memory"" + 0.027*""run"" + 0.016*""time"" + 0.012*""cpu"" + 0.011*""machine"" + 0.010*""process"" + 0.009*""gb"" + 0.009*""size"" + 0.009*""datum"""
57786660_so,"data-analysis machine-learning pandas preprocessor python preprocessing dataset with large categorical variables i have tried to find out basic answers for this question but none on stack overflow seems a best fit   i have a dataset with 40 columns and 55,000 rows only 8 out of these columns are numerical the remaining 32 are categorical with string values in each  now i wish to do an exploratory data analysis for a predictive model and i need to drop certain irrelevant columns that do not show high correlation with the target variable to predict but since all of these 32 variables are categorical what can i do to see their relevance with the target variable?  what i am thinking to try    labelencoding all 32 columns then run a dimensional reduction via pca and then create a predictive model if i do this then how can i clean my data by removing the irrelevant columns that have low corr with target?    one hot encoding all 32 columns and directly run a predictive model on it if i do this then the concept of cleaning data is lost totally and the number of columns will skyrocket and the model will consider all relevant and irrelevant variables for its prediction!     what should be the best practice in such a situation to make a predictive model in the end where you have many categorical columns you can have a look if your categorical variables are suitable for a spearman rank correlation which ranks the categorical variables and calculates the correlation coefficient however be careful for collinearity between the categorical variables",2,0.8673665830912459,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
54772309_so,gradient-descent linear-regression machine-learning gradient descent cost function explosion i am writing this code for linear regression and trying gradient descent to minimize the rss the cost function seems to explode to infinity within 12 iterations i know this is not supposed to happen maybe i have used the wrong gradient function for rss can be seen in the function grad?   please help ,3,0.8665288061678533,"0.054*""function"" + 0.040*""loss"" + 0.022*""gradient"" + 0.022*""weight"" + 0.016*""learn"" + 0.016*""parameter"" + 0.012*""learning"" + 0.011*""rate"" + 0.011*""update"" + 0.010*""cost"""
89862_kg,def fashionably_latearrivals name:    given an ordered list of arrivals to the party and a name return whether the guest with that    name was fashionably late.        list_len=lenarrivals    if list_len % 2 == 0:         order = arrivals[intlist_len / 2:list_len - 1]    else:        order = arrivals[intlist_len / 2 + 1:list_len - 1]    return name in order,19,0.8662194367406065,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
61004_kg,if we have a large number of features is it any other way we can use backward elimination? since it would be tedious to eliminate a feature after each step    @akkibansal     i agree with your observations  i have the same observation   i use other methods to eliminate variables before i use backward elimination for instance  i use **correlation **matrix to eliminate numerical  variables which does not have correlation with a target variable,2,0.8661416029099652,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
59343843_so,"conv-neural-network keras machine-learning neural-network tensorflow how to compute number of weights of cnn how can we compute number of weights considering a convolutional neural network that is used to classify images into two classes    input 100x100 gray-scale images  layer 1 convolutional layer with 60 7x7 convolutional filters stride=1 validpadding  layer 2 convolutional layer with 100 5x5 convolutional filters stride=1 validpadding  layer 3 a max pooling layer that down-samples layer 2 by a factor of 4 e.g from 500x500 to 250x250  layer 4 dense layer with 250 units  layer 5 dense layer with 200 units  layer 6 single output unit   assume the existence of biases in each layer moreover pooling layer has a weight similar to alexnet  how many weights does this network have?  some keras code tl;dr - for tensorflow + keras  use   -  link  to documentation   example usage    the output for your architecture is     that s 50,828,751 parameters  explanation  number of weights in a 2d convolutional layer  for a 2d convolutional layer having       filters  a filter size of    and a bias parameter per filter     the number of weights is     e.g  layer 1 in your neural network has   60 filters  and a filter size of 7 * 7 * 1 notice that the number of channels 1 comes from the input image.     the number of weights in it is   which is    number of weights in a dense layer  for a dense layer having     neurons    neurons in the layer prior to it  and a bias parameter per neuron     the number of weights is     e.g  layer 5 in your neural network has   200 neurons  and the layer prior to it - layer 4 - has 250 neurons     the number of weights in it is   which is",11,0.8661298965202122,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
41774632_so,c++ compilation opencv opencv 3.2 file compilation how to compile c++ file opencv included using opencv 3.2 mingw and command window in windows 10 i do not want to use any softwares like codeblocks/vbasic/eclipse/netbeans try using cmake for generating the makefile and then use the same for make and build  following is a minimalisitic example of cmake wherein i was using opencv for clustering of pixels  you need to create a cmakelists.txt file and add the following things for more information on building you can check my github repo: https://github.com/anubhavrohatgi/imageprocessing.git,21,0.866064776565631,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
21819_kg,i have total 1000 rows in the training data set  i have around very little around 200 labeled data   i want to label rest 800 so that i can predict on test data set which contain another 500 data points.i know we should use semi supervised learning  how to start doing this ? i am using r    did you figure out how to do this?  i have the same  question,1,0.8656383294037471,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
56229547_so,conv-neural-network neural-network recurrent-neural-network receptive field size a convolutional neural network cnn has 3 consecutive 5×5 convolutional layers with a stride of 1 without pooling what is the size of the receptive field for a neuron  in the 3rdconvolutional layer ,11,0.865618011559109,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
54763549_so,android c# opencv xamarin xamarin.forms is it possible to instantiate a cascadeclassifier with an xml file downloaded from web i m using  xamarin.opencv.droid   i use  cascadeclassifier  and i have an xml file on an http server with the designated ip address  how is it possible to instantiate a  cascadeclassifier  with the content stream of the downloaded xml file?   https://github.com/naxam/opencv-android-binding ,21,0.8650824439472001,"0.060*""file"" + 0.032*""opencv"" + 0.026*""caffe"" + 0.017*""java"" + 0.016*""library"" + 0.014*""build"" + 0.012*""android"" + 0.009*""project"" + 0.009*""convert"" + 0.009*""find"""
81534_kg,if there was the adaptionspeed in the test data one could fit a model to 100% accuracy    you are supposed to predict adoptionspeed in the test set using a model trained on the train set   i believe that s the test set they are evaluating against if you want to test your models for overfitting you can do a train-test split on the training set i.e use a subset of the training set as your own test set   thanks i misunderstood the use of test_image folder   thanks but i wonder why it provides test_images here does it use to evaluate during the submission?   yes but is it not correct,1,0.8649967917647884,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
52128_kg,kindly anyone tell the input and target columns for this type   mohan i may not undestand your question do refer to the data description?   how do you calculate multicollinearity efficiently?   usually i will compute pearson correlation between every numerical variables there will be some variables have high correlation i will drop one of them   i get 4 pair variables that have more than 0.8 correlation coef why did you select these variables?    usually i will drop the one has lower corr with the dependant variable for example if independant variables a and b has 0.8 correlation a and dependant variable has corr 0.79 and b and dependant variable has corr 0.65 i will drop b   thanks a lot!   how do you deal with the categorical variables?   in this script i just create dummy variables for all nomial and oridinal variables not encoded as numbers i found that only a few variables are valuable for predicting the house price during my data explanatory analysis thus i only do this processing on categorical variables   great start for a novice,2,0.8645983055819312,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
29338872_so,machine-learning scikit-learn scikits svm scikit learn multi-class classification for support vector machines i want to know whether   supports multi-class classification by default or do we have to wrap it in    like according to  this part of the documentation      svc nusvc and  linearsvc  are classes capable of performing multi-class classification on a dataset      [...]      on the other hand  linearsvc  implements “one-vs-the-rest” multi-class strategy thus training n_class models if there are only two classes only one model is trained   so it supports multiclass classification by default,9,0.8643496876856009,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
58891269_so,confusion-matrix machine-learning roc roc-curve calculation of elements i know that the roc-curve is calculated from the true-positive-rate and the false-positive-rate   but the roc-curve has infinite elements on it s curve right? how is each element calculated? can someone explain this to me? where is each point coming from?   example   thanks in advance the values are calculated for all values of the threshold of the classifier  on the x axis you have the false positive rate for the given threshold fpr = fp / tn + fp where   fp are the number of false positive the elements predicted positive but which are negative  tn the number of true negative the elements predicted negative and are really negative  and fp the number of false positive the elements predicted positive but are negative   on the y axis you have the true positive rate for the given threshold tpr = tp / tp + fn where   tp are the number of true positive predicted positive and are indeed positive  fn the number of false negative predicted negative but are positive   you have not an infinite number of points in practice you are limited to the number of points of the dataset the rate dont change for some ranges of threshold,18,0.863921928761099,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
55420610_so,machine-learning python xgboost xgboost predict_proba  how to do the mapping between the probabilities and the labels i m trying to predict solve a multiclass classification using the xgboost algorithm however i do not know how does   works exactly in fact   generates a list of probabilities but i don t know to which class each probability is related  here is a simple example  this my train data   then when i try to predict probas for a new example   this will return something like this   my question is  what is the class that has the probability of 0.5 ? is it the class 2 or 3 or 0  it seems that you use the sklearn api of xgboost in this case the model has a dedicated attribute   that returns the classes that were learned by the model and the order of classes in the output array corresponds to the order of probabilities  here is an example with dummy data,9,0.8638822369650232,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
74733_kg,"i am trying to concat ngs data and kernel just keeps disconnecting every time  ngsdata1 = pd.read_csv../input/ngs-2016-reg-wk13-17.csvngsdata2 = pd.read_csv../input/ngs-2017-reg-wk1-6.csvngsdata3 = pd.read_csv../input/ngs-2017-reg-wk7-12.csvngsdata4 = pd.read_csv../input/ngs-2017-reg-wk13-17.csv  merge1 = pd.concat[ngsdata1,ngsdata2],axis=0,join=outermerge2 = pd.concat[merge1,ngsdata3],axis=0,join=outermerge3 = pd.concat[merge2,ngsdata4],axis=0,join=outeri am newbie to datascience any pointers are appreciated.tia",19,0.863724157465799,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
54332680_so,categorical-data imputation r random-forest survey multiple imputation in r using missforest on categorical variables i have survey dataset with nas in several columns therefore i decided to perform multiple imputation using the missforest package to impute the missing values this was not a problem however i noticed after checking my data that many of the imputed values are numeric with decimal values in columns that were previously factors   i assume that missforest requires the columns to be numeric it requires a data.matrix for x in order for it to perform imputation  the nrmse is quite good and the means of the columns with imputed values are similar to the columns with nas  i plan to use the dataset with the imputed values for a multilevel linear regresssion and would have converted the factor columns to numeric anyways  should these imputed values that are numeric with decimal places pose a problem i don t know your data or your code but missforest is definitely able to deal with mixed type data and does not automatically convert these   this is an example from the  missforest  manual,2,0.8636105317120739,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
70866_kg,"hi,i am trying to use crupdateable for multi target regression and i found the crupdateable  s default classifier is hoeffdingtree but when i call method as buildclassifier it gives me this error  weka.core.unsupportedattributetypeexception weka.classifiers.bayes.naivebayesupdateable cannot handle numeric class!  my code is here 👍crupdateable classifier = new crupdateable;hoeffdingtree ht = new hoeffdingtree;classifier.setclassifierht;classifier.buildclassifiertraininginstances  if the hoeffdingtree is not for regression why it is default classifier in crupdateable and if it is for regression why it doesn t work?  thanksmali",9,0.863477658613066,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
52917965_so,machine-learning matlab random-forest how can i determine the number of trees in random forest in matlab in matlab we train the random forest by using   method one of the parameters of this method is the number of trees i am using random forest for classification approach how can i determine the number of trees of random forest if you ve been training this model you should know the number of trees that used in the model because it must set as input for    anyway for the learned model like   you can use   to determine the number of trees  this is regression example based on  matlab documentation,9,0.8628490619538487,"0.062*""class"" + 0.037*""classification"" + 0.031*""classifier"" + 0.029*""label"" + 0.027*""machine"" + 0.021*""svm"" + 0.018*""scikit_learn"" + 0.018*""learning"" + 0.016*""model"" + 0.014*""learn"""
52703568_so,machine-learning text text-mining text mining to classify a text into categories i have a text related to a very specific topic i have  apriori  tags by me defined i would like to define how closely related the words from the text are to my tags  my initial idea was to use a vocabulary to identify all the synonyms of the tags and use a bag of word approach ,12,0.8625636560799352,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
113931_kg,"some questions regarding k fold validation cycles:1 should test data-points repeat in different test-train split dataset?to elaborate:data-points [1,2,3,4,5,6,7,8,9,0]now:cycle1 {test [1 2 3 4 5] train [6 7 8 9 0]}cycle2 {test [1 5 6 7 9] train [2 3 4 8 0]}cycle3 {test [0 6 8 9 5] train [1 2 3 7 4]}  here in train different train sets 0 2 3 7 ...etc these data points  are repeating is this a good practise? or depends upon dataset?   how many splits you should consider while doing k-fold validation for a dataset having n number of data points and k=5",1,0.8621458546841128,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
37789724_so,"gensim machine-learning nlp nltk semantics algorithm for sentence matching after calculating word similarity using nltk aim- user inputs a string i need to compare this input with sentence 1 and sentence 2 and find the maximum similarity with either of these sentences  current approach- i tokenize the input and both sentences find synonym sets of each token and compare maximum similarity by adding similarity for each token using nltk .path_similaritytoken1,token2  problem- if sentence 1 is short and sentence 2 is long with many tokens since i sum up individual similarities the similarity of sentence 2 with input is always more even if most of tokens of input match with sentence 1  one solution- i can divide the similarity of each sentence with length of sentence and hence i get similarity per token of sentence but this approach is too aggressive is there an industry standard approach for this ",12,0.8621366970865253,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
6581_kg,"presents = read.csv&quot;presents.csv&quot;   numpresents = nrowpresents  presentids = presents[,1] presentwidth = presents[,2] presentlength = presents[,3] presentheight = presents[,4]  presentvol = presentwidth*presentlength*presentheight minvol = minpresentvol maxvol = maxpresentvol   sleighwidth = 1000 sleighlength = 1000  xs = 1 ys = 1 zs = 1   lastrowidxs = rep0,1000 lastlayeridxs = rep0,1000  numinrow = 0 numinlayer = 0  presentcoords = data.framepresentid = rep0,numpresents x1 = rep0,numpresents y1 = rep0,numpresents z1 = rep0,numpresents x2 = rep0,numpresents y2 = rep0,numpresents z2 = rep0,numpresents x3 = rep0,numpresents y3 = rep0,numpresents z3 = rep0,numpresents x4 = rep0,numpresents y4 = rep0,numpresents z4 = rep0,numpresents x5 = rep0,numpresents y5 = rep0,numpresents z5 = rep0,numpresents x6 = rep0,numpresents y6 = rep0,numpresents z6 = rep0,numpresents x7 = rep0,numpresents y7 = rep0,numpresents z7 = rep0,numpresents x8 = rep0,numpresents y8 = rep0,numpresents z8 = rep0,numpresents  for i in 1:numpresents {  if xs + presentwidth[i] &gt sleighwidth + 1{ # exceeded allowable width ys = ys + maxpresentlength[lastrowidxs[1:numinrow]] # increment y to ensure no overlap xs = 1 numinrow = 1} else ifys + presentlength[i] &gt sleighlength + 1{ # exceeded allowable length zs = zs - maxpresentheight[lastlayeridxs[1:numinlayer]] # increment z to ensure no overlap xs = 1 ys = 1 numinlayer = 0} # fill present coordinate matrix presentcoords[i,1] = presentids[i] presentcoords[i,c2,8,14,20] = xs presentcoords[i,c5,11,17,23] = xs + presentwidth[i] - 1 presentcoords[i,c3,6,15,18] = ys presentcoords[i,c9,12,21,24] = ys + presentlength[i] - 1 presentcoords[i,c4,7,10,13] = zs presentcoords[i,c16,19,22,25] = zs - presentheight[i] + 1  # update location info xs = xs + presentwidth[i] numinrow = numinrow + 1 numinlayer = numinlayer + 1 lastrowidxs[numinrow] = presentids[i] lastlayeridxs[numinlayer] = presentids[i]  }  # we started at z = -1 and went downward need to shift so all z-values &gt;= 1 zcoords = presentcoords[,c4,7,10,13,16,19,22,25] minz = minpresentcoords$z1,presentcoords$z2,presentcoords$z3,presentcoords$z4,presentcoords$z5,presentcoords$z6,presentcoords$z7,presentcoords$z8 presentcoords[,c4,7,10,13,16,19,22,25] = zcoords - minz + 1   # evaluation metric abc &lt;- functionpresentcoords1{ presentscoords1 = presentcoords1[,c1,4,7,10,13,16,19,22,25] presentcoords1$maxz = maxpresentcoords1$z1,presentcoords1$z2,presentcoords1$z3,presentcoords1$z4,presentcoords1$z5,presentcoords1$z6,presentcoords1$z7,presentcoords1$z8 presentcoords1[withpresentcoords1 ordermaxz,presentid,] presentcoords1$presentorder = 1:nrowpresentcoords1 returnpresentcoords1 } abc1 &lt;- abcpresentcoords score &lt;- 2*maxabc1$maxz + sumabsabc1$presentid - abc1$presentorder paste&quot;evaluation metric score is &quot;,score  solution &lt;- abc1[,1:25]   write.csvsolution,file=&quot;output.csv&quot;,row.names=false   [quote=thakur raj anand;36092]   presents = read.csv&quot;presents.csv&quot;   numpresents = nrowpresents  presentids = presents[,1] presentwidth = presents[,2] presentlength = presents[,3] presentheight = presents[,4]  presentvol = presentwidth*presentlength*presentheight minvol = minpresentvol maxvol = maxpresentvol   sleighwidth = 1000 sleighlength = 1000  xs = 1 ys = 1 zs = 1   lastrowidxs = rep0,1000 lastlayeridxs = rep0,1000  numinrow = 0 numinlayer = 0  presentcoords = data.framepresentid = rep0,numpresents x1 = rep0,numpresents y1 = rep0,numpresents z1 = rep0,numpresents x2 = rep0,numpresents y2 = rep0,numpresents z2 = rep0,numpresents x3 = rep0,numpresents y3 = rep0,numpresents z3 = rep0,numpresents x4 = rep0,numpresents y4 = rep0,numpresents z4 = rep0,numpresents x5 = rep0,numpresents y5 = rep0,numpresents z5 = rep0,numpresents x6 = rep0,numpresents y6 = rep0,numpresents z6 = rep0,numpresents x7 = rep0,numpresents y7 = rep0,numpresents z7 = rep0,numpresents x8 = rep0,numpresents y8 = rep0,numpresents z8 = rep0,numpresents  for i in 1:numpresents {  if xs + presentwidth[i] &gt sleighwidth + 1{ # exceeded allowable width ys = ys + maxpresentlength[lastrowidxs[1:numinrow]] # increment y to ensure no overlap xs = 1 numinrow = 1} else ifys + presentlength[i] &gt sleighlength + 1{ # exceeded allowable length zs = zs - maxpresentheight[lastlayeridxs[1:numinlayer]] # increment z to ensure no overlap xs = 1 ys = 1 numinlayer = 0} # fill present coordinate matrix presentcoords[i,1] = presentids[i] presentcoords[i,c2,8,14,20] = xs presentcoords[i,c5,11,17,23] = xs + presentwidth[i] - 1 presentcoords[i,c3,6,15,18] = ys presentcoords[i,c9,12,21,24] = ys + presentlength[i] - 1 presentcoords[i,c4,7,10,13] = zs presentcoords[i,c16,19,22,25] = zs - presentheight[i] + 1  # update location info xs = xs + presentwidth[i] numinrow = numinrow + 1 numinlayer = numinlayer + 1 lastrowidxs[numinrow] = presentids[i] lastlayeridxs[numinlayer] = presentids[i]  }  # we started at z = -1 and went downward need to shift so all z-values &gt;= 1 zcoords = presentcoords[,c4,7,10,13,16,19,22,25] minz = minpresentcoords$z1,presentcoords$z2,presentcoords$z3,presentcoords$z4,presentcoords$z5,presentcoords$z6,presentcoords$z7,presentcoords$z8 presentcoords[,c4,7,10,13,16,19,22,25] = zcoords - minz + 1   # evaluation metric abc &lt;- functionpresentcoords1{ presentscoords1 = presentcoords1[,c1,4,7,10,13,16,19,22,25] presentcoords1$maxz = maxpresentcoords1$z1,presentcoords1$z2,presentcoords1$z3,presentcoords1$z4,presentcoords1$z5,presentcoords1$z6,presentcoords1$z7,presentcoords1$z8 presentcoords1[withpresentcoords1 ordermaxz,presentid,] presentcoords1$presentorder = 1:nrowpresentcoords1 returnpresentcoords1 } abc1 &lt;- abcpresentcoords score &lt;- 2*maxabc1$maxz + sumabsabc1$presentid - abc1$presentorder paste&quot;evaluation metric score is &quot;,score  solution &lt;- abc1[,1:25]   write.csvsolution,file=&quot;output.csv&quot;,row.names=false  [/quote]  &nbsp  what is the run time for this code?   [quote=shreyes;36103]  [quote=thakur raj anand;36092]   presents = read.csv&quot;presents.csv&quot;   numpresents = nrowpresents  presentids = presents[,1] presentwidth = presents[,2] presentlength = presents[,3] presentheight = presents[,4]  presentvol = presentwidth*presentlength*presentheight minvol = minpresentvol maxvol = maxpresentvol   sleighwidth = 1000 sleighlength = 1000  xs = 1 ys = 1 zs = 1   lastrowidxs = rep0,1000 lastlayeridxs = rep0,1000  numinrow = 0 numinlayer = 0  presentcoords = data.framepresentid = rep0,numpresents x1 = rep0,numpresents y1 = rep0,numpresents z1 = rep0,numpresents x2 = rep0,numpresents y2 = rep0,numpresents z2 = rep0,numpresents x3 = rep0,numpresents y3 = rep0,numpresents z3 = rep0,numpresents x4 = rep0,numpresents y4 = rep0,numpresents z4 = rep0,numpresents x5 = rep0,numpresents y5 = rep0,numpresents z5 = rep0,numpresents x6 = rep0,numpresents y6 = rep0,numpresents z6 = rep0,numpresents x7 = rep0,numpresents y7 = rep0,numpresents z7 = rep0,numpresents x8 = rep0,numpresents y8 = rep0,numpresents z8 = rep0,numpresents  for i in 1:numpresents {  if xs + presentwidth[i] &gt sleighwidth + 1{ # exceeded allowable width ys = ys + maxpresentlength[lastrowidxs[1:numinrow]] # increment y to ensure no overlap xs = 1 numinrow = 1} else ifys + presentlength[i] &gt sleighlength + 1{ # exceeded allowable length zs = zs - maxpresentheight[lastlayeridxs[1:numinlayer]] # increment z to ensure no overlap xs = 1 ys = 1 numinlayer = 0} # fill present coordinate matrix presentcoords[i,1] = presentids[i] presentcoords[i,c2,8,14,20] = xs presentcoords[i,c5,11,17,23] = xs + presentwidth[i] - 1 presentcoords[i,c3,6,15,18] = ys presentcoords[i,c9,12,21,24] = ys + presentlength[i] - 1 presentcoords[i,c4,7,10,13] = zs presentcoords[i,c16,19,22,25] = zs - presentheight[i] + 1  # update location info xs = xs + presentwidth[i] numinrow = numinrow + 1 numinlayer = numinlayer + 1 lastrowidxs[numinrow] = presentids[i] lastlayeridxs[numinlayer] = presentids[i]  }  # we started at z = -1 and went downward need to shift so all z-values &gt;= 1 zcoords = presentcoords[,c4,7,10,13,16,19,22,25] minz = minpresentcoords$z1,presentcoords$z2,presentcoords$z3,presentcoords$z4,presentcoords$z5,presentcoords$z6,presentcoords$z7,presentcoords$z8 presentcoords[,c4,7,10,13,16,19,22,25] = zcoords - minz + 1   # evaluation metric abc &lt;- functionpresentcoords1{ presentscoords1 = presentcoords1[,c1,4,7,10,13,16,19,22,25] presentcoords1$maxz = maxpresentcoords1$z1,presentcoords1$z2,presentcoords1$z3,presentcoords1$z4,presentcoords1$z5,presentcoords1$z6,presentcoords1$z7,presentcoords1$z8 presentcoords1[withpresentcoords1 ordermaxz,presentid,] presentcoords1$presentorder = 1:nrowpresentcoords1 returnpresentcoords1 } abc1 &lt;- abcpresentcoords score &lt;- 2*maxabc1$maxz + sumabsabc1$presentid - abc1$presentorder paste&quot;evaluation metric score is &quot;,score  solution &lt;- abc1[,1:25]   write.csvsolution,file=&quot;output.csv&quot;,row.names=false  [/quote]  &nbsp  what is the run time for this code?  [/quote]  i left that to the user as a case study : i tested code on 1000 items it was giving result similar to benchmark so i just shared it here frankly i am not planning to use r for this competition",19,0.8618341552260219,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
15480_kg,eeg are surely prone to be contaminated with  noise  i.e signals not related to brain activity this include emg from muscles attached to the cranium including facial muscles e.g as evident during eye blinking as well as eye movements the eyes are significant dipoles and eye movements therefore strongly affects eeg recordings in addition it s difficult to ensure stable electrode impedance and ambient electromagnetic noise   the data set contains noise of these kinds although elaborate precautions were take to minimize them including performing the recordings in a shielded room faraday cage and designing a task that required minimal head and torso movements in other words the signal quality of the data set - despite the  noise  - is superior to anything that can be expected under  real-life  scenarios e.g when riding a wheel chair   guocong song raised concerns regarding the sensor system system polhemus fastrak used for recording the 3d positions of the object the hand and the engaged digits polhemus uses a stationary signal source that generates short-lasting electromagnetic pulses @~10 khz alternating between 3 planes x y z at a rate of 120 hz in theory these pulses could be demodulated by eeg electrodes giving rise to  pulses  with 120 and 360 hz frequency probably needless to say no overt evidence of interference from the polhemus were observed during the experiments but it is possible that it was present in the recordings importantly the em source was stationary throughout the experiments and the fact that the sensors themselves were moving in space is of no consequence,10,0.861593202819697,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
42553650_so,caffe deep-learning machine-learning neural-network can we use concate layer for two different size of input images i am implement multiple scale input for my network   the scheme is very simple just use same network architecture but different image scale can i use   layer for that task? specially the layer prototxt will be ,11,0.8613735647975239,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
14796_kg,here is the output from the script  &gt file.sqlite = pastefolder &quot;database.sqlite&quot sep = &quot;&quot;  &gt db.sqlite = dbconnectsqlite dbname=file.sqlite  &gt dblisttablesdb.sqlite  [1] &quot;adsinfo&quot &quot;category&quot &quot;location&quot &quot;phonerequestsstream&quot &quot;searchinfo&quot &quot;userinfo&quot [7] &quot;visitsstream&quot &quot;testsearchstream&quot &quot;trainsearchstream&quot  &gt rs = dbsendquerydb.sqlite &quot;select * from adsinfo&quot;  &gt recordadsinfo = dbfetchrs 1 # fetch one record  &gt recordadsinfo adid locationid categoryid 1 1 343 43 params 1 {1283 &#1057 &#1087;&#1088;&#1086;&#1073;&#1077;&#1075;&#1086;&#1084  633 &#1057;&#1080;&#1085;&#1080;&#1081  1159:0 210 toyota  184 0 - 4 999  1162:0 1165:0 1135:0 1329 2.0  1138:0 277 estima  695 &#1055;&#1086;&#1083;&#1085;&#1099;&#1081  696 &#1087;&#1088;&#1072;&#1074;&#1099;&#1081  697 &#1053;&#1077 &#1073;&#1080;&#1090;&#1099;&#1081  186 &#1044;&#1080;&#1079;&#1077;&#1083;&#1100  187 &#1052;&#1080;&#1082;&#1088;&#1086;&#1072;&#1074;&#1090;&#1086;&#1073;&#1091;&#1089  188 1993  185 &#1052;&#1077;&#1093;&#1072;&#1085;&#1080;&#1082;&#1072 } price title iscontext 1 160000 toyota estima 1993 0  &gt dbgetinfors  $statement [1] &quot;select * from adsinfo&quot  $isselect [1] 1  $rowsaffected [1] -1  $rowcount [1] 1  $completed [1] 0  $fields name  sclass type len  1adid integer integer 4  2 locationid integer integer 4  3 categoryid integer integer 4  4 params character text na  5 price character text na  6 title character text na  7 iscontext integer integer 4  &gt dbclearresultrs  [1] true,19,0.8612089446056338,"0.044*""column"" + 0.044*""file"" + 0.032*""csv"" + 0.026*""row"" + 0.026*""datum"" + 0.017*""data"" + 0.013*""lt"" + 0.013*""_"" + 0.011*""read"" + 0.011*""table"""
46922_kg,hi i am doing some research on this datasets.i want to ask how can i get the evaluation of my results since i can t find the ground truth for the test set.thanks   hi there!  divide your dataset in 3 parts   training set60%  cross validation set20%  test set20%   or you may change the ratio according to your model but just make sure to keep the training set large enough and then  use the test set  to see if the model is performing well   are the labels of the test set available somewhere,1,0.8599932613025826,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
63615_kg,josh i enjoyed your script but i have some questions about the way you approached the training/validation/test data   instead of keeping the test data entirely separate as your unseen data in order to subsequently check the generalisation ability of your model it seems to me that you merged the training and test data and then created a validation set out of that combined data   but now you don t have anything to test your model on at the end and are left just taking it on faith that your validation accuracy is a good representation of the model s ability to generalise why would you expect that to be the case? weren t you just using that validation set to optimise your hyperparameters?    hi andrew  thank you for reading my kernel  i actually first combined all the available data then randomly split it into a training and test set see step one the training set consists of 2/3 of the total data and the test 1/3 i did it this way to customize my training to test set size ratio  the hyperparameters were trained using the training set and the models accuracy was tested on the test set note these two sets were randomly generated from the total data,1,0.8593730363854992,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
103892_kg,@higgstachyon   why have you used test dataset for validation we shouldn t expose the test dataset while training the model we should create a validation data from training data and use it to tune the hyperparameters and only use test set after we have finished training the model using the test data as validation data may result in overfitting and may give good performance during evaluatiion right??,1,0.8591021177586571,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
138987_kg,hello i am working through the second exercise i initially solved the problem on my own but kept arriving at an incorrect solution however when i copy and pasted the provided solutions i still received an incorrect solution here is the code i used      zero_pollution_query =                          select *                         from                           where value = 0                           safe_config = bigquery.queryjobconfigmaximum_bytes_billed=10**10  query_job = client.queryzero_pollution_query job_config=safe_config  zero_pollution_results = query_job.to_dataframe   which gives an output of  incorrect the results don t look right try again   hi i have the same problem as you have you slove this problem?   same problem,0,0.8589041986722623,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
9969599_so,gensim lda machine-learning how to use gensim for lda on news articles i m trying to retrieve list of topics from a large corpus of news articles i m planning to use gensim to extract a topic distribution for each document using lda i want to know the format of processed articles required by gensim implementation of lda and how to convert raw articles to that format i saw this link about using lda on wikipedia dump but i found the corpus to be in a processed state whose format was not mentioned anywhere i don t know if i got the problem right but gensim supports multiple corpora you can find a list of them  here    if you want to  process natural language you have to tokenize the text first you can follow the step-by-step tutorial on the gensim website  here  it s explained pretty well  there is an offline learning step and an online feature creation step   offline learning   assume you have a big corpus such as wikipedia or downloaded a bunch of news articles  for each article/document   you get the raw text  you lemmatize it gensim has utils.lemmatize  you create a dictionary   you create a bag of word representation   then you train the tf-idf model and convert the whole corpus to the tf-idf space.finally you train the lda model on the tf-idf corpus   online   with an incoming news article you do almost the same   lemmatize it  create a bag of word representaiton using the dictionary  convert it to tf-idf space using the tf-idf model  convert it to lda space,12,0.858765788920516,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
29121_kg,"hello all,can anyone please help and explain the evaluation formula i was able to calculate r^2 but could not understand how to calculate r there is   sign   written in the formula what does it mean?thanks   the r² could be negative or positive so the r is the sqrtabsr² * sign of r²   r^2 may be negative by its definition and we want to set the same plus-minus signs to r and r^2 so there is signr^2 in the formula of r",18,0.8586620604431137,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
39391_kg,"hey levgen   regarding your remark more than 2/3 of experiments had bad grasp result also for cases with less than 11 measurements most grasps were bad it may be the result of dropping an object completely and thus stop of the measurement process  yes when i check the stability i stop the experiment if the distance is too big basically if the ball fell from the hand while moving the arm so those bad experiments are stopped short   hi ugo   thanks for additional explanations   i ve changed the chart now it provides more insight my suggestion is experiment can be stopped early if desired robustness is achieved am i right here?  also it is interesting that there are experiments with less than 30 measurements and robustness slightly less than 100 why were they stopped? did they have chance to gain &gt;= 100 robustness before measurement 30?  best,ievgen",10,0.8585759802210815,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
116574_kg,doesn t surprise me that takedown attempts is so critical considering most fights in which the dominant opponent is a strong wrestler usually results in him pinning the other guy down resulting in a unanimous decision win   @rapiddev i agree about the take-down attempts and figured it would be high but i m surprised that take-down defense didn t have more impact because of it,10,0.8581799016185911,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
56935501_so,categorical-data imputation r random-forest how to use both categorical and continuous predictors in a multiple imputation [r i have a large dataset of a couple of categorical nominal variables and a number of continuous variables most of the continuous variables have missing data  i have been using the mice package pmm and rf to impute the missing data however i realised that the method is ignoring the categorical data the categorical data could be useful for prediction   therefore i am looking for a multiple imputation code ideally random forest because there is a large share of missing data in r which allows considers both continuous and categorical predictors to impute multiple continuous variables it turns out i needed to convert my categorical variables into vectors,2,0.857823449141988,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
56519276_so,python random-forest using random forest for feature selection - dealing with correlated variables i would like to know how to deal with correlated variables when building a random forest for feature selection  so i need to do some feature selection on different datasets that contain categorical and continuous variables i m a bit lost here because the most obvious correlation measure is the pearson s correlation coeff that works for continuous variables but what about categorical variables  would the following approach work if i wanted to do a good feature selection using rf   do some kind of feature selection on the continuous variables independently of the categorical variables by using any of the techniques described in this article   https://machinelearningmastery.com/an-introduction-to-feature-selection/   from what i understand univariate selection rfe or pca are only valid for continuous variables i doubt transforming a categorical by one hot encoding and then doing these techniques would be benefical  once the continuous variables are chosen create the random forest which would give uncorrelated variables  however can categorical variables be correlated ? if yes would doing a chi-square test on only categorical variables be useful  in the end would combining the results from the feature selection on continuous variables + chi-square test on cat variables be a good solution ?  thank you for your help i m new to feature selection  ,2,0.8577150413612401,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
56518367_so,c++ conv-neural-network deep-learning conv2d vs depthwise conv2d calculation i am trying to understand the similarities/differences in the calculation of 2d convolutional and 2d depthwise convolutional neural networks i understand the concepts   for example say there is an input image that is 3x3 with 3 channels rgb and padding of 1 and stride of 1 the filter is 2x2   what is the output? can disregard activation and bias  i know that regular conv2d will have 1 3x3 output whereas dw conv2d will have 3 beyond that i am a little confused thanks ,11,0.8576133829258927,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
56725_kg,i am using keras with a tensorflow backend i am training a cnn with vgg19 pre-trained weights i have freezed 29 layers of cnn while training while training a cnn i am using image input shape as 150x150 my training parameters are as batch size = 8 epoch = 15 optimizer = adadelta  for such settings training accuracy and validation accuracy is not changing but if i change my input image resolution from 150 to 224 or any other resolution the training curve does change,13,0.8570920014531735,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
5121_kg,the harmonic features for phase 1 and 2 are listed as the fundamental and 5 harmonics for the i and v measurements for the two phases of the circuit am i to take that to mean it s a measurement of the signal at 60 120 180 240 300 360 hz?  i read elsewhere that the sampling rate for the fft was 2 mhz that gives bin spacing of ~244hz that basically means the harmonic features are only affecting the 1st 2 or so bins of the fft?&nbsp   yes for the current measurements the 6 values are the fundamental and first 5 harmonics of the current measurement  the fft and 2 mhz that you are referring to are measured in voltage domain and have nothing in this context to do with the 60hz current harmonics this is explained in the competition description as evident by the figure and also the paper referenced as [3] i highly recommend&nbsp;going over that literature to develop an intuition of what these various feature are  sidhant,10,0.8565355771591179,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
24136_kg,hi  i would like to ask if the signals were procesed to remove ac mains interference? if not could we know what the ac mains frequency is in the country where the recordings were made?   [quote=michal;137970]  hi  i would like to ask if the signals were procesed to remove ac mains interference? if not could we know what the ac mains frequency is in the country where the recordings were made?  [/quote]    this removes the dc but i was asking about ac mains :   if i m not mistaken these are implants so unless the subjects spend most of the time resting their head on electric devices there presumably is no ac signal to remove?   line noise should be minimal you could check though line noise is at 50 hz in australia where the data was recorded   it depends a good design of a differential amplifier that doesn t degrade its cmrr would probably have minimal power line noise it s especially important for high gain amplifiers like for eeg to remove power line noise by a differential amplifier or by adding a notch filter hardware still you never know there might be some residual there   i m confused now &quot;should be minimal&quot sounds like there is still reasonable chance of line noise at what point in the processing does the power line come in?   from bits on neurovista found on google i assumed that the signal must be amplified and digitized in the chest part of the implant - so no ac line involved prior to digitization at all right?    it s as you say the device is fully implanted and battery powered therefore 50 hz mains noise is unlikely to show up unless the electrodes/implant are near very strong electromagnetic sources i have now swept through all data files looking for 50 hz noise and nothing stands out that should be processed or filtered out the common average referencing and other electronic aspects used by the implant were designed to mitigate 50 hz noise the device did not implement a notch filter to remove 50 hz content    thanks a lot levin :,10,0.8564387408683332,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
58187132_so,r r-caret random-forest multi-level feature importance of random forest with caret in r i am using r package caret to carry out random forest for this package it separate a factor predictor with more than two levels to more than one variables  so does the variable importance got from function varimp  is there any way i can combine different different levels into one variable? or how can i combine on my own? my instinct is to calculate the sum of the importance of different levels but i am not sure ,2,0.855942540397472,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
12046213_so,algorithm document-classification feature-extraction machine-learning document features vector representation i am building a document classifier to categorize documents  so first step is to represent each documents as features vector for the training purpose  after some research i found that i can use either the bag of words approach or n-gram approach to represent a document as a vector  the text in each document scanned pdfs and images is retrieved using an ocr thus some words contain errors and i don t have previous knowledge about the language used in these documents can t use stemming   so as far as i understand i have to use the n-gram approach or are there other approaches to represent a document ?    i would also appreciate if someone could link me to an n-gram guide in order to have a clearer picture and understand how it works   thanks in advance use  language detection  to get document s language my favorite tool is  languageidentifier  from tika project but many others are available   use  spell correction  see  this question  for some details    stem  words if you work in java environment  lucene  is your choice    collect  all  n-grams  see below   make  instances  for classification by extracting n-grams from particular documents    build classifier     n-gram models  n-grams are just sequences of n items in classification by topic you normally use n-grams of words or their roots though there are models based on n-grams of chars most popular n-grams are unigrams just word bigrams 2 serial words and trigrams 3 serial words so from sentence      hello my name is frank   you should get following unigrams      [hello my name is frank] or [hello i name be frank] if you use roots   following bigrams      [hello_my my_name name_is is_frank]   and so on   at the end your feature vector should have as much positions dimensions as there are words in all your text  plus 1 for unknown words  every position in instance vector should somehow reflect number of corresponding words in instance text this may be  number of occurrences   binary feature  1 if word occurs 0 otherwise  normalized feature  or   tf-idf   very popular in classification by topic   classification process itself is the same as for any other domain,12,0.8547946510798621,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
3153_kg,i always hear about how difficult it would be to produce life else where in the universe due to the differences between our planet s situation as oppose to others &nbsp;life can not exist because there is no water and all the right possibilities are not in tact but my question is how do we know that these other life forms do not live off the nature in other planets? for example instead of breathing oxygen the different organisms simply use other gases   perfectly valid point in my opinion i often think the same thing myself i understand that life doesn t necessarily need water to occur it just needs some liquid medium for the chemical reactions essential for life to occur in  &nbsp  also on this planet we are all carbon based lifeforms but there could also be silicon based lifeforms on other worlds in the universe  &nbsp  i once watched a documentary on the discovery channel about a scientist who based on the number of stars and planets in space predicted there were 1000 different intelligent civilizations living on other worlds,10,0.8547939747909408,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
58296610_so,deep-learning keras vgg-net why training vgg16 cnn with images from scratch doesn t show up convergence i m training the vgg16 cnn model with the imagenet weights there is no convergence when training the model from scratch i have used a saved model after one epoch from another machine and started training on top of that what could be the issue?            what could be the actual reason ,13,0.8547777112818691,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
52647799_so,r random-forest tree read categorical value split in random forest in r i have a dataset which contains various categorical variables and no numeric variable i converted the variables to ordered factors by   now i am making a random forest model and then making a tree using below code   i get the tree something like below   and so on...  ask  both my split var are ordered factor categorical variables now how do i interpret split point as 1.5 or 2.5 i can t say the split is between two groups  to explain it further lets say   is gender with levels as   or   and   is   with levels as         now to explain it to stakeholders i can t say when the  gender is between male and female and the weight is between medium to high    can someone help me in how to explain rf tree when dealing with categorical variable ,2,0.8544823142153616,"0.097*""feature"" + 0.046*""variable"" + 0.034*""model"" + 0.024*""datum"" + 0.017*""column"" + 0.016*""categorical"" + 0.014*""regression"" + 0.009*""target"" + 0.009*""miss"" + 0.008*""data"""
17953189_so,distribution excel excel-formula normal-distribution statistics normdist function is not giving the correct output i m trying to use   function in excel to create a bell curve but the output is strange   my  mean  is   and  standard deviation  is   so when i plug this to the function    i expect to get something close to   as i m using the same value as the mean probability of this value should be   but the function gives an output of   which is clearly not correct   why is it like this a probability cannot have values greater than 1 but a density can  the integral of the entire range of a density function is equal 1 but it can have values greater than one in specific interval  example  a uniform distribution on the interval [0 ½] has probability density fx = 2 for 0 ≤ x ≤ ½ and fx = 0 elsewhere see below:      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp             returns the density function densities are probabilities per unit it is almost the probability of a point but with a very tiny range interval the derivative in the point  shg s answer  here  explain how to get a probability on a given interval with normidist and also in what occasions it can return a density greater than 1     for a continuous variable the probability of any particular value is zero because there are an infinite number of values      if you want to know the probability that a continuous random variable with a normal distribution falls in the range of a to b use      =normdistb mean dev true - normdista mean dev true      the peak value of the density function occurs at the mean i.e =normdistmean mean dev false  and the value is      =1/sqrt2*pi*dev      the peak value will exceed 1 when the deviation is less than 1 / sqrt2pi ~ 0.399   which was your case  this is an amazing  answer  on cross validated stack exchange statistics from a moderator whuber that addresses this issue very thoughtfully  it is returning the probability density function whereas i think you want the cumulative distribution function so try true in place of false  ref,18,0.8537238788810092,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
50168057_so,computer-vision convolutional-neural-network deep-learning neural-network why the depth of kernel of first convolutional layer is 48 in alexnet in alexnet the filter size is   in first layer and   in second layer  why 48 and 128 are used as depth? can we change both to different numbers?       thanks the depiction of neural network there could be confusing for some actually layer with 48 dimensions specifically 5 * 5 * 48 dimensions is the second convolutional layer from the  article       ..the second convolutional layer takes as input the response-normalized  and pooled output of the first convolutional layer and filters it with 256 kernels of size 5 × 5 × 48   i assumed though your confusion stem from the first layer was described as 11 * 11 * 96 dimensions but depiction in the image was not in case you are asking why did the authors chose such size is still something varies in scientific community as about deciding the parameters of a neural network is somewhat done by intuition at least by this time,11,0.8534019534235127,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
7238_kg,i m having trouble conceptualizing the relation between fluorescence and an individual action potential.&nbsp since the time interval is 20 ms we re potentially capturing multiple action potentials per observation  is a dramatic increase in fluorescence over a period of several observations representative of bursting activity?&nbsp   hi sorry for delay in the answer!  you correctly pointed out an important problem the time resolution of calcium imaging is bad&#8230 or to be more correct it could be made better but then the signal-to-noise ration would deteriorate so it is not clear whether it would be an advantage or not  the simulated fluorescence signal we provide is compliant with nowadays standards for typical labs some labs can do much better but this is not the rule  the bad time resolution means of course that many spiking events might be confounded however the signal itself is also passing through some saturating non-linearity so the growth of fluorescence is bounded this creates an additional complication btw because you cannot expect perfect proportionality between number of spikes and observed signal  in summary it is a mess but that s current life and you have to cope with that..  i hope this comments clarify things   and a small follow-up comment bursting tends to synchronize over many neurons so you can detect it by looking at matching events of firing over larger subsets of cells.&nbsp  but careful! during bursts firing together doesn t mean necessarily being connected cf discussions on state selection in&nbsp stetter et al 2012  so you need to be clever if you want to exploit bursts for inferring structural rather than mere functional connectivity..   [quote=salviati;39923]  however the signal itself is also passing through some saturating non-linearity so the growth of fluorescence is bounded this creates an additional complication btw because you cannot expect perfect proportionality between number of spikes and observed signal  [/quote]  does this imply that if a majority/enough of the neurons fire simultaneously due to synchronization the fluorescence from this event will saturate the measurement field and a spike in fluorescence will be measured on all/most channels even if some of the neurons did not actually fire? if this is the case then is it not true that the proximity of a given neuron to this group firing event or any firing nearby would affect the level of fluorescence measured for that neuron? it is not clear to me whether space dependent scattering effects are included in the simulated data  i also wanted to see how others interpret variability in the magnitude of measured spikes the network-wide events described above seem to have the greatest magnitude presumably due to a superposition of scattered fluorescence? between those events there are smaller less synchronized spikes of varying magnitude is this variability an artifact of the measurement method alone or is there any biological significance to this occurrence?  as a specific case for discussion that piqued my interest in the lowcon set neuron #73 has only one incoming connection possibly a significant fact with an iaf neuron model dictating behavior and its fluorescence data is unlike other neurons fluorescence activity is still measured but at a much lower/degraded level that still correlates with network-wide firing events are these degraded fluorescence events inherent to this neuron s firing activity or could it be scattered fluorescence from nearby?  i am trying to develop a better intuition for this problem and hope that any responses will be of aid to others  thank you,10,0.8527928466521093,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
50651996_so,keras multi-gpu python tensorflow keras fine-tuning a pre-trained model does not change weights when using multi_gpu_model and layers.trainable = true i m loading the vgg16 pretrained model adding a couple of dense layers and fine tuning the last 5 layers of the base vgg16 i m training my model on mutliple gpus i saved the model before and after training the weights are the same inspite of having layers.trainable = true   please help!  heres the code   weights in before_training and after_training models are the same!!! which is not what i expected ,13,0.8524137796909704,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
110322_kg,hi everyone  i have certain dataset to train a model the dataset is not very small in size first i split the dataset into training and validation data using train_test_split 80-20 train the model on training data and test on validation data get an accuracy of 85% later i take the full dataset and use 5-fold cross-validation to get mean score accuracy which comes out to be 68% why? any help would be appreciated,1,0.8509013447418498,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
121380_kg,"hi.is it correct way to use loglabel for calcalate metrics?i think  if calculate  score as function [y -test-true  expy-test-predict ]  then result will be other   yes,it will give different answer but as we have used loglabel so we will use log value only",18,0.8508818010365529,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
32293606_so,machine-learning matlab neural-network matlab neural network weights in matlab i ran the neural networks toolbox and received weights titled the following   what part of the neural network are these weights referring to? i m assuming b1 and b2 are the biases and iw1_1 and lw2_2 are the weights but what part of the network is iw1_1 for and lw2_2 for iw1_1 is the weights between the input and hidden layers and lw2_2 is between the hidden and output layers,11,0.8508234090255928,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
48009532_so,gensim machine-learning nlp word2vec word embedding for oov words i have generated word vectors from a corpus but i am facing out of vocabulary issues for many words how can i generate word vectors for oov words on the fly using existing word embedding a very late answer not even the answer you are looking for but with   models what you ask is almost impossible because each word is a distinct entity in and of itself  the feature you ask can be done with  fasttext  out of the box it generates oov word vectors using it s  s  gensim has a high-level  api  to use fasttext,12,0.849949855867857,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
59107747_so,machine-learning model validation is the validation set part of training set in machine learning we use validation set to tune the hyperparameters but i am confused about the origin of the validation set is it part of the training set? that would mean the model has seen the data before or is it like test set i.e data that the model has never seen before? i am really really confused you should split training data into two parts one for training and one for validation as you mentioned  you train your data on the first part while setting hyperparameters according to score on validation usually 80%-20% split is used other values may be fine depending on the amount of data you have  for final assessment of your algorithm use another separate testing set which wasn t incorporated in either training nor hyperparameters search,1,0.8490001488268742,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
50692494_so,convolutional-neural-network keras resnet tensorflow transfer-learning resnet50 predicts all the images to be of the same class i have experimented with a number of models available in keras on my dataset it is a 10-class image classification problem i have tried training from scratch fine-tuning the whole network and transfer learning with each architecture most of them perform quite well on my dataset except transfer learning with resnet50 here is the model i am using      all the images have already been resized to 224 x 224 pixel size i have tried adam optimizer with various learning rates and batch sizes like     but still the model predicts all the images to be of the same class and to be specific the class which contains 26% of all the images while training the training loss reduces and the validation loss seems to increase the training accuracy is above 95% at the end of training but the validation accuracy is stuck at 26% when the same model resnet50 is trained from scratch or fine-tuned this problem doesn t exist the models with no skip connection such as inceptionv3 xception vgg16 show good performance all the time whether training from scratch fine-tuning or transfer learning is used the other models using skip connections inceptionresnetv2 densenet don t predict all the images to be of the same class when transfer learning is used but the accuracy is a bit lower compared to no skip connection models again these models inceptionresnetv2 densenet show good performance when training from scratch or fine-tuning is used   so my question is      is there something with the skip connection which is hurting the performance of the model when transfer learning is used?   i am using keras with tensorflow backend ,13,0.8480111883043359,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
58671017_so,"conv-neural-network vgg-net how do we determine the value of channel in neural networks here s a network from vgg16  layer type                 output shape              param #  input_1 inputlayer         none 150 150 3       0            block1_conv1 conv2d        none 150 150 64      1792         block1_conv2 conv2d        none 150 150 64      36928        block1_pool maxpooling2d   none 75 75 64        0            block2_conv1 conv2d        none 75 75 128       73856        block2_conv2 conv2d        none 75 75 128       147584       block2_pool maxpooling2d   none 37 37 128       0            block3_conv1 conv2d        none 37 37 256       295168       block3_conv2 conv2d        none 37 37 256       590080       block3_conv3 conv2d        none 37 37 256       590080       block3_pool maxpooling2d   none 18 18 256       0            block4_conv1 conv2d        none 18 18 512       1180160      block4_conv2 conv2d        none 18 18 512       2359808      block4_conv3 conv2d        none 18 18 512       2359808      block4_pool maxpooling2d   none 9 9 512         0            block5_conv1 conv2d        none 9 9 512         2359808      block5_conv2 conv2d        none 9 9 512         2359808      block5_conv3 conv2d        none 9 9 512         2359808      block5_pool maxpooling2d   none 4 4 512         0  how do i determine the value of channel in neural networks?such as 64,128,256 and 512?thanks for your help ",11,0.8479354478161784,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
54831_kg,"how do i get imagedatagenerator / train_datagen.flow_from_directory to accept a 4-channel image? i use keras 2.1.5 with tensorflow backend on windows 10  please can anyone help me?  the code is  import keras  import os  train_clas1_dir= c:/dir1/train/class1   train_clas2_dir= c:/dir1/train/class2   test_clas1_dir= c:/dir1/test/class1   test_clas2_dir= c:/dir1/test/class2   validation_clas1= c:/dir1/validation/class1   validation_clas2_dir= c:/dir1/validation/class2   train_dir= c:/dir1/train   test_dir= c:/dir1/test   validation_dir= c:/dir1/validation   print total training clas1 images  lenos.listdirtrain_clas1_dir  print total training clas2 images  lenos.listdirtrain_clas2_dir  print total test clas1 images  lenos.listdirtest_clas1_dir  print total test clas2 images  lenos.listdirtest_clas2_dir  print total validation clas1 images  lenos.listdirvalidation_clas1_dir  print total validation clas2 images  lenos.listdirvalidation_clas2_dir  from keras.models import model sequential  from keras.layers import input dense dropout flatten activation  from keras.layers import conv2d convolution2d maxpooling2d  from keras.layers.convolutional import zeropadding2d  from keras.layers.normalization import batchnormalization  import matplotlib.pyplot as plt  from keras.preprocessing.image import imagedatagenerator  nb_train_samples=lenos.listdirtrain_clas1_dir+lenos.listdirtrain_clas2_dir  epochs=1  nb_validation_samples=lenos.listdirvalidation_clas1_dir+lenos.listdirvalidation_clas2_dir  batch_size=100  dropout = 0.5  model_input = inputshape = 227 227 4  z = conv2dfilters = 96 kernel_size = 11,11 strides = 4,4 activation = relumodel_input  z = maxpooling2dpool_size = 3,3 strides=2,2z  z = flattenz  z = dense4096 activation=reluz  z = dropoutdropoutz  model_output = dense2 activation= softmax z  model = modelmodel_input model_output  model.summary  train_datagen = imagedatageneratorrescale=1./255  test_datagen = imagedatageneratorrescale=1./255  validation_datagen = imagedatageneratorrescale=1./255  printtrain_generator  train_generator = train_datagen.flow_from_directory        train_dir,        target_size=227 227,        batch_size=batch_size,        class_mode= categorical   printtest_generator  test_generator = test_datagen.flow_from_directory        test_dir,        target_size=227 227,        batch_size=batch_size,        class_mode= categorical   printvalidation_generator  validation_generator = validation_datagen.flow_from_directory        validation_dir,        target_size=227 227,        batch_size=batch_size,        class_mode= categorical   for data_batch labels_batch in train_generator   from keras.optimizers import sgd  sgd = sgdlr=0.001 decay=1e-6 momentum=0.9 nesterov=true   model.compileloss= categorical_crossentropy  optimizer=sgd metrics=[ accuracy ]  from keras.callbacks import earlystopping modelcheckpoint callback csvlogger reducelronplateauclass losshistorycallback   checkpointer = modelcheckpoint pedestre_pedestrenao.h5  verbose=1 monitor= val_acc  mode= max  save_best_only=true save_weights_only=false  printfit_generator  csv_logger = csvlogger log.csv  append=true separator=    history = losshistory  results_train = model.fit_generator      train_generator,      steps_per_epoch=nb_train_samples // batch_size,      epochs=epochs,      validation_data=validation_generator,      validation_steps=nb_validation_samples // batch_size,      callbacks=[history checkpointer csv_logger],      verbose=2 # reduce_lr earlystopper  printresults_train.history  acc = results_train.history[ acc ]  val_acc = results_train.history[ val_acc ]  loss = results_train.history[ loss ]  val_loss = results_train.history[ val_loss ]  epochs = rangelenacc  plt.plotepochs acc  bo  label= training acc   plt.plotepochs val_acc  b  label= validation acc   plt.title training and validation accuracy   plt.legend  plt.figure  plt.plotepochs loss  bo  label= training loss   plt.plotepochs val_loss  b  label= validation loss   plt.title training and validation loss   plt.legend  plt.show  printsaved model and weights  model.save pedestre_pedestrenao_model.h5   model.save_weights pedestre_pedestrenao_weights.h5   model.load_weightspedestre_pedestrenao_weights.h5",13,0.846594862306041,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
47933601_so,deep-learning machine-learning what does non-linearity of deep neural networks means when we say non-linearity of deep neural networks what do we actually mean by the term non-linearity in this context ?  also the purpose of the activation function is to introduce non-linearity into the network what does this non-linearity means ?i am new to deep learning non-linear means that the output cannot be reproduced from a linear combination of the inputs which is not the same as output that renders to a straight line--the word for this is affine  another way to think of it without a non-linear activation function in the network a nn no matter how many layers it had would behave just like a single-layer perceptron because summing these layers would give you just another linear function see definition just above   source,11,0.8457187661468653,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
38652638_so,backpropagation conv-neural-network deep-learning machine-learning neural-network how to propagate error from the conv-layer to previous layer in lenet-5 cnn recently i m trying to implement the lenet-5 cnn but i stuck in how to propagate error from the conv-layer to previous layer for example from c3 layer to s2 layer could anybody please help me cnn typically have convolutional layer and pooling layer since pooling layer does not have parameters it does not require any learning error propagation in the last layer fc is same as nn the only magic tricks involve in convolutional layers while having backpropagation you can visualize the convolutional layers as a connection cutting nn  transforming multilayer perceptron to convolutional neural network  the error can be propagated back by utilizing the equation  back propagation of delta error,11,0.8457090206220368,"0.114*""network"" + 0.077*""neural"" + 0.072*""layer"" + 0.044*""output"" + 0.035*""input"" + 0.021*""learn"" + 0.016*""weight"" + 0.013*""deep"" + 0.012*""neuron"" + 0.012*""conv"""
21582_kg,according to  kaggle s own definition  of rmsle &quot;rmsle penalizes an under-predicted estimate greater than an over-predicted estimate.&quot how is this the case based on the definition of root mean squared logarithmic error?   well i answered my own question it follows from y = logx that there s a larger &#916;y corresponding to an equivalent &#916;x when x is small   brian i agree with you it s not clear common example i was able to find is this  rmsle measures the ratio between actual and predicted  logpi+1−logai+1can be written as logpi+1/ai+1  it can be used when you don’t want to penalize huge differences when both the values are huge numbers.also this can be used when you want to penalize under estimates more than over estimates  lets have a look at the below example  case a  pi = 600 ai = 1000rmse = 400 rmsle = 0.5108  case b  pi = 1400 ai = 1000rmse = 400 rmsle = 0.3365  as it is evident the differences are same between actual and predicted in both the cases rmse treated them equally however rmsle penalized the under estimate more than over estimate,18,0.8452734236660969,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
20922570_so,distribution gaussian statistics conditional normal distribution proportional to a joint density first of all i am sorry if this is not the proper place to ask questions about statistics i study machine learning so i wonder if there is a more appropriate website for this kind of questions  i only wonder why a conditional gaussian px1|x2 is said to be proportional to the joint density where it comes from px1 x2  thanks a conditional gaussian px1|x2 is said to be proportional to the joint density where it comes from px1 x2   in a sense every conditional density is proportional to the corresponding joint density since px1 | x2 = px1 x2 / px2 so maybe that s what they mean it s not a property which is special to the gaussian distribution however that s not proportional in the usual sense because the factor 1/px2 is not a constant,18,0.8451341666391553,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
41199160_so,conv-neural-network torch inceptionv3 transfer learning on torch is there code for an implementation of transfer learning on torch using incpetionv3 by training it on a  custom dataset ? i have obtained the model from  https://github.com/moodstocks/inception-v3.torch ,13,0.8444509008550094,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
36754888_so,classification machine-learning r text-classification topic-modeling topic modeling using pre-existing topics i need to do topic modeling in certain number of documents in r using lda  i have  n  most occurring words for each of  m  topics and i want to feed this to lda and want to get most occurring topicout of m topics present in each document  in short -    input  - x documents m topics with n top words for each   output  - top occurring 2 topics out of m topics in each document  is there any way to achieve this using already existing package in r or any other language yes it is possible to achieve this with  mallet  the command line syntax for this task is   where the classifier file contains your pre-trained topics,12,0.8441397791487126,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
58269867_so,darknet deep-learning keras neural-network why darknet model to keras model conversion drops accuracy i have a trained darknet model and have weights file with this now i converted this to keras using this    @ this  https://github.com/qqwweee/keras-yolo3   but this causing wrong prediction while in darknet it is giving true prediction on the same image. image with converted model    image with orignal darknet model ,13,0.8433492443162173,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
115933_kg,i don t know what s wrong — showing an error  something went wrong.this unexpected error has been logged for site administrators to review.please feel free to let us know if this error keeps happening i don t know what s wrong showing error.pls help how to fix it,0,0.8426305782081499,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
48940705_so,keras tensorflow very low accuracy upon retraining vgg16 in keras i am trying to retrain vgg16 for a new dataset by using transfer learning i have loaded the model with imagenet weights and without the top fully connected layers obtained predictions on the dataset from the bottleneck layers and trained a small model with those bottleneck predictions however the validation accuracy is very low at 0.002 after 50 epochs i am unable to figure out where the problem lies in my code which is a modified version of the inceptionv3 retraining code from the keras docs i have been able to retrain resnet50 on the same dataset with an accuracy of 0.88 my code is as below vgg16 uses the sequential model from keras resnet the functional api.therefore you should replace   by   also use softmax instead of sigmoid when using categorical class_mode,13,0.8415993309001911,"0.114*""model"" + 0.042*""keras"" + 0.032*""kera"" + 0.029*""train"" + 0.025*""image"" + 0.022*""loss"" + 0.021*""training"" + 0.018*""layer"" + 0.016*""learn"" + 0.014*""pytorch"""
23506_kg,i ve been tinkering a bit with augmenting by randomly changing up the order of channels if the electrodes were implanted in different parts of each of the patients  brains then this might be a sensible thing to do however i m not seeing the hoped-for improvement and i m wondering whether the electrodes really are interchangeable.. are the electrodes are being placed in more or less the same location in each of the patient s brains?   electrodes were placed on cerebral cortex covering the regions of the brain thought to be generating seizures thus electrode locations may differ across patients this is one reason why it might be better to train models on individual patients,10,0.8385808949975231,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
129597_kg,both arabic wikipedia articles and books were cleaned using the following code it is not perfect as some other odd combination of letters and symbols are likely to  be there ex ======== ------ .... to separate sections . etc. for downstream tasks text should be cleaned in a similar fashion. output  الماء سائل شفاف ولم أجد شيئا غير قابل للسؤال وهذا نص إنجليزي   i think keeping english words isn t bad because in news articles or other arabic text you will encounter entities in english company names or products scientific names and other names ... and removing these names will make the sentences meaningless   maybe in a non-general model where english presence is more usual and for non-general downstream tasks in this corpus foreign strings are rare ex terms in other languages in wikipedia for downstream tasks if kept they ll map as unks using same cleaning as above is probably better,12,0.8362885361753133,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
141780_kg,incorrect you have the wrong set of countries check your where clause.it s giving me wrong/incorrect even i use the solution you have given plz help me to understand this problem    it looks like you have solved this issue - let me know if you still need help!   yes it solved when i run after some time and thank you for your response,0,0.8360175178783398,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
10514_kg,"according to the evaluation page predicting a 0 when the true value is 1 should be very heavily penalised by the log function but the score seems much more reasonable have i misunderstood the evaluation?  update &nbsp;i missed this   &nbsp;in order to avoid infinite values and resolution problems the predicted probabilities \\y&#770;_{ij}\\ are bounded within the range [\\10^{&#8722;15},1&#8722;10^{-15}\\]    you got it a predicted probability of \\0\\&nbsp;is converted into \\10^{-15}\\,&nbsp;\\\hat{y}=0 \rightarrow \hat{y}=10^{-15}\\  actually you can mathematically find the benchmark value.&nbsp;an average sample belongs to&nbsp;1.12 out of the 33 labels hence the aggregated score function looks like this  \\\ \ \ \ \ logloss = \frac{1.12}{33} \left [-1 \cdot log10^{-15} \right ] + \frac{31.88}{33} \left [-1-0 \cdot log1-10^{-15} \right ]\\  the second term is so small that can be depreciated thus we have  \\\ \ \ \ \ logloss\approx \frac{1.12}{33} \left [-1 \cdot log10^{-15} \right ] = 1.1722\",18,0.8352651524331556,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
19002_kg,"hi kushal for each id in the test set you need to predict the probability that fault_severity = 0 the probability that fault_severity = 1 and the probability that fault_severity = 2.so in the sample sample submission predict_0 refers to the probability that fault severity = 0 ect   @kushal that is correct  hi ayse those values in the sample submission are merely for demonstration purposes it is preferable to predict the probability for each class   e.g say for id 9999 you predict 60% chance that the fault_severity =0 30% probability that the fault_severity = 1 and 10% chance that the fault severity = 2 then  id,predict_0,predict_1,predict_2   9999,0.6,0.3,0.1",18,0.8349756633141637,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
48628870_so,machine-learning nlp nltk python text-mining extracting sentenses belongs to different category from text using nltk i am new to natural language processing nlp and i came across a problem where from the given text i have to extract sentences belongs to different category like  1 sentences related to commitments like sentences including  will   shall  etc  2 sentences related to cost or budget  3 and so on...  i need to know which features of nltk should i use to implement this how easy to add more and more category to extract more subjective information?  any examples are even more helpful you are looking for text classification and nltk by itself is not enough nltk can do tokenization stemming word count etc but not classification   an alternate library in python is spacy which will do the above plus allow you to train and use a text classifier to identify sentences that belong to certain category suggest you go through the use cases at  spacy usage examples   for identifying sentences with commitment you can do a sentence dependency parse and look for will shall as the verb,12,0.8337712067259612,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
65483_kg,why  dataset is splitted after making vectors? it means that we have trained our model using entire dataset then what is the purpose of making test data set? should nt the test dataset be unseen from our model and only train dataset be used to train our model?  please correct me if i am wrong,1,0.8334209673356977,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
112776_kg,hi i have a question about the use of validation set after training on train set if i don t use cv strategy after seeing model performance on validation set should i put the validation set into train set for more train epochs or just leave it alone? and which stop strategy should i use for training on the whole train set including validation set? thanks!   you can do cross_validation and obtain number epochs before overfitting and used this number epochs for prevent overfitting,1,0.8333928685080005,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
11947748_so,categorization document-classification information-retrieval machine-learning tf-idf caluculating idfinverse document frequency for document categorization i have doubt in calculating idf inverse document frequency in document categorization i have more than one category with multiple documents for training i am calculating idf for each term in a document using following formula   my questions are   what does total number documents in corpus mean? whether the document count from a current category or from all available categories?  what does number of document matching term mean? whether the term matching document count from a current category or from all available categories i have written a small post describing term frequency-inverse document frequency here  http://bigdata.devcodenote.com/2015/04/tf-idf-term-frequency-inverse-document.html   here is a snippet from the post  tf-idf is the most fundamental metric used extensively in classification of documents.let us try and define these terms  term frequency basically is significant of the frequency of occurrence of a certain word in a document compared to other words in the document   inverse document frequency on the other hand is significant of the occurrence of the word in all the documents for a given collection of documents which we want to classify into different categories    is simply the amount of documents you have in your corpus so if you have 20 documents then this value is      is the count of in how many documents the term   occurs so if you have 20 documents in total and the term   occurs in 15 of the documents then the value for   is 15  the value for this example would thus be    now if i m correct you have multiple categories per document and you want to able to categorize new documents with one or more of these categories one method to do this would be to create one documents for each category each category-document should hold all texts which are labelled with this category you can then perform   on these documents  a simple way of categorizing a new document could then be achieved by summing the term values of the query using the different term values calculated for each category the category whose term values used to calculate the product result in the highest outcome will then be ranked 1st  another possibility is to create a vector for the query using the   of each term in the query all terms which don t occur in the query are given the value of   the query-vector can then be compared for similarity to each category-vector using for example  cosine similarity    smoothing  is also a useful technique to deal with words in a query which don t occur in your corpus  i d suggest reading  sections 6.2 and 6.3  of introduction to information retrieval by christopher d manning prabhakar raghavan and hinrich schütze,12,0.8332107955673095,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
32520_kg,the very large max times are mostly war games some of which actually can take that long!   wow i didn t realize that ok i guess i ll remove the filter for very large max times.i couldn t play a game that long mostly because i would be in constant fear of the board being knocked over,10,0.832883494510118,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
53128308_so,machine-learning nlp topic-modeling text content relevancy check i need to check relevancy of content on particular web page i have thousands of  webpages to check this on what is the best way to check if the page title is relevant to the content on the page you question is a bit vague when you say     what is the best way to check if the page title is relevant to the  content on the page   how is being relevant defined in the context of your problem?   i don t know if this is what you want but couple of thing come to my mind which essentially is comparing how similar two documents are being one document the title and the other the description  you can think about methods to generate vector representations for both and compare how similar they are   jaccard similarity using the tokens as elements of the both sets i.e documents   tf-idf weighted vectors and compare them with cosine similarity  compute distribution topic model/lda for each document and compare them using kullback-leibler divergence  encode the documents into some sort of dense vector doc2vec or read them through an lstm and keep the last state and then compare both vectors   the only consideration is that the size of the title is very small compared to the content of the webpage,12,0.8312362070212407,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
17053459_so,classification machine-learning how to transform a text to vector i m learning classification i read about using vectors but i can t find an algorithm to translate a text with words to a vector is it about generating a hash of the words and adding a 1 to the hash location in the vector if you are learning classification i would start with the easier and more intuitive bag of words representation of your text  if you are however interested in using a feature hashing method particularly if you have a large set of data i would suggest  this article  which describes the use of hashing in text representation and classification   when most people talk about turning text into a   feature  vector  all they mean is recording the presence of the word token  two main ways to encode a vector one is explicit where you have a   for each word that is not present but is in your vocabulary the other way is implicit---like a  sparse matrix  but just a single vector---where you only encode terms with a frequency value    bag of words model  the main article that explains this the best is most likely the  bag of words model  which is used extensively for natural language processing applications  explicit bow vector example  suppose you have the vocabulary     the sentence   could be encoded as     remember position is important  the sentence  ---even though it is shorter in length---would then be encoded as     the problem with the explicit approach is that if you have hundreds of thousands of vocabulary terms each document will also have hundreds of thousands of terms with mostly zero values  implicit bow vector example  in this case the sentence   could be encoded as     where the order is arbitrary,12,0.8311328561716049,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
58836322_so,cosine-similarity doc2vec gensim nlp search how to do language representation on huge documents of 3000-4000 word for query-based retrieval i am trying to implement a semantic search to retrieve similar documents from a dataset of unstructured french documents   these documents are not categorized and are templates with 300 - 3000 words per document  i am using doc2vec using gensim to find the paragraph embeddings with 300 dimensions and a window of 5 of the dataset  i am then converting the search query which is a maximum of 5 words to the vector with 300 dimensions and comparing the cosine distance to find the document close to the search queries   i am not getting good results please suggest some strategies to do the semantic search i was trying to reduce the number of words in my dataset by doing rake keyword extraction the reason for your poor result if the queries are just too short to be embedded by  doc2vec if you only care about performance i would recommend using some off-the-shelf information retrieval tools like lucene  if you want to play with neural nets and embeddings you can do the following    just use word embedding e.g from  fasttext  remove stop words both in the query and the documents and represent them with the average word embedding and do the comparison by cosine distance    if you don t care about efficiency a lot you can also try multilingual bert available in the  transformers  library or brand new french model called  camembert  in this case you would just take the   vectors and do the cosine distance on them    i would start with indexing your documents in  elasticsearch  their out-of-the-box methods with tf-idf are pretty great  if you re looking to do more sophisticated semantic search using neural networks i would recommend  nboost  you can just   and it will create a semantic search engine out of the elasticsearch,12,0.8310274587844705,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
80529_kg,i supposed that when line began to discharge or forming a fault the components of the signal may have changed there might be some noise in the main components of a signal however if we observe a signal merely from its apperance or the voltage it shows it would be really hard for us or even for computer to distinguish the fault thus i assumed that fft could be useful for us to reduce the dimension of a signal since it could separate the signal into the frequency domain.i m just starting to play this game so this is just a primary guess your comments are welcomed   when you take fft of a faulty signal you are likely to get spikes at odd harmonics but under healthy state the spikes in a fft plot would be at fundamental frequencies.i am have no idea about the code for fft of a signal data but you can find it easily,10,0.8303589377495466,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
131880_kg,hii am confused about the exercise because my own code that looks like the answer triggers an error and the suggested answer also triggers the same error and thus prevents me from progressing what am i doing wrong however i think the code to evaluate the response has a little bug has anyone managed to make it work?   finally works as it should.seems they did something to correct the bug,0,0.8294510496097192,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
53875185_so,"cross-validation machine-learning does k-fold cross validation use all k-1 fold in each training step in classification does k-fold cross validation use all k-1 fold in each training step ? if i have a fold  a,b,c  and  d  and i use  d  as my test fold in k-k+1 step will i use  a  +  b  +  c  as my training data yes basically the steps are as follows   split the whole data into k folds after random shuffling optionally  hold out one group as the test set  train the model on the remaining groups  evaluate the model on the test set",1,0.8290539029898816,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
33217030_so,"r statistics receiver operating characteristics can i expect a continuous roc curve on binary outcomesactual,predicted i am using the following commands on the binary actual and binary predicted outcomes and all i am getting is just a plot with one inflection.the command i am using is    the reference sample dataset is    please let me know if there is any alternative explanation and plotting the roc as has been suggested roc curves can be plotted when you have a score or probability variable the roc cure then plots different false positive rate / true positive rate pairs according to varying thresholds your classifier seems to produce 0/1 output so you can only plot a point in the roc space see  fawcett 2005  for more information  here is an example of an roc curve where the predicted value is a probability        this is not the correct way to plot the area under the roc curve plotting it this way will give you 50% for all points since you do not provide any thresholds  the whole point of the roc curve is to provide a more thorough view of your accuracy of the model by plotting the specificities and sensitivities for each threshold check  here   the threshold takes values between 0 and 1 since it is a probability threshold is what determines a test case to be 0 or 1 according to its associated probability as an example having a threshold of 40% any predicted case with probability over 0.4 would be classified as 1 success and less than 0.4 as 0 failure the collection of specificities and sensitivities according to various thresholds is used in the calculation and plotting of the roc curve  as an example from the proc documentation in order to use the plot.roc function you could do   and then you can plot it as",18,0.8260274399516354,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
11344854_so,algorithm artificial-intelligence machine-learning multilingual search-engine multi-language search matching suppose we have the  name  written in any  none-latin letters  - languages like   etc  how could a   match between the   and the   of the same name and vice versa?  something like the name   in japanese and the   spelling     what is the   used to do this  good day  you have to do following  classificate each lang in the world on the same symbols      engish [26 letters]  a  b c d  e  f g ..   russian [33 letters]  a б в  г д е  ...  chinese [x letters]  ...  ukrainian [x letters]  a б в г д .... i   japanese [x letters] ..   ................   finally you will be have rules between any symbols spelling in any langs.some langs for instance hindi chinese and etc not will be have any rules you should be create your own rulesbased on transcription of this langs     [w][e][п] = wep  e  e  r  e - engr - rustranscription[п] = p  search engines like google probably has huge amount of data sets corpus each corpus in different languages  when you want to translate a word in one language to other language it can be done by searching the word in the corpus in the first language and return the compatible word in the corpus of the second language same technique for names  that s the basic idea  you better read about the nlp field here for some background: http://en.wikipedia.org/wiki/natural_language_processing,12,0.8259966212932708,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
113012_kg,"what is the need of this and where we can use it efficently   first,interquartile is calculated by = quartile3-quartile1as a general way to find outliers is any datapoint which is above quartile3+1.5inter quartile range is qualifying for outliers same way any datapoint which is below quartile1-1.5inter quartile range is also qualifying for outliers.and datapoints in interquartile range are less affected by outliers.the interquartile range which tells us how far apart the first and third quartile are indicates how spread out the middle 50% of our set of data is   thank u   inter quartile range is the difference between your first quartile and your third quartile.inter_quartile_range = third_quartile - first_quartile",18,0.8259146985483642,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
46244_kg,i tried the predict function the results were pretty bad it was 0.6xx then i tried predict_proba it jumped to 0.05 on lb does anyone has an explanation? does this have something to do with log loss? thanks   predict will output 0 or 1 while predict_proba will output a probability of classes occurrence 0 and 1 as we our evaluation metric is log loss instead of accuracy probabilities are more relevant and appropriate in our case   yep this has to do with logloss - logloss cares about the confidence in your predictions - if you say you are very confident in a prediction and you turn out to be wrong then the loss is very high  predict gives outputs of either 0 or 1 actually internally all this is doing is   while predict_proba gives you a probability let s evaluate a case where your classifier predicts 0.7 as the probability   predict_proba = 0.7   you are right       you are wrong    expected loss given that p=0.7 0.356 * 0.7 + 1.2 * 0.3 = 0.609   predict = 1   you are right       you are wrong   actually probably   as kaggle clips your predictions to avoid infinite loss  expected loss given that p=0.7 0 * 0.7 + 13.81 * 0.3 = 4.14  as you can see logloss penalises you much much more if you predict a super high probability and end up getting it wrong  from this we can see that with predict even though your loss would be lower if your prediction was correct the added loss from getting a  sure  prediction incorrect greatly outweighs the score gain you get thus it s best to give your  best guess  probability with logloss as this will mean that on average you will get a better score  this is one of the reasons logloss is a useful metric - it enforces that your provided probabilities are indicative of the  actual  probabilities unlike a metric such as auc which only cares about how well you separate the positive and negative classes,18,0.8254236656747723,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
65723_kg,"i am performing classification on a dataset of 20477 samples i have done a 70−30 split and fit a randomforest model on the train data i am getting an accuracy of 99% on the train data on the remaining 30% as test data i am getting an accuracy of 80.1% now i decided to use cross-validation to check for overfitting  i use 10- fold cross-validation on the entire dataset and get an accuracy of 81% how do i infer from this whether i am overfitting?next i decided to run cross-validation on my training set alone and got an accuracy of 78% does this drop from 99% meant that i my training model was overfitting?    thanks for your reply so my accuracy on [cv_train cv_entire_data test] or [78,81,80.1] is the real indicator of how my model is performing right? i had a confusion regarding whether getting a cv_train or 78% and a cv_entire_dataset or 81% is the right way to go about it  i will definitely try the hyperparameter tuning   you should not expect to get 100% accuracy on the training data just because your model is trained on that data this is only possible if the model is complex enough to memorize all the data and there are no contradictions or ambuiguity in the dataset  your model is scoring 99% on the training set but significantly less on your cv and holdout set so it very likely it s overfitting you should try reducing the depth of the tree reducing the max_features available to each learner increasing the minimum samples required to split etc  use your cross-validation to tune the parameters then test again against the holdout set   thanks @garethjones for your reply i am also getting a crossvalidation accuracy of 81% on the entire dataset and my test accuracy is 80.1% although these are two separate methods to evaluate a model doesn t my test accuracy tell us that we are not overfitting",1,0.8253744868263682,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
56099495_so,"classification machine-learning python train-test-split what should be passed as input parameter when using train-test-split function twice in python 3.6 basically i wanted to split my dataset into training,testing and validation set i therefore have used train_test_split function twice i have a dataset of around 10-million rows   on the first split i have split training and testing dataset into 70-million training and 30-million testing now to get validation set i am bit confused whether to use splitted testing data or training data as an input parameter of train-test-split in order to get validation set give some advise tia don t make a testing set too small a 20% testing dataset is fine it would be better if you splitted you training dataset into training and validation 80%/20% is a fair split considering this you shall change your code in this way        this is a common practice to split a dataset like this",1,0.8236592874955494,"0.087*""datum"" + 0.067*""set"" + 0.061*""test"" + 0.057*""training"" + 0.054*""train"" + 0.050*""model"" + 0.036*""dataset"" + 0.021*""data"" + 0.016*""sample"" + 0.016*""prediction"""
10185_kg,each subject has a different number of test examples which can bias the evaluation metrics towards the subjects with most examples does the metric account for the difference for example by taking an average of aucs calculated for each subject separately?  bartosz   not only towards the subjects with most examples but also with respect to the different ratios of preictal/interictal test examples in each subject  i understand that the auc is computed globally not by averaging 7 per-subject aucs but i agree with you intuitively the average would be a fairer measure of performance,18,0.82358677989483,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
44612806_so,machine-learning named-entity-recognition nltk generating ques-answer pairs from unstructured text i have to create a system that generates all possible question answer pairs from unstructured text in a specific domain.many questions may have the same answer but the system should generate all possible types of questions that an answer can have.the questions formed should be meaningful and grammatically correct for this purpose i used nltk and trained an ner creating entities according to my domain and then i created some rules to identify the question word using the combination of ner identified entities and pos tagged words but this approach isn t working fine as i am not able to create meaningful questions from the text moreover some question words are wrongly identified and some question words are missed i also read research papers on using rnn for this purpose but i don t have a large training data since the domain is pretty small can anyone suggest a better approach ,12,0.8204537315415363,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
56723111_so,bert-language-model classification deep-learning nlp using bert in order to detect language of a given word i have words in the hebrew language part of them are originally in english and part of them are  hebrew english  meaning that those are words that are originally from english but are written with hebrew words for example  insulin  in hebrew is אינסולין same phonetic sound   i have a simple binary dataset x words written with hebrew charactersy label 1 if the word is originally in english and is written with hebrew characters else 0  i ve tried using the classifier but the input for it is full text and my input is just words   i don t want any masking to happen i just want simple classification  is it possible to use bert for this mission? thanks bert is intended to work with words in context without context a bert-like model is equivalent to simple word2vec lookup there is fancy tokenization but i don t know how it works with hebrew - probably not very efficiently so if you really really want to use distributional features in your classifier you can take a pretrained word2vec model instead - it s simpler than bert and no less powerful  but i m not sure it will work anyway word2vec and its equivalents like bert without context don t know much about inner structure of a word - only about contexts it is used in in your problem however word structure is more important than possible contexts for example words בלוטת gland or דם blood or סוכר sugar often occur in the same context as insulin but בלוטת and דם are hebrew whereas סוכר is english okay originally arabic but we are probably not interested in too ancient origins you just cannot predict it from context only  so why not start with some simple model e.g logistic regression or even naive bayes over simple features e.g character n-grams? distributional features i mean w2v may be added as well because they tell about topic and topics may be informative e.g in medicine and technology in general there are probably relatively more english words than in other domains,12,0.8202998374291438,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
10191_kg,the evaluation metric of this challenge is&nbsp;area under the roc curve but how is this curve generated? specifically if our submission contains only boolean predictions i.e 0 or 1 instead of real-value probabilities changing the threshold value will not yield different&nbsp;classification results and there will be only one single point in the plot instead of a curve  according to  wikipedia  there are multiple techniques to produce the roc curve such as trapezoidal approximations and roc auch i wonder which one kaggle uses  thanks!   if you use a 0/1 output you obtain a pair of sensitivity/specifity values say se* and sp*  in that case your roc curve consists of three points  se = 0 sp = 1  se= se* sp = sp*  se=1 sp = 0  the area under this trapezoid is the auc   kaggle specifies probabilistic outputs not binary this means they can generate the entire roc curve by varying the threshold probability that defines a hit that being said the best 3-point score will be found by using the threshold with the fewest classification errors if the cost of a false alarm is not the same as the cost of a missed detection then this is not the case   [quote=kdoniger;53292]  kaggle specifies probabilistic outputs not binary this means they can generate the entire roc curve by varying the threshold probability that defines a hit that being said the best 3-point score will be found by using the threshold with the fewest classification errors if the cost of a false alarm is not the same as the cost of a missed detection then this is not the case  [/quote]  i think binary outputs are also accepted since they can be seen as probabilities of 100% and 0,18,0.8172218434777716,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
131772_kg,why we use r square and adjusted r square inn linear regression?   r squared is a measure of how much variance is explained in the model the other common calculation of mse is used to gauge how the fit of the model is to the data where the regression is gauged on how the variance is understood that way outliers will not be as much of a surprise it displays a bigger measure of extremties b by using r squared,18,0.8171478588583668,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
10914846_so,"boost c++ normal-distribution probability statistics how to compute cdf probability of normal distribution in c++ is there any function that allow me to compute the cdf probability of a normal distribution given a mean and sigma ? i.e for example p x &lt x  given the normal distribution with $\bar{x}$ and $\sigma$  i think boost have this but i think that it is just for the  standard  normal distribution you scale -- any nm s can be turned into n0,1 by dividing by s and subtracting m  so all you need is a cdf for n0,1 which is provided by a number of libraries  here is a simple r example",18,0.8166152724743512,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
3631_kg,in order to improve the two disjoint paths one might remove some edge a-b that looks like it might be largely improved select the set of say 10 or 20 cities that are nearest to a remove any edge from the two disjoint paths with both ends in the selected set union {a b} and find the best way to reconnect the two disjoint paths by some exhaustive backtracking search i think it can easily be done with a short execution time by early detecting choices of edges that prevent any future improving choice of edges from another city in the set   i ve tried something similar trying all possible re-wirings of about 20 cities close to ends of long edges with some optimizations to avoid a full combinatorial explosion found a few good improvements this way initially but then it dried up as search is only local   that s about all i did combined with long edge rewiring i found long edges and then for all nodes near each end point tried reordering things from a-b-c to a-reverse b-c where the long edge is at the atail-bhead and the near nodes that are checked for an improvement are btail this easily gets rid of all long legs and crossed legs but didn t get under 6.8million   yes we did that for subsets of vertices of size around 100 :   probably why i am lower down the board - as part of my solution i had a fairly brute-force 10-node full search and optimise it had a small amount of speed up for skipping routes blocked by being non-disjoint but otheriwse was too crude to make the test paths longer as it considered all possible combinations even though there are probably good heuristics out there for safely ignoring the majority of bad combinations which would allow it to find longer exact solutions   [quote=quantum leap;19471]&nbsp i ve tried something similar trying all possible re-wirings of about 20 cities close to ends of long edges with some optimizations to avoid a full combinatorial explosion found a few good improvements this way initially but then it dried up as search is only local.&nbsp  [/quote]    thanks quantum leap that s what i was thinking of and didn t find the time to finish up one difference though  did you explore the longest edges only ? unfortunately this would have prevented you to improve on many bad edges in dense regions that were shorter than good edges in sparse regions   &nbsp  &nbsp  [quote=vlado boza;19479]&nbsp yes we did that for subsets of vertices of size around 100 :&nbsp  [/quote]   excellent vlado boza&nbsp;! i now see on your blog that you did something much like it -- and so much more !  is your use of sat in part v able to find the real local optimum on the sector or does constraining it to alternating cycles cleverly mirror the kind of improvements that surfaced in your previous optimizations but might well ignore some other kinds of improvements in full generality?  were you also careful of not constraining disjointness on virtual outer edges in your first sector optimization with lkh in part ii ? unfortunately it was fixing the other solution path and not yet improving on both paths simultaneously i m not sure i understand everything you did between part ii and part v in case part v looses some generality d id you do try some real full local optimization on both solution path simultaneously ?   &nbsp  [quote=neil slater;19488]&nbsp probably why i am lower down the board ... to make the test paths longer ... allow it to find longer exact solutions ...&nbsp  [/quote]    neil slater maybe you should have looked for shorter paths instead of longer ! lol    [quote=claude chaunier;19551]   &nbsp;in case part v looses some generality d  id you do try some real full local optimization on both solution path simultaneously ?   [/quote]  in fact this is an optimization of both paths simultaneously aiming at their average decreasing max while maintaining avg can by done by k-opt moves in our megaopt the alternating cycle is between the current 4-factor and other edges after you find an alternating cycle i.e a way how to change current 4-factor to cheaper 4-factor you still need to re-wire both paths moreover as we learned later this technique is not really working on a single path as the alternating cycles have a tendency to change the cycle 2-factor to a cheaper 2-factor which is seldom a full circle  moreover i believe that you can always rebuild 4-factor to the smallest 4-factor just by finding alternating cycles and flipping edges on them the difference of two 4-factors is an &quot;even-factor&quot graph with all vertex degrees even and this can be always decomposed to several cycles just take an euler path of each connected set of vertices and obviously one of these cycles must be negative otherwise the first 4-factor is cheaper than the optimal one the only problem is that these cycles might be way longer than we search for but that is a tradeoff between finding an optimal 4-factor proving there is no negative alternating cycle and the speed,10,0.8164595908740098,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
15959_kg,hi everyone  i have this concern about the raw data we got for this competition since the recorded grasp-and-lift tasks aren t imagery require the subject to actually perform the movement the data has a lot of information that comes from muscular activity in fact this emg information can be used to help with classification of each phase   if that was an eeg-only research such emg information would be treated as noise an highpass filtered since that is not the case here someone can use this emg information to improve his/hers results although the accuracy will increase this will no longer be the eeg classification problem   i would like to know what s the case here? is using this muscular movement related information fair and the &quot;eeg&quot in the competition s name is just to gain attention or is it in some way forbidden?   binaryb how would you separate the emg from the eeg signal what does it have special? i ve read it is known which muscles influence activity on which electrodes but how would one make the difference between neuronal and muscular activity?   the rules for this competition state that &quot;future&quot data are not permitted in any computations e.g eeg signals when muscular activity is already taking place cannot be used for predicting onset of muscle movement i would be more concerned about the usage of evoked activity from the visual cue as the predictor of movement since it precedes the intent of movement   @ana_4min  the best way would be to have a reference emg signal for adaptive filtering unfortunately that is not the case here you could also use some blind source separation methods but that would validate causality requirement  here at least some parts of such artifacts would lay in low frequency range these can be observed as significant changes in signal s trend and can be removed with highpass filtering that would also help with eye movements   @jemmychen   you can still use this muscular information with some delay that way your algorithm s output would stabilize faster on a correct  value lateralized readiness potential precedes the movement for only a few milliseconds if you use muscle movement information here you would missclassify those only first few samples but then it would be good  on the other hand i wouldn t worry that much about visually evoked potentials vep you can discard channels that cover visual cortex even better solution would be to select only eeg channels from motor cortex   binaryb thank you what sort of frequencies bands are muscle activity and eye movements expected to be in?   @ana_4min  i d say that it is best to cut out frequencies below 1hz to get rid of this unwanted trending   with eyeblinks also very problematic next to eye movements it is a bit more complicated as i said the best practice would be to use additionally provided eog signal for adaptive filter unfortunately we don t have that most papers on ocular artifacts in eeg say that eyeblink related artifacts are strongest below 10hz that means they are mixed with brain s alpha activity  my suggestion would be to perform time-frequency analysis of short signal fragment with eye artifact so that you have the idea how this works probably highpass filter with cut-off frequency set to 10-12hz would do the trick you must be aware of the tradeoff here the higher cut-off the better ocular artifacts are filter but also more eeg information is lost   binaryb thank you,10,0.8159160150774157,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
58541811_so,bert-language-model named-entity-extraction ner nlp pytorch how to use bert just for entity extraction from a sequence without classification in the ner task my requirement here is given a sentencesequence i would like to just extract the entities present in the sequence without classifying them to a type in the ner task i see that bertfortokenclassification for ner does the classification can this be adapted for just the extraction?  can bert just be used to do  entity extraction/identification  regardless bert ner tagging is usually done by tagging with the iob format inside outside beginning or something similar often the end is also explicitly tagged the  inside  and  beggining  tags contain the entity type something like this   if you modify your training data such that there will be only one entity type the model will only learn to detect the entities without knowing what type the entity is,12,0.8154844915431299,"0.049*""word"" + 0.036*""text"" + 0.019*""document"" + 0.015*""sentence"" + 0.015*""vector"" + 0.011*""nlp"" + 0.011*""model"" + 0.009*""embed"" + 0.009*""feature"" + 0.008*""question"""
48632_kg,i need clarification about how the threshold is incorporated into the computation of the average precision of a single image the formula is presented as  &gt \frac{1}{|thresholds|} \sum_t \frac{tpt}{tpt + fpt + fnt}  i don t understand three things about the first term     why is it plural? shouldn t it be threshold?    why is it outside the sum? shouldn t it be inside?    why the absolute value bars? there is no need thresholds are not negative    i think the formula should probably be  &gt \sum_t \frac{1}{threshold} \frac{tpt}{tpt + fpt + fnt}  somebody please confirm or correct    thresholds  would probably be more explicit as # of thresholds in this case it comes out to 1/10 computationally it doesn t matter whether the 1/10 is inside the sum or outside i agree the absolute value bars aren t needed since there will always be more than one threshold  in other words the evaluation metric for an image is the unweighted mean of the precision values at the different thresholds   thanks,18,0.815367463145368,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
55208144_so,hypothesis-test p-value permutation r statistics-bootstrap how to calculate p-value comparing bootstrap-based predicted probabilities and observed probabilities given the sample data   below i would appreciate any help to  1 check whether my approach below following boot s  vignette  to calculate bootstrap-based predictions from logistic regression is correct and help correct if there is any mistake in my approach   2 calculate    bootstrap-based p-values comparing the observed probability and the predicted probability   #my sample data     #doing bootstrap     #calculating bootstrap-based p-value comparing the observed probabilitye.g 0.45 and the predicted probabilities based on the bootstrap algorithm    thanks in advance for any help if there is anything that is not clear please kindly let me know ,18,0.8127908739672604,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
19216912_so,bayesian statistics for the multivariate normal model why is jeffreys  prior distribution not a probability density for the multivariate normal model jeffreys  rule for generating a prior distribution on   gives     my book notes in a footnote that   cannot actually be a probability density for   why is this it s improper meaning it doesn t integrate to 1 as probability distributions have to do  for example the marginal density with respect to theta is just a constant whose integral over the real line is infinite  it s ok to use improper distributions as priors in bayesian inference as long as the posterior is a proper probability distribution,18,0.8125500496835503,"0.027*""score"" + 0.024*""probability"" + 0.019*""prediction"" + 0.018*""metric"" + 0.016*""distribution"" + 0.015*""predict"" + 0.015*""calculate"" + 0.012*""model"" + 0.012*""result"" + 0.011*""give"""
91449_kg,we commonly see bayesian optimization and whatnot but i was wondering why we don t use genetic algorithms as often   initially people thought that genetic and evolutionary algorithms were the future fueled by spectacular early results however rigorous results were slow in coming and often sobering most prominently the no free lunch theorem it became evident that genetic/evolutionary algorithms are often decent heuristics but never optimal in any sense  genetic algorithms are mostly useful for brute force search problems,10,0.8124621700534473,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
52993992_so,jupyter-notebook python tensorboard tensorflow tensorboard written in the jupyter notebook doesn t work i run the code   but this code is not running because of the following error   after trying to understand the source of the problem i saw that if the line   in the loop i change the line      the problem is solved  i tried to search for understand what the error was and didn t find anything to solve the problem  i need the line to work in its original form without the deletions  i would be happy if someone can tell me what the problem is and what its solution is i m on   and the original unedited version      runs successfully runs with no errors on both   and on the terminal   i did however notice that when i ran the script a second time on   that i got the same error as you this leads me to believe you re keeping state between runs  on the terminal where no state is kept between consecutive runs it all worked fine,0,0.8117022724518776,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
92420_kg,i keep getting indentationerror unexpected indent error after i run my code please help!!!   hi bashir  i think that if you just remove the space you have before   and   it will work in python whitespaces matter and this is why the interpreter is confused  i hope this helps  cheers   it did work! thank you,0,0.8106924742404938,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
6258_kg,hello  i ve attached a graph of the absolute values of current for the 2 phases in the red boxes you can see a periodic event that is consuming power but doesn t exists in the tagging info.&nbsp  what is it? should be considered noise?  thanks  nick   my assumption was that was some sort of heating/cooling system that kicks in with a fairly regular though not perfectly periodic behavior e.g the room temperature drops to 65 degrees f the system kicks in the temperature rises to 70 degrees the system turns off the temperature drops etc that s just a guess.&nbsp  at any rate i treated it as noise - those controlling the appliances did not have control over it   your guess makes sense ronsfeld thanks for the reply,10,0.8098273315537412,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
116740_kg,nameerror name  run  is not defined getting this error?   nameerror name  detect  is not defined as well as  name  run  is not defined getting this error?   any updates on how to fix the error   run function should be tr.run,0,0.8064485125238685,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
42313_kg,if the pokemon in the first columns attacks first which is the meaning of speed attribute? i knew that the pokemon with more speed should attack first but maybe i m wrong can you give me more information about it? thank you    a pokemon s speed determines who goes first in battle a pokemon with 200 speed will move before a pokemon with 199 speed some moves have priority a move with a higher priority will move before one with lower priority for example if a pidgeot with 300just an example speed went against a deoxys with 301 speed the deoxys would normally move first but if pidgeot used quick attack and deoxys used light screen pidgeot would move first because quick attack has higher priority if two pokemon use a move with the same priority the pokemon who has more speed will move first example pidgeot and mew mew uses quick attack and so does pidgeot if pidgeot or mew has lower speed than the other that one will move last.if two pokemon with the same speed use a move with the same priority whoever moves first is determined randomly,10,0.8036875106112362,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
77718_kg,hi all  the sampling rate is 4 mhz which looks very high to me i don t know if this is a common sampling rate deployed in the real earthquake monitoring task nor do i know if this is commonfrequency to  see  the destructive waves in lab conditions   being high is not bad resolution thing needs to be just right  supposedly  those major destructive waves indeed reside in somelower frequency bands what we will need is to zoom-in our spectral graph especially the lower chunk  that is to require a higher resolution in the frequency domain in whicheverthe transformation we use e.g stft  just realize this i m not sure if this will lead to a better modeling strategy.if anyone knows about this feel free to comment!   real world earthquake monitoring uses much lower sample rates - maybe 20 hz max the waves travel hundreds of miles and are subject to plenty of attenuation especially the high frequencies in the lab the distance is a few feet and so the frequencies are much higher just what type of waves we are seeing in these laboratory data is a bit unclear to me especially since i don t know the geometry - probably mostly surface waves also i don t think we are looking here at destructive waves - note that the seismic amplitude at the failure is small - no spikes there the paper calls them slow earthquakes   i tried to looked at the sample spectrum below 1k hz but failed.. too blur   if say even in lab condition we are expecting small frequency ones then aggregated statistics/features might end up being more informative than the features from windows within windows..   my thoughts are here i am more and more convinced there s a mistake in competition description. https://www.kaggle.com/c/lanl-earthquake-prediction/discussion/77708    umm i m not sure about those but considering such experiment/simulation is pretty standard in earth science i choose to trust the description it is worth mentioning though i didn t think of that before,10,0.8019202923369896,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
70682_kg,i ve got this message. something went wrong.this unexpected error has been logged for site administrators to review.please feel free to let us know if this error keeps happening  any solution for the issue?   same here   same here,0,0.8005739067240528,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
115463_kg,would you like to tell me that are the below case a running play or pass play or other ?   qb throw the ball to backyard offense player and gain yards  qb is overthrown by defense before throw ball and lost yards    both of these come under trick play actually i think i m not sure about the game as well and from what i have understood is that these are just unorthodox tactics in play  for more research try here  https://en.wikipedia.org/wiki/trick_play    thank you! i ll try to check this wiki,10,0.7969789677774128,"0.027*""time"" + 0.013*""good"" + 0.012*""make"" + 0.010*""problem"" + 0.009*""point"" + 0.007*""question"" + 0.007*""thing"" + 0.007*""find"" + 0.007*""work"" + 0.007*""approach"""
52983880_so,python tensorflow tf.case get unexpected results when use lambda look this example   we expect m1 m2 is 0 1but we got 24.and the result of m_list is right just like m1_ and m2_ it s strange  although i have fixed this bugsee my answer i still have a question i don t know why this code will cause closure case_set is not in any function dose anyone know why this is closure infact this bug is not caused by tensorflow the real reason is python s closure  see this link so this code will get expected result   although i have fixed this bug i still don t know why this code will cause closure case_set is not in any function dose anyone know why this is closure,0,0.7963426235743281,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
141655_kg,i am getting error for the following exercise         hi biranchi i got the same error message and the problem turned out to be due an error i made in the previous step of the exercise maybe it helps   what error were you making in the previous step?i get an error incorrect expected a returned value of around 0.85 your function returned 0.5which is impossible with only 4 values   what error were you making in the previous step?i get an error incorrect expected a returned value of around 0.85 your function returned 0.5which is impossible with only 4 values   hi noah actually the expected value of 0.85 is for a larger dataset not the initial 4 images,0,0.7896689179490657,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
140379_kg,hi i have some problem with the check function in this exercise although i typed the answer for potential_leakage_feature is 2 i still received a message attributeerror  nonetype  object has no attribute  keys   does anyone suffer with this problem? if yes how can you manage to get over it? thanks a lot    hello!  you accidentally commented this line in the first code cell  removing it fixes the issue  congratulations for finishing the course,0,0.7889370093103993,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
57505_kg,it says something went wrong this unexpected error has been logged for site administrators to review.please feel free to let us know if this error keeps happening   i also met the same problem   i also met the same problem   now it works!   this should be fixed now sorry for the inconvenience    thank you! it was my mistake i was not sure how to submit i ended up doing it wrong,0,0.7873215405294582,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
100092_kg,nan  just un-comment them  by removing # hash  at start of each statment   remove the # from the hint or solution and then run the cell   wherever there is a # before a statement that statement won t be executed because that s a comment remove them and voila! you can see your hint/solution,0,0.7765041605759415,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
60147_kg,hello i have code that appears to execute perfectly in the console no error codes but when i hit commit and run i get an error and am not able to see the error codes  any suggestions?is anyone else experiencing errors ,0,0.7762118006916136,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
147222_kg,trying to run code in q4 of the exercise loops and list comprehension of the basic python micro-course and it s not showing any output i refreshed the page and re-ran the setup code and all other code is working when ran except for q4  am i doing something wrong? i tried to intentionally put errors in my code and it didn t even show any warnings  thanks!   put q4.check  in the bottomcomment out q4.hint   also note that you need to exec the code portion on the top   hi srinika   thanks for the help but it still isn t giving me an output even when i put a print and q4.check i commented all of my code out and it still thinks got it right  https://gyazo.com/fbd38d9437af144a359b4010a2154a17    earlier your issue was not showing an output i assumed that you might have missed the q4.check.was that the issue or anything else?  what is your new issue? i do not know how q4.check works so i don t have an answer for that one.and i feel like your code is not correct   i just figured this out in other exercises in this course you never had to call the function you re running by yourself it s usually done when you run the .check function but in this specific question .check will always produce the solution no matter what so when i explicitly ran the function i can see the output  thank you for trying to help,0,0.7747134993421554,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
48587582_so,cluster-analysis eoferror python-2.7 shows some py code error called eof clustering code below i get this error eof as it works for others . but shows some error for me. pls do help me with this guys. thanks in advance  i get this error eof as it works for others . but shows some error for me. pls do help me with this guys. thanks in advance i get this error eof as it works for others . but shows some error for me. pls do help me with this guys. thanks in advance i get this error eof as it works for others . but shows some error for me. pls do help me with this guys. thanks in advance most likely your pickle file is corrupt  for example incomplete truncated,0,0.7686046314514776,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
110954_kg,"hi,when i commit seems to be complete but the kernel does not display the outputs the run is very short please the  kernel  without output there is no error in log message i run the code manually one by one   it works      log message      click on  open version  u will see  output  section  your kernels are executed without errors   @kmezhoud     yes but i can  not see the results of the codes   i run the same code by  r script  and i get this error message      it s weird your cell blocks don t have numbers that means that the cell blocks are not executing   i m not sure what is causing this but i have seen a weird thing once in a while where i have a python kernel where one cell block of code gets skipped and not executed the skipped code block always follows a code block that produced an error  for example code block 1 runs fine code block 2 has an error code block 3 gets skipped code block 4 runs fine   thanks i tried to run all blocks successively and manually they work and i get the submission dataframe but i can not save it",0,0.7667957833032423,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
69210_kg,i m getting weird error that says something went wrong.this unexpected error has been logged for site administrators to review.please feel free to let us know if this error keeps happening.what s going on,0,0.766639342452579,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
69187_kg,it shows the error information as follow:something went wrong.this unexpected error has been logged for site administrators to review.please feel free to let us know if this error keeps happening  could you please help to fix it,0,0.7616024465172782,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
140481_kg,it is said there are 4 problems but i  can only find 3 and this exercise can t be completed.is there something wrong?😂    hello!  looks like the four problems was just a typo  to get full credit for this exercise you need to:- run  - run  - get a correct result from running    congrats for completing the course!   it s completed! thank you very much,0,0.7601222037009812,"0.076*""code"" + 0.067*""error"" + 0.034*""run"" + 0.033*""problem"" + 0.030*""work"" + 0.021*""python"" + 0.020*""follow"" + 0.017*""issue"" + 0.017*""change"" + 0.015*""line"""
